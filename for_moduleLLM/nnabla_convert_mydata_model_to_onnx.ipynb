{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7AZw388QBa6U1OJFapuTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronron-gh/ESP32_EdgeAI_PlatformIO/blob/main/for_moduleLLM/nnabla_convert_mydata_model_to_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nnablaをインストールする。"
      ],
      "metadata": {
        "id": "rXJs-ZgSD3lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnabla-ext-cuda116"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ef69qbZjGiG5",
        "outputId": "a04f1214-45cf-4c5e-c72c-aeda7ccb0e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnabla-ext-cuda116\n",
            "  Downloading nnabla_ext_cuda116-1.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nnabla-ext-cuda116) (75.1.0)\n",
            "Collecting nnabla==1.39.0 (from nnabla-ext-cuda116)\n",
            "  Downloading nnabla-1.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (3.0.11)\n",
            "Requirement already satisfied: numpy~=1.26.0 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (1.26.4)\n",
            "Collecting boto3 (from nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading boto3-1.35.90-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting configparser (from nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting contextlib2 (from nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (3.12.1)\n",
            "Collecting protobuf~=3.20 (from nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (4.67.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (2.36.1)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (11.0.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla-ext-cuda116) (2024.12.14)\n",
            "Collecting botocore<1.36.0,>=1.35.90 (from boto3->nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading botocore-1.35.90-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->nnabla==1.39.0->nnabla-ext-cuda116)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->nnabla==1.39.0->nnabla-ext-cuda116) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->nnabla==1.39.0->nnabla-ext-cuda116) (2.2.3)\n",
            "Downloading nnabla_ext_cuda116-1.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (108.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nnabla-1.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (18.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.7/18.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.90-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading botocore-1.35.90-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, jmespath, contextlib2, configparser, botocore, s3transfer, boto3, nnabla, nnabla-ext-cuda116\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.35.90 botocore-1.35.90 configparser-7.1.0 contextlib2-21.6.0 jmespath-1.0.1 nnabla-1.39.0 nnabla-ext-cuda116-1.39.0 protobuf-3.20.3 s3transfer-0.10.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports",
                  "google"
                ]
              },
              "id": "bcb31a521ffd4f28a69a291f056f1d1c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "こちらのトラブルシュートに従い、CUDAのツールキットを追加でインストールする  \n",
        "https://github.com/ai-forever/ghost/issues/87"
      ],
      "metadata": {
        "id": "EBKzeU3RON9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install nvidia-cuda-toolkit --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cwJ3ZfoOSfz",
        "outputId": "cbee616c-2d6b-453f-85ac-31e40fce3da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libaccinj64-11.5 libatk-wrapper-java libatk-wrapper-java-jni\n",
            "  libbabeltrace1 libcub-dev libcublas11 libcublaslt11 libcudart11.0 libcufft10 libcufftw10\n",
            "  libcuinj64-11.5 libcupti-dev libcupti-doc libcupti11.5 libcurand10 libcusolver11 libcusolvermg11\n",
            "  libcusparse11 libdebuginfod-common libdebuginfod1 libegl-dev libfontenc1 libgail-common libgail18\n",
            "  libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglvnd-core-dev libglvnd-dev libglx-dev\n",
            "  libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libipt2 libnppc11 libnppial11 libnppicc11 libnppidei11\n",
            "  libnppif11 libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11 libnpps11 libnvblas11\n",
            "  libnvidia-compute-495 libnvidia-compute-510 libnvidia-compute-535 libnvidia-ml-dev libnvjpeg11\n",
            "  libnvrtc-builtins11.5 libnvrtc11.2 libnvtoolsext1 libnvvm4 libopengl-dev librsvg2-common\n",
            "  libsource-highlight-common libsource-highlight4v5 libthrust-dev libvdpau-dev libxkbfile1 libxtst6\n",
            "  libxxf86dga1 node-html5shiv nvidia-cuda-dev nvidia-cuda-gdb nvidia-cuda-toolkit-doc\n",
            "  nvidia-profiler nvidia-visual-profiler openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libvdpau-doc nodejs libnss-mdns fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "Recommended packages:\n",
            "  libnvcuvid1 nsight-compute nsight-systems\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libaccinj64-11.5 libatk-wrapper-java libatk-wrapper-java-jni\n",
            "  libbabeltrace1 libcub-dev libcublas11 libcublaslt11 libcudart11.0 libcufft10 libcufftw10\n",
            "  libcuinj64-11.5 libcupti-dev libcupti-doc libcupti11.5 libcurand10 libcusolver11 libcusolvermg11\n",
            "  libcusparse11 libdebuginfod-common libdebuginfod1 libegl-dev libfontenc1 libgail-common libgail18\n",
            "  libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglvnd-core-dev libglvnd-dev libglx-dev\n",
            "  libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libipt2 libnppc11 libnppial11 libnppicc11 libnppidei11\n",
            "  libnppif11 libnppig11 libnppim11 libnppist11 libnppisu11 libnppitc11 libnpps11 libnvblas11\n",
            "  libnvidia-compute-495 libnvidia-compute-510 libnvidia-compute-535 libnvidia-ml-dev libnvjpeg11\n",
            "  libnvrtc-builtins11.5 libnvrtc11.2 libnvtoolsext1 libnvvm4 libopengl-dev librsvg2-common\n",
            "  libsource-highlight-common libsource-highlight4v5 libthrust-dev libvdpau-dev libxkbfile1 libxtst6\n",
            "  libxxf86dga1 node-html5shiv nvidia-cuda-dev nvidia-cuda-gdb nvidia-cuda-toolkit\n",
            "  nvidia-cuda-toolkit-doc nvidia-profiler nvidia-visual-profiler openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 77 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,540 MB of archives.\n",
            "After this operation, 4,234 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libnvidia-compute-535 535.216.03-0ubuntu1 [36.9 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti11.5 amd64 11.5.114~11.5.1-1ubuntu1 [7,696 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libaccinj64-11.5 amd64 11.5.114~11.5.1-1ubuntu1 [845 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcub-dev all 1.15.0-3 [217 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublaslt11 amd64 11.7.4.6~11.5.1-1ubuntu1 [148 MB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [78.2 MB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcudart11.0 amd64 11.5.117~11.5.1-1ubuntu1 [178 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcufft10 amd64 11.1.1+~10.6.0.107~11.5.1-1ubuntu1 [70.4 MB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcufftw10 amd64 11.1.1+~10.6.0.107~11.5.1-1ubuntu1 [211 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 libnvidia-compute-510 amd64 525.147.05-0ubuntu2.22.04.1 [7,310 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 libnvidia-compute-495 amd64 510.108.03-0ubuntu0.22.04.1 [7,378 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcuinj64-11.5 amd64 11.5.114~11.5.1-1ubuntu1 [1,004 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcurand10 amd64 11.1.1+~10.2.7.107~11.5.1-1ubuntu1 [41.8 MB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusolver11 amd64 11.3.2.107~11.5.1-1ubuntu1 [31.3 MB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusolvermg11 amd64 11.3.2.107~11.5.1-1ubuntu1 [17.8 MB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusparse11 amd64 11.7.0.107~11.5.1-1ubuntu1 [96.2 MB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [430 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppial11 amd64 11.5.1.107~11.5.1-1ubuntu1 [5,234 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppicc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [2,373 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppidei11 amd64 11.5.1.107~11.5.1-1ubuntu1 [2,587 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppif11 amd64 11.5.1.107~11.5.1-1ubuntu1 [33.8 MB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppig11 amd64 11.5.1.107~11.5.1-1ubuntu1 [14.5 MB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppim11 amd64 11.5.1.107~11.5.1-1ubuntu1 [3,037 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppist11 amd64 11.5.1.107~11.5.1-1ubuntu1 [13.7 MB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppisu11 amd64 11.5.1.107~11.5.1-1ubuntu1 [177 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnppitc11 amd64 11.5.1.107~11.5.1-1ubuntu1 [1,292 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnpps11 amd64 11.5.1.107~11.5.1-1ubuntu1 [7,116 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvblas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [191 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvidia-ml-dev amd64 11.5.50~11.5.1-1ubuntu1 [69.1 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvjpeg11 amd64 11.5.4.107~11.5.1-1ubuntu1 [1,858 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvrtc-builtins11.5 amd64 11.5.119~11.5.1-1ubuntu1 [116 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvrtc11.2 amd64 11.5.119~11.5.1-1ubuntu1 [15.7 MB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvvm4 amd64 11.5.119~11.5.1-1ubuntu1 [8,675 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvdpau-dev amd64 1.4-3build2 [38.7 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-html5shiv all 3.7.3+dfsg-4 [13.6 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-toolkit-doc all 11.5.1-1ubuntu1 [6,263 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u432-ga~us1-0ubuntu2~22.04 [30.8 MB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u432-ga~us1-0ubuntu2~22.04 [75.3 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti-dev amd64 11.5.114~11.5.1-1ubuntu1 [7,915 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcupti-doc all 11.5.114~11.5.1-1ubuntu1 [2,373 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.3 [6,848 B]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libnvtoolsext1 amd64 11.5.114~11.5.1-1ubuntu1 [28.8 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libthrust-dev all 1.15.0-1 [423 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-dev amd64 11.5.1-1ubuntu1 [667 MB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-gdb amd64 11.5.114~11.5.1-1ubuntu1 [3,404 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-profiler amd64 11.5.114~11.5.1-1ubuntu1 [1,732 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-cuda-toolkit amd64 11.5.1-1ubuntu1 [62.8 MB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 nvidia-visual-profiler amd64 11.5.114~11.5.1-1ubuntu1 [108 MB]\n",
            "Fetched 1,540 MB in 22s (69.0 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libdebuginfod-common.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdebuginfod-common_0.186-1build1_all.deb ...\n",
            "Unpacking libdebuginfod-common (0.186-1build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libcupti11.5:amd64.\n",
            "Preparing to unpack .../03-libcupti11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcupti11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libaccinj64-11.5:amd64.\n",
            "Preparing to unpack .../04-libaccinj64-11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libaccinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../05-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../06-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../07-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../08-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../09-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../10-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../11-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libcub-dev.\n",
            "Preparing to unpack .../12-libcub-dev_1.15.0-3_all.deb ...\n",
            "Unpacking libcub-dev (1.15.0-3) ...\n",
            "Selecting previously unselected package libcublaslt11:amd64.\n",
            "Preparing to unpack .../13-libcublaslt11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcublas11:amd64.\n",
            "Preparing to unpack .../14-libcublas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcudart11.0:amd64.\n",
            "Preparing to unpack .../15-libcudart11.0_11.5.117~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcudart11.0:amd64 (11.5.117~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcufft10:amd64.\n",
            "Preparing to unpack .../16-libcufft10_11.1.1+~10.6.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcufft10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcufftw10:amd64.\n",
            "Preparing to unpack .../17-libcufftw10_11.1.1+~10.6.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcufftw10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-535:amd64.\n",
            "Preparing to unpack .../18-libnvidia-compute-535_535.216.03-0ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-535:amd64 (535.216.03-0ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-compute-510:amd64.\n",
            "Preparing to unpack .../19-libnvidia-compute-510_525.147.05-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-510:amd64 (525.147.05-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package libnvidia-compute-495:amd64.\n",
            "Preparing to unpack .../20-libnvidia-compute-495_510.108.03-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libnvidia-compute-495:amd64 (510.108.03-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libcuinj64-11.5:amd64.\n",
            "Preparing to unpack .../21-libcuinj64-11.5_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcuinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcurand10:amd64.\n",
            "Preparing to unpack .../22-libcurand10_11.1.1+~10.2.7.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcurand10:amd64 (11.1.1+~10.2.7.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusolver11:amd64.\n",
            "Preparing to unpack .../23-libcusolver11_11.3.2.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusolvermg11:amd64.\n",
            "Preparing to unpack .../24-libcusolvermg11_11.3.2.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolvermg11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusparse11:amd64.\n",
            "Preparing to unpack .../25-libcusparse11_11.7.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libdebuginfod1:amd64.\n",
            "Preparing to unpack .../26-libdebuginfod1_0.186-1build1_amd64.deb ...\n",
            "Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../27-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../28-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../29-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../30-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../31-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../32-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../33-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../34-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../35-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../36-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libipt2.\n",
            "Preparing to unpack .../37-libipt2_2.0.5-1_amd64.deb ...\n",
            "Unpacking libipt2 (2.0.5-1) ...\n",
            "Selecting previously unselected package libnppc11:amd64.\n",
            "Preparing to unpack .../38-libnppc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppial11:amd64.\n",
            "Preparing to unpack .../39-libnppial11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppial11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppicc11:amd64.\n",
            "Preparing to unpack .../40-libnppicc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppicc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppidei11:amd64.\n",
            "Preparing to unpack .../41-libnppidei11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppidei11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppif11:amd64.\n",
            "Preparing to unpack .../42-libnppif11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppif11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppig11:amd64.\n",
            "Preparing to unpack .../43-libnppig11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppig11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppim11:amd64.\n",
            "Preparing to unpack .../44-libnppim11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppim11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppist11:amd64.\n",
            "Preparing to unpack .../45-libnppist11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppist11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppisu11:amd64.\n",
            "Preparing to unpack .../46-libnppisu11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppisu11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnppitc11:amd64.\n",
            "Preparing to unpack .../47-libnppitc11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnppitc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnpps11:amd64.\n",
            "Preparing to unpack .../48-libnpps11_11.5.1.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnpps11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvblas11:amd64.\n",
            "Preparing to unpack .../49-libnvblas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvblas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvidia-ml-dev:amd64.\n",
            "Preparing to unpack .../50-libnvidia-ml-dev_11.5.50~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvidia-ml-dev:amd64 (11.5.50~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvjpeg11:amd64.\n",
            "Preparing to unpack .../51-libnvjpeg11_11.5.4.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvjpeg11:amd64 (11.5.4.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvrtc-builtins11.5:amd64.\n",
            "Preparing to unpack .../52-libnvrtc-builtins11.5_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvrtc-builtins11.5:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvrtc11.2:amd64.\n",
            "Preparing to unpack .../53-libnvrtc11.2_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvrtc11.2:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libnvvm4:amd64.\n",
            "Preparing to unpack .../54-libnvvm4_11.5.119~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvvm4:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../55-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../56-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsource-highlight-common.\n",
            "Preparing to unpack .../57-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n",
            "Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libsource-highlight4v5.\n",
            "Preparing to unpack .../58-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n",
            "Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Selecting previously unselected package libvdpau-dev:amd64.\n",
            "Preparing to unpack .../59-libvdpau-dev_1.4-3build2_amd64.deb ...\n",
            "Unpacking libvdpau-dev:amd64 (1.4-3build2) ...\n",
            "Selecting previously unselected package node-html5shiv.\n",
            "Preparing to unpack .../60-node-html5shiv_3.7.3+dfsg-4_all.deb ...\n",
            "Unpacking node-html5shiv (3.7.3+dfsg-4) ...\n",
            "Selecting previously unselected package nvidia-cuda-toolkit-doc.\n",
            "Preparing to unpack .../61-nvidia-cuda-toolkit-doc_11.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking nvidia-cuda-toolkit-doc (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../62-openjdk-8-jre-headless_8u432-ga~us1-0ubuntu2~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../63-openjdk-8-jre_8u432-ga~us1-0ubuntu2~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "Selecting previously unselected package libbabeltrace1:amd64.\n",
            "Preparing to unpack .../64-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n",
            "Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Selecting previously unselected package libcupti-dev:amd64.\n",
            "Preparing to unpack .../65-libcupti-dev_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcupti-dev:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcupti-doc.\n",
            "Preparing to unpack .../66-libcupti-doc_11.5.114~11.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking libcupti-doc (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../67-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../68-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../69-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Selecting previously unselected package libnvtoolsext1:amd64.\n",
            "Preparing to unpack .../70-libnvtoolsext1_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnvtoolsext1:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libthrust-dev.\n",
            "Preparing to unpack .../71-libthrust-dev_1.15.0-1_all.deb ...\n",
            "Unpacking libthrust-dev (1.15.0-1) ...\n",
            "Selecting previously unselected package nvidia-cuda-dev:amd64.\n",
            "Preparing to unpack .../72-nvidia-cuda-dev_11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-dev:amd64 (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-gdb.\n",
            "Preparing to unpack .../73-nvidia-cuda-gdb_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-gdb (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-profiler.\n",
            "Preparing to unpack .../74-nvidia-profiler_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-cuda-toolkit.\n",
            "Preparing to unpack .../75-nvidia-cuda-toolkit_11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-cuda-toolkit (11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package nvidia-visual-profiler.\n",
            "Preparing to unpack .../76-nvidia-visual-profiler_11.5.114~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking nvidia-visual-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libdebuginfod-common (0.186-1build1) ...\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.sh with new version\n",
            "\n",
            "Creating config file /etc/profile.d/debuginfod.csh with new version\n",
            "Setting up libnppc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n",
            "Setting up node-html5shiv (3.7.3+dfsg-4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libcupti-doc (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n",
            "Setting up libcudart11.0:amd64 (11.5.117~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppisu11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppicc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvjpeg11:amd64 (11.5.4.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up libcupti11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up libipt2 (2.0.5-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n",
            "Setting up libnpps11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppim11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcufft10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libnppitc11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppist11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libnvidia-compute-535:amd64 (535.216.03-0ubuntu1) ...\n",
            "Setting up libnvvm4:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up libvdpau-dev:amd64 (1.4-3build2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libnvtoolsext1:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libcub-dev (1.15.0-3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up nvidia-cuda-toolkit-doc (11.5.1-1ubuntu1) ...\n",
            "Setting up libaccinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppig11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libcurand10:amd64 (11.1.1+~10.2.7.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n",
            "Setting up libnvrtc-builtins11.5:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppidei11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libthrust-dev (1.15.0-1) ...\n",
            "Setting up libnppial11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnppif11:amd64 (11.5.1.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcufftw10:amd64 (11.1.1+~10.6.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-cuda-gdb (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libnvidia-compute-510:amd64 (525.147.05-0ubuntu2.22.04.1) ...\n",
            "Setting up libcupti-dev:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-compute-495:amd64 (510.108.03-0ubuntu0.22.04.1) ...\n",
            "Setting up libnvblas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvrtc11.2:amd64 (11.5.119~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusolvermg11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libcuinj64-11.5:amd64 (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up libnvidia-ml-dev:amd64 (11.5.50~11.5.1-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up nvidia-cuda-dev:amd64 (11.5.1-1ubuntu1) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up nvidia-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Setting up nvidia-cuda-toolkit (11.5.1-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u432-ga~us1-0ubuntu2~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up nvidia-visual-profiler (11.5.114~11.5.1-1ubuntu1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "インストールできたか確認。以下が出ればOK。  \n",
        "Initializing CPU extension...  \n",
        "Initializing CUDA extension...  \n",
        "Initializing cuDNN extension...  \n"
      ],
      "metadata": {
        "id": "05fDib9fO-2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import nnabla_ext.cuda, nnabla_ext.cudnn\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeMMBzMwO4Of",
        "outputId": "4c6fbc65-f832-4526-82a8-4d7464976068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 02:25:28,973 [nnabla][INFO]: Initializing CPU extension...\n",
            "2024-12-29 02:25:30,250 [nnabla][INFO]: Initializing CUDA extension...\n",
            "2024-12-29 02:25:30,323 [nnabla][INFO]: Initializing cuDNN extension...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nnablaのサンプル群をGitHubから取得。"
      ],
      "metadata": {
        "id": "nCYTRdT5D6Aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBnv_Ye6GTYm",
        "outputId": "53554582-d7d1-49cc-b931-52b61e277630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nnabla-examples'...\n",
            "remote: Enumerating objects: 9648, done.\u001b[K\n",
            "remote: Counting objects: 100% (2206/2206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (916/916), done.\u001b[K\n",
            "remote: Total 9648 (delta 1291), reused 2077 (delta 1230), pack-reused 7442 (from 1)\u001b[K\n",
            "Receiving objects: 100% (9648/9648), 298.96 MiB | 34.66 MiB/s, done.\n",
            "Resolving deltas: 100% (5255/5255), done.\n",
            "Updating files: 100% (1711/1711), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sony/nnabla-examples.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "本ブログで公開しているデータセットやプログラムをGitHubから取得。"
      ],
      "metadata": {
        "id": "UgWFw-HwT2o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ronron-gh/ESP32_EdgeAI_PlatformIO.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecF5PgfsUl0b",
        "outputId": "b915afa5-c6d5-415b-ccca-6813ff97959f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ESP32_EdgeAI_PlatformIO'...\n",
            "remote: Enumerating objects: 751, done.\u001b[K\n",
            "remote: Counting objects: 100% (751/751), done.\u001b[K\n",
            "remote: Compressing objects: 100% (676/676), done.\u001b[K\n",
            "remote: Total 751 (delta 72), reused 740 (delta 68), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (751/751), 2.46 MiB | 29.64 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ESP32_EdgeAI_PlatformIO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-iBemakaxJw",
        "outputId": "413697e6-509b-491b-b923-0e4f27ba72cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ESP32_EdgeAI_PlatformIO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データセットをnnablaに読み込ませるためのリストファイル(train.csv, test.csv)を作成する。画像は28x28のモノクロに変換する。（CSVの作成と画像の変換を行うPythonスクリプトを用意しました。）"
      ],
      "metadata": {
        "id": "fq9sNf-7a3qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python make_dataset_csv.py my_dataset/finger_direction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8we8BQekb6gN",
        "outputId": "fda7502d-1f09-48ab-fc58-8f78da23f2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current folder is my_dataset/finger_direction\n",
            "The current folder is my_dataset/finger_direction/3\n",
            "listed file : my_dataset/finger_direction/3/0014.jpg\n",
            "listed file : my_dataset/finger_direction/3/0027.jpg\n",
            "listed file : my_dataset/finger_direction/3/0032.jpg\n",
            "listed file : my_dataset/finger_direction/3/0025.jpg\n",
            "listed file : my_dataset/finger_direction/3/0035.jpg\n",
            "listed file : my_dataset/finger_direction/3/0060.jpg\n",
            "listed file : my_dataset/finger_direction/3/0047.jpg\n",
            "listed file : my_dataset/finger_direction/3/0069.jpg\n",
            "listed file : my_dataset/finger_direction/3/0036.jpg\n",
            "listed file : my_dataset/finger_direction/3/0011.jpg\n",
            "listed file : my_dataset/finger_direction/3/0033.jpg\n",
            "listed file : my_dataset/finger_direction/3/0064.jpg\n",
            "listed file : my_dataset/finger_direction/3/0034.jpg\n",
            "listed file : my_dataset/finger_direction/3/0055.jpg\n",
            "listed file : my_dataset/finger_direction/3/0067.jpg\n",
            "listed file : my_dataset/finger_direction/3/0063.jpg\n",
            "listed file : my_dataset/finger_direction/3/0040.jpg\n",
            "listed file : my_dataset/finger_direction/3/0030.jpg\n",
            "listed file : my_dataset/finger_direction/3/0007.jpg\n",
            "listed file : my_dataset/finger_direction/3/0013.jpg\n",
            "listed file : my_dataset/finger_direction/3/0016.jpg\n",
            "listed file : my_dataset/finger_direction/3/0018.jpg\n",
            "listed file : my_dataset/finger_direction/3/0066.jpg\n",
            "listed file : my_dataset/finger_direction/3/0049.jpg\n",
            "listed file : my_dataset/finger_direction/3/0028.jpg\n",
            "listed file : my_dataset/finger_direction/3/0041.jpg\n",
            "listed file : my_dataset/finger_direction/3/0062.jpg\n",
            "listed file : my_dataset/finger_direction/3/0053.jpg\n",
            "listed file : my_dataset/finger_direction/3/0068.jpg\n",
            "listed file : my_dataset/finger_direction/3/0052.jpg\n",
            "listed file : my_dataset/finger_direction/3/0065.jpg\n",
            "listed file : my_dataset/finger_direction/3/0022.jpg\n",
            "listed file : my_dataset/finger_direction/3/0061.jpg\n",
            "listed file : my_dataset/finger_direction/3/0039.jpg\n",
            "listed file : my_dataset/finger_direction/3/0048.jpg\n",
            "listed file : my_dataset/finger_direction/3/0021.jpg\n",
            "listed file : my_dataset/finger_direction/3/0050.jpg\n",
            "listed file : my_dataset/finger_direction/3/0057.jpg\n",
            "listed file : my_dataset/finger_direction/3/0029.jpg\n",
            "listed file : my_dataset/finger_direction/3/0009.jpg\n",
            "listed file : my_dataset/finger_direction/3/0070.jpg\n",
            "listed file : my_dataset/finger_direction/3/0059.jpg\n",
            "listed file : my_dataset/finger_direction/3/0024.jpg\n",
            "listed file : my_dataset/finger_direction/3/0012.jpg\n",
            "listed file : my_dataset/finger_direction/3/0058.jpg\n",
            "listed file : my_dataset/finger_direction/3/0038.jpg\n",
            "listed file : my_dataset/finger_direction/3/0051.jpg\n",
            "listed file : my_dataset/finger_direction/3/0071.jpg\n",
            "listed file : my_dataset/finger_direction/3/0026.jpg\n",
            "listed file : my_dataset/finger_direction/3/0020.jpg\n",
            "listed file : my_dataset/finger_direction/3/0019.jpg\n",
            "listed file : my_dataset/finger_direction/3/0023.jpg\n",
            "listed file : my_dataset/finger_direction/3/0006.jpg\n",
            "listed file : my_dataset/finger_direction/3/0017.jpg\n",
            "listed file : my_dataset/finger_direction/3/0054.jpg\n",
            "listed file : my_dataset/finger_direction/3/0015.jpg\n",
            "listed file : my_dataset/finger_direction/3/0037.jpg\n",
            "listed file : my_dataset/finger_direction/3/0008.jpg\n",
            "listed file : my_dataset/finger_direction/3/0010.jpg\n",
            "listed file : my_dataset/finger_direction/3/0031.jpg\n",
            "listed file : my_dataset/finger_direction/3/0056.jpg\n",
            "The current folder is my_dataset/finger_direction/4\n",
            "listed file : my_dataset/finger_direction/4/0014.jpg\n",
            "listed file : my_dataset/finger_direction/4/0027.jpg\n",
            "listed file : my_dataset/finger_direction/4/0032.jpg\n",
            "listed file : my_dataset/finger_direction/4/0025.jpg\n",
            "listed file : my_dataset/finger_direction/4/0035.jpg\n",
            "listed file : my_dataset/finger_direction/4/0060.jpg\n",
            "listed file : my_dataset/finger_direction/4/0047.jpg\n",
            "listed file : my_dataset/finger_direction/4/0069.jpg\n",
            "listed file : my_dataset/finger_direction/4/0036.jpg\n",
            "listed file : my_dataset/finger_direction/4/0033.jpg\n",
            "listed file : my_dataset/finger_direction/4/0064.jpg\n",
            "listed file : my_dataset/finger_direction/4/0034.jpg\n",
            "listed file : my_dataset/finger_direction/4/0055.jpg\n",
            "listed file : my_dataset/finger_direction/4/0067.jpg\n",
            "listed file : my_dataset/finger_direction/4/0063.jpg\n",
            "listed file : my_dataset/finger_direction/4/0040.jpg\n",
            "listed file : my_dataset/finger_direction/4/0084.jpg\n",
            "listed file : my_dataset/finger_direction/4/0013.jpg\n",
            "listed file : my_dataset/finger_direction/4/0016.jpg\n",
            "listed file : my_dataset/finger_direction/4/0018.jpg\n",
            "listed file : my_dataset/finger_direction/4/0082.jpg\n",
            "listed file : my_dataset/finger_direction/4/0066.jpg\n",
            "listed file : my_dataset/finger_direction/4/0049.jpg\n",
            "listed file : my_dataset/finger_direction/4/0088.jpg\n",
            "listed file : my_dataset/finger_direction/4/0028.jpg\n",
            "listed file : my_dataset/finger_direction/4/0078.jpg\n",
            "listed file : my_dataset/finger_direction/4/0041.jpg\n",
            "listed file : my_dataset/finger_direction/4/0062.jpg\n",
            "listed file : my_dataset/finger_direction/4/0053.jpg\n",
            "listed file : my_dataset/finger_direction/4/0068.jpg\n",
            "listed file : my_dataset/finger_direction/4/0052.jpg\n",
            "listed file : my_dataset/finger_direction/4/0065.jpg\n",
            "listed file : my_dataset/finger_direction/4/0081.jpg\n",
            "listed file : my_dataset/finger_direction/4/0022.jpg\n",
            "listed file : my_dataset/finger_direction/4/0080.jpg\n",
            "listed file : my_dataset/finger_direction/4/0061.jpg\n",
            "listed file : my_dataset/finger_direction/4/0039.jpg\n",
            "listed file : my_dataset/finger_direction/4/0048.jpg\n",
            "listed file : my_dataset/finger_direction/4/0021.jpg\n",
            "listed file : my_dataset/finger_direction/4/0046.jpg\n",
            "listed file : my_dataset/finger_direction/4/0050.jpg\n",
            "listed file : my_dataset/finger_direction/4/0083.jpg\n",
            "listed file : my_dataset/finger_direction/4/0057.jpg\n",
            "listed file : my_dataset/finger_direction/4/0029.jpg\n",
            "listed file : my_dataset/finger_direction/4/0070.jpg\n",
            "listed file : my_dataset/finger_direction/4/0024.jpg\n",
            "listed file : my_dataset/finger_direction/4/0038.jpg\n",
            "listed file : my_dataset/finger_direction/4/0051.jpg\n",
            "listed file : my_dataset/finger_direction/4/0071.jpg\n",
            "listed file : my_dataset/finger_direction/4/0026.jpg\n",
            "listed file : my_dataset/finger_direction/4/0085.jpg\n",
            "listed file : my_dataset/finger_direction/4/0020.jpg\n",
            "listed file : my_dataset/finger_direction/4/0023.jpg\n",
            "listed file : my_dataset/finger_direction/4/0017.jpg\n",
            "listed file : my_dataset/finger_direction/4/0054.jpg\n",
            "listed file : my_dataset/finger_direction/4/0015.jpg\n",
            "listed file : my_dataset/finger_direction/4/0037.jpg\n",
            "listed file : my_dataset/finger_direction/4/0087.jpg\n",
            "listed file : my_dataset/finger_direction/4/0079.jpg\n",
            "listed file : my_dataset/finger_direction/4/0077.jpg\n",
            "listed file : my_dataset/finger_direction/4/0086.jpg\n",
            "listed file : my_dataset/finger_direction/4/0056.jpg\n",
            "The current folder is my_dataset/finger_direction/1\n",
            "listed file : my_dataset/finger_direction/1/0014.jpg\n",
            "listed file : my_dataset/finger_direction/1/0027.jpg\n",
            "listed file : my_dataset/finger_direction/1/0032.jpg\n",
            "listed file : my_dataset/finger_direction/1/0025.jpg\n",
            "listed file : my_dataset/finger_direction/1/0043.jpg\n",
            "listed file : my_dataset/finger_direction/1/0035.jpg\n",
            "listed file : my_dataset/finger_direction/1/0047.jpg\n",
            "listed file : my_dataset/finger_direction/1/0036.jpg\n",
            "listed file : my_dataset/finger_direction/1/0011.jpg\n",
            "listed file : my_dataset/finger_direction/1/0045.jpg\n",
            "listed file : my_dataset/finger_direction/1/0033.jpg\n",
            "listed file : my_dataset/finger_direction/1/0034.jpg\n",
            "listed file : my_dataset/finger_direction/1/0055.jpg\n",
            "listed file : my_dataset/finger_direction/1/0044.jpg\n",
            "listed file : my_dataset/finger_direction/1/0040.jpg\n",
            "listed file : my_dataset/finger_direction/1/0030.jpg\n",
            "listed file : my_dataset/finger_direction/1/0042.jpg\n",
            "listed file : my_dataset/finger_direction/1/0007.jpg\n",
            "listed file : my_dataset/finger_direction/1/0013.jpg\n",
            "listed file : my_dataset/finger_direction/1/0016.jpg\n",
            "listed file : my_dataset/finger_direction/1/0018.jpg\n",
            "listed file : my_dataset/finger_direction/1/0049.jpg\n",
            "listed file : my_dataset/finger_direction/1/0028.jpg\n",
            "listed file : my_dataset/finger_direction/1/0041.jpg\n",
            "listed file : my_dataset/finger_direction/1/0053.jpg\n",
            "listed file : my_dataset/finger_direction/1/0052.jpg\n",
            "listed file : my_dataset/finger_direction/1/0022.jpg\n",
            "listed file : my_dataset/finger_direction/1/0039.jpg\n",
            "listed file : my_dataset/finger_direction/1/0048.jpg\n",
            "listed file : my_dataset/finger_direction/1/0021.jpg\n",
            "listed file : my_dataset/finger_direction/1/0046.jpg\n",
            "listed file : my_dataset/finger_direction/1/0050.jpg\n",
            "listed file : my_dataset/finger_direction/1/0029.jpg\n",
            "listed file : my_dataset/finger_direction/1/0009.jpg\n",
            "listed file : my_dataset/finger_direction/1/0024.jpg\n",
            "listed file : my_dataset/finger_direction/1/0012.jpg\n",
            "listed file : my_dataset/finger_direction/1/0038.jpg\n",
            "listed file : my_dataset/finger_direction/1/0051.jpg\n",
            "listed file : my_dataset/finger_direction/1/0026.jpg\n",
            "listed file : my_dataset/finger_direction/1/0020.jpg\n",
            "listed file : my_dataset/finger_direction/1/0019.jpg\n",
            "listed file : my_dataset/finger_direction/1/0023.jpg\n",
            "listed file : my_dataset/finger_direction/1/0006.jpg\n",
            "listed file : my_dataset/finger_direction/1/0017.jpg\n",
            "listed file : my_dataset/finger_direction/1/0054.jpg\n",
            "listed file : my_dataset/finger_direction/1/0015.jpg\n",
            "listed file : my_dataset/finger_direction/1/0037.jpg\n",
            "listed file : my_dataset/finger_direction/1/0008.jpg\n",
            "listed file : my_dataset/finger_direction/1/0010.jpg\n",
            "listed file : my_dataset/finger_direction/1/0031.jpg\n",
            "listed file : my_dataset/finger_direction/1/0005.jpg\n",
            "listed file : my_dataset/finger_direction/1/0056.jpg\n",
            "The current folder is my_dataset/finger_direction/2\n",
            "listed file : my_dataset/finger_direction/2/0014.jpg\n",
            "listed file : my_dataset/finger_direction/2/0027.jpg\n",
            "listed file : my_dataset/finger_direction/2/0032.jpg\n",
            "listed file : my_dataset/finger_direction/2/0025.jpg\n",
            "listed file : my_dataset/finger_direction/2/0043.jpg\n",
            "listed file : my_dataset/finger_direction/2/0035.jpg\n",
            "listed file : my_dataset/finger_direction/2/0036.jpg\n",
            "listed file : my_dataset/finger_direction/2/0011.jpg\n",
            "listed file : my_dataset/finger_direction/2/0045.jpg\n",
            "listed file : my_dataset/finger_direction/2/0033.jpg\n",
            "listed file : my_dataset/finger_direction/2/0034.jpg\n",
            "listed file : my_dataset/finger_direction/2/0044.jpg\n",
            "listed file : my_dataset/finger_direction/2/0040.jpg\n",
            "listed file : my_dataset/finger_direction/2/0030.jpg\n",
            "listed file : my_dataset/finger_direction/2/0042.jpg\n",
            "listed file : my_dataset/finger_direction/2/0007.jpg\n",
            "listed file : my_dataset/finger_direction/2/0013.jpg\n",
            "listed file : my_dataset/finger_direction/2/0016.jpg\n",
            "listed file : my_dataset/finger_direction/2/0018.jpg\n",
            "listed file : my_dataset/finger_direction/2/0028.jpg\n",
            "listed file : my_dataset/finger_direction/2/0041.jpg\n",
            "listed file : my_dataset/finger_direction/2/0022.jpg\n",
            "listed file : my_dataset/finger_direction/2/0039.jpg\n",
            "listed file : my_dataset/finger_direction/2/0021.jpg\n",
            "listed file : my_dataset/finger_direction/2/0029.jpg\n",
            "listed file : my_dataset/finger_direction/2/0009.jpg\n",
            "listed file : my_dataset/finger_direction/2/0024.jpg\n",
            "listed file : my_dataset/finger_direction/2/0012.jpg\n",
            "listed file : my_dataset/finger_direction/2/0038.jpg\n",
            "listed file : my_dataset/finger_direction/2/0026.jpg\n",
            "listed file : my_dataset/finger_direction/2/0020.jpg\n",
            "listed file : my_dataset/finger_direction/2/0019.jpg\n",
            "listed file : my_dataset/finger_direction/2/0023.jpg\n",
            "listed file : my_dataset/finger_direction/2/0006.jpg\n",
            "listed file : my_dataset/finger_direction/2/0017.jpg\n",
            "listed file : my_dataset/finger_direction/2/0015.jpg\n",
            "listed file : my_dataset/finger_direction/2/0037.jpg\n",
            "listed file : my_dataset/finger_direction/2/0008.jpg\n",
            "listed file : my_dataset/finger_direction/2/0010.jpg\n",
            "listed file : my_dataset/finger_direction/2/0031.jpg\n",
            "listed file : my_dataset/finger_direction/2/0005.jpg\n",
            "The current folder is my_dataset/finger_direction/0\n",
            "listed file : my_dataset/finger_direction/0/0014.jpg\n",
            "listed file : my_dataset/finger_direction/0/0027.jpg\n",
            "listed file : my_dataset/finger_direction/0/0032.jpg\n",
            "listed file : my_dataset/finger_direction/0/0025.jpg\n",
            "listed file : my_dataset/finger_direction/0/0043.jpg\n",
            "listed file : my_dataset/finger_direction/0/0035.jpg\n",
            "listed file : my_dataset/finger_direction/0/0060.jpg\n",
            "listed file : my_dataset/finger_direction/0/0047.jpg\n",
            "listed file : my_dataset/finger_direction/0/0069.jpg\n",
            "listed file : my_dataset/finger_direction/0/0036.jpg\n",
            "listed file : my_dataset/finger_direction/0/0011.jpg\n",
            "listed file : my_dataset/finger_direction/0/0000.jpg\n",
            "listed file : my_dataset/finger_direction/0/0045.jpg\n",
            "listed file : my_dataset/finger_direction/0/0033.jpg\n",
            "listed file : my_dataset/finger_direction/0/0072.jpg\n",
            "listed file : my_dataset/finger_direction/0/0064.jpg\n",
            "listed file : my_dataset/finger_direction/0/0034.jpg\n",
            "listed file : my_dataset/finger_direction/0/0055.jpg\n",
            "listed file : my_dataset/finger_direction/0/0044.jpg\n",
            "listed file : my_dataset/finger_direction/0/0067.jpg\n",
            "listed file : my_dataset/finger_direction/0/0074.jpg\n",
            "listed file : my_dataset/finger_direction/0/0063.jpg\n",
            "listed file : my_dataset/finger_direction/0/0040.jpg\n",
            "listed file : my_dataset/finger_direction/0/0030.jpg\n",
            "listed file : my_dataset/finger_direction/0/0042.jpg\n",
            "listed file : my_dataset/finger_direction/0/0084.jpg\n",
            "listed file : my_dataset/finger_direction/0/0007.jpg\n",
            "listed file : my_dataset/finger_direction/0/0013.jpg\n",
            "listed file : my_dataset/finger_direction/0/0016.jpg\n",
            "listed file : my_dataset/finger_direction/0/0018.jpg\n",
            "listed file : my_dataset/finger_direction/0/0082.jpg\n",
            "listed file : my_dataset/finger_direction/0/0004.jpg\n",
            "listed file : my_dataset/finger_direction/0/0066.jpg\n",
            "listed file : my_dataset/finger_direction/0/0049.jpg\n",
            "listed file : my_dataset/finger_direction/0/0088.jpg\n",
            "listed file : my_dataset/finger_direction/0/0028.jpg\n",
            "listed file : my_dataset/finger_direction/0/0001.jpg\n",
            "listed file : my_dataset/finger_direction/0/0078.jpg\n",
            "listed file : my_dataset/finger_direction/0/0041.jpg\n",
            "listed file : my_dataset/finger_direction/0/0062.jpg\n",
            "listed file : my_dataset/finger_direction/0/0053.jpg\n",
            "listed file : my_dataset/finger_direction/0/0073.jpg\n",
            "listed file : my_dataset/finger_direction/0/0068.jpg\n",
            "listed file : my_dataset/finger_direction/0/0052.jpg\n",
            "listed file : my_dataset/finger_direction/0/0090.jpg\n",
            "listed file : my_dataset/finger_direction/0/0065.jpg\n",
            "listed file : my_dataset/finger_direction/0/0081.jpg\n",
            "listed file : my_dataset/finger_direction/0/0022.jpg\n",
            "listed file : my_dataset/finger_direction/0/0080.jpg\n",
            "listed file : my_dataset/finger_direction/0/0003.jpg\n",
            "listed file : my_dataset/finger_direction/0/0061.jpg\n",
            "listed file : my_dataset/finger_direction/0/0039.jpg\n",
            "listed file : my_dataset/finger_direction/0/0048.jpg\n",
            "listed file : my_dataset/finger_direction/0/0021.jpg\n",
            "listed file : my_dataset/finger_direction/0/0046.jpg\n",
            "listed file : my_dataset/finger_direction/0/0050.jpg\n",
            "listed file : my_dataset/finger_direction/0/0075.jpg\n",
            "listed file : my_dataset/finger_direction/0/0083.jpg\n",
            "listed file : my_dataset/finger_direction/0/0057.jpg\n",
            "listed file : my_dataset/finger_direction/0/0002.jpg\n",
            "listed file : my_dataset/finger_direction/0/0029.jpg\n",
            "listed file : my_dataset/finger_direction/0/0009.jpg\n",
            "listed file : my_dataset/finger_direction/0/0070.jpg\n",
            "listed file : my_dataset/finger_direction/0/0059.jpg\n",
            "listed file : my_dataset/finger_direction/0/0024.jpg\n",
            "listed file : my_dataset/finger_direction/0/0012.jpg\n",
            "listed file : my_dataset/finger_direction/0/0058.jpg\n",
            "listed file : my_dataset/finger_direction/0/0038.jpg\n",
            "listed file : my_dataset/finger_direction/0/0051.jpg\n",
            "listed file : my_dataset/finger_direction/0/0071.jpg\n",
            "listed file : my_dataset/finger_direction/0/0026.jpg\n",
            "listed file : my_dataset/finger_direction/0/0085.jpg\n",
            "listed file : my_dataset/finger_direction/0/0020.jpg\n",
            "listed file : my_dataset/finger_direction/0/0089.jpg\n",
            "listed file : my_dataset/finger_direction/0/0019.jpg\n",
            "listed file : my_dataset/finger_direction/0/0023.jpg\n",
            "listed file : my_dataset/finger_direction/0/0006.jpg\n",
            "listed file : my_dataset/finger_direction/0/0017.jpg\n",
            "listed file : my_dataset/finger_direction/0/0054.jpg\n",
            "listed file : my_dataset/finger_direction/0/0015.jpg\n",
            "listed file : my_dataset/finger_direction/0/0092.jpg\n",
            "listed file : my_dataset/finger_direction/0/0037.jpg\n",
            "listed file : my_dataset/finger_direction/0/0087.jpg\n",
            "listed file : my_dataset/finger_direction/0/0076.jpg\n",
            "listed file : my_dataset/finger_direction/0/0008.jpg\n",
            "listed file : my_dataset/finger_direction/0/0079.jpg\n",
            "listed file : my_dataset/finger_direction/0/0077.jpg\n",
            "listed file : my_dataset/finger_direction/0/0091.jpg\n",
            "listed file : my_dataset/finger_direction/0/0086.jpg\n",
            "listed file : my_dataset/finger_direction/0/0010.jpg\n",
            "listed file : my_dataset/finger_direction/0/0031.jpg\n",
            "listed file : my_dataset/finger_direction/0/0005.jpg\n",
            "listed file : my_dataset/finger_direction/0/0056.jpg\n",
            "The current folder is my_dataset/finger_direction/5\n",
            "listed file : my_dataset/finger_direction/5/0014.jpg\n",
            "listed file : my_dataset/finger_direction/5/0027.jpg\n",
            "listed file : my_dataset/finger_direction/5/0032.jpg\n",
            "listed file : my_dataset/finger_direction/5/0025.jpg\n",
            "listed file : my_dataset/finger_direction/5/0035.jpg\n",
            "listed file : my_dataset/finger_direction/5/0036.jpg\n",
            "listed file : my_dataset/finger_direction/5/0129.jpg\n",
            "listed file : my_dataset/finger_direction/5/0011.jpg\n",
            "listed file : my_dataset/finger_direction/5/0126.jpg\n",
            "listed file : my_dataset/finger_direction/5/0033.jpg\n",
            "listed file : my_dataset/finger_direction/5/0130.jpg\n",
            "listed file : my_dataset/finger_direction/5/0034.jpg\n",
            "listed file : my_dataset/finger_direction/5/0115.jpg\n",
            "listed file : my_dataset/finger_direction/5/0121.jpg\n",
            "listed file : my_dataset/finger_direction/5/0040.jpg\n",
            "listed file : my_dataset/finger_direction/5/0030.jpg\n",
            "listed file : my_dataset/finger_direction/5/0013.jpg\n",
            "listed file : my_dataset/finger_direction/5/0016.jpg\n",
            "listed file : my_dataset/finger_direction/5/0018.jpg\n",
            "listed file : my_dataset/finger_direction/5/0125.jpg\n",
            "listed file : my_dataset/finger_direction/5/0028.jpg\n",
            "listed file : my_dataset/finger_direction/5/0022.jpg\n",
            "listed file : my_dataset/finger_direction/5/0039.jpg\n",
            "listed file : my_dataset/finger_direction/5/0021.jpg\n",
            "listed file : my_dataset/finger_direction/5/0113.jpg\n",
            "listed file : my_dataset/finger_direction/5/0029.jpg\n",
            "listed file : my_dataset/finger_direction/5/0123.jpg\n",
            "listed file : my_dataset/finger_direction/5/0024.jpg\n",
            "listed file : my_dataset/finger_direction/5/0012.jpg\n",
            "listed file : my_dataset/finger_direction/5/0038.jpg\n",
            "listed file : my_dataset/finger_direction/5/0026.jpg\n",
            "listed file : my_dataset/finger_direction/5/0020.jpg\n",
            "listed file : my_dataset/finger_direction/5/0019.jpg\n",
            "listed file : my_dataset/finger_direction/5/0023.jpg\n",
            "listed file : my_dataset/finger_direction/5/0017.jpg\n",
            "listed file : my_dataset/finger_direction/5/0127.jpg\n",
            "listed file : my_dataset/finger_direction/5/0015.jpg\n",
            "listed file : my_dataset/finger_direction/5/0037.jpg\n",
            "listed file : my_dataset/finger_direction/5/0010.jpg\n",
            "listed file : my_dataset/finger_direction/5/0114.jpg\n",
            "listed file : my_dataset/finger_direction/5/0122.jpg\n",
            "listed file : my_dataset/finger_direction/5/0124.jpg\n",
            "listed file : my_dataset/finger_direction/5/0031.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.csv, test.csv, converted_datasetsフォルダが作成されていることを確認する。"
      ],
      "metadata": {
        "id": "4UvfZiD3NUCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2M39YKWNf3l",
        "outputId": "3fbbfbe5-5cd7-439e-cd03-59c1c1647882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converted_datasets   my_dataset\t\t\t\t\tnnabla-example-modify  test.csv\n",
            "LICENSE\t\t     nnabla_convert_mnist_model_to_csrc.ipynb\tPlatformio\t       train.csv\n",
            "make_dataset_csv.py  nnabla_convert_mydata_model_to_csrc.ipynb\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nnablaのMNISTサンプルコードのディレクトリに、作成したCSV、データセット（変換後）、改造したプログラムをコピー。"
      ],
      "metadata": {
        "id": "7KqdiU04owwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp *.csv ../nnabla-examples/image-classification/mnist-collection/"
      ],
      "metadata": {
        "id": "qLN_kW59pN7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r converted_datasets ../nnabla-examples/image-classification/mnist-collection/"
      ],
      "metadata": {
        "id": "2f-gxaINq_dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp nnabla-example-modify/classification_mydata.py ../nnabla-examples/image-classification/mnist-collection/"
      ],
      "metadata": {
        "id": "T58Z5AgTreIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mnistサンプルプログラムのフォルダに移動し、学習を実行。"
      ],
      "metadata": {
        "id": "loUVBhtMZ4IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../nnabla-examples/image-classification/mnist-collection/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yocj4nJVG-sF",
        "outputId": "c5407318-8122-4b19-8cf9-d8873b588c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnabla-examples/image-classification/mnist-collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classification_mydata.py -c cudnn -n lenet -o output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CTfat5XH3wl",
        "outputId": "724112c0-d79d-4659-dada-2e687ef648a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 02:29:22,095 [nnabla][INFO]: Initializing CPU extension...\n",
            "2024-12-29 02:29:23,122 [nnabla][INFO]: Running in cudnn\n",
            "2024-12-29 02:29:23,359 [nnabla][INFO]: Initializing CUDA extension...\n",
            "2024-12-29 02:29:23,395 [nnabla][INFO]: Initializing cuDNN extension...\n",
            "2024-12-29 02:29:26,503 [nnabla][INFO]: Saving output/lenet_result_epoch0.nnp as nnp\n",
            "2024-12-29 02:29:26,503 [nnabla][INFO]: Saving <_io.StringIO object at 0x79969834e050> as prototxt\n",
            "2024-12-29 02:29:26,510 [nnabla][INFO]: Parameter save (.h5): <_io.BytesIO object at 0x7996983b1080>\n",
            "2024-12-29 02:29:26,511 [nnabla][INFO]: Model file is saved as (.nnp): output/lenet_result_epoch0.nnp\n",
            "2024-12-29 02:29:26,511 [nnabla][INFO]: DataSource with shuffle(True)\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: Using DataSourceWithFileCache\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: DataSource with shuffle(True)\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: Cache Directory is None\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: Cache size is 100\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: Num of thread is 10\n",
            "2024-12-29 02:29:26,514 [nnabla][INFO]: Cache file format is .npy\n",
            "2024-12-29 02:29:26,515 [nnabla][INFO]: Tempdir for cache /tmp/tmpl7mkj5hq created.\n",
            "2024-12-29 02:29:26,587 [nnabla][INFO]: Creating cache file /tmp/tmpl7mkj5hq/cache_00000000_00000099.npy\n",
            "2024-12-29 02:29:26,640 [nnabla][INFO]: Creating cache file /tmp/tmpl7mkj5hq/cache_00000100_00000199.npy\n",
            "2024-12-29 02:29:26,683 [nnabla][INFO]: Creating cache file /tmp/tmpl7mkj5hq/cache_00000200_00000280.npy\n",
            "2024-12-29 02:29:26,685 [nnabla][INFO]: Using DataSourceWithMemoryCache\n",
            "2024-12-29 02:29:26,686 [nnabla][INFO]: DataSource with shuffle(True)\n",
            "2024-12-29 02:29:26,686 [nnabla][INFO]: On-memory\n",
            "2024-12-29 02:29:26,686 [nnabla][INFO]: Using DataIterator\n",
            "2024-12-29 02:29:26,687 [nnabla][INFO]: DataSource with shuffle(False)\n",
            "2024-12-29 02:29:26,688 [nnabla][INFO]: Using DataSourceWithFileCache\n",
            "2024-12-29 02:29:26,688 [nnabla][INFO]: DataSource with shuffle(False)\n",
            "2024-12-29 02:29:26,688 [nnabla][INFO]: Cache Directory is None\n",
            "2024-12-29 02:29:26,688 [nnabla][INFO]: Cache size is 100\n",
            "2024-12-29 02:29:26,689 [nnabla][INFO]: Num of thread is 10\n",
            "2024-12-29 02:29:26,689 [nnabla][INFO]: Cache file format is .npy\n",
            "2024-12-29 02:29:26,689 [nnabla][INFO]: Tempdir for cache /tmp/tmpulx_wvg5 created.\n",
            "2024-12-29 02:29:26,729 [nnabla][INFO]: Creating cache file /tmp/tmpulx_wvg5/cache_00000000_00000069.npy\n",
            "2024-12-29 02:29:26,731 [nnabla][INFO]: Using DataSourceWithMemoryCache\n",
            "2024-12-29 02:29:26,731 [nnabla][INFO]: DataSource with shuffle(False)\n",
            "2024-12-29 02:29:26,732 [nnabla][INFO]: On-memory\n",
            "2024-12-29 02:29:26,732 [nnabla][INFO]: Using DataIterator\n",
            "2024-12-29 02:29:29,947 [nnabla][INFO]: Solver state save (.h5): output/states_0.h5\n",
            "2024-12-29 02:29:29,953 [nnabla][INFO]: Parameter save (.h5): output/params_0.h5\n",
            "2024-12-29 02:29:29,953 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_0.json\n",
            "2024-12-29 02:29:30,121 [nnabla][INFO]: iter=9 {Training loss}=1.9921636581420898\n",
            "2024-12-29 02:29:30,121 [nnabla][INFO]: iter=9 {Training error}=0.74296875\n",
            "2024-12-29 02:29:30,163 [nnabla][INFO]: iter=19 {Training loss}=1.2750539779663086\n",
            "2024-12-29 02:29:30,163 [nnabla][INFO]: iter=19 {Training error}=0.2765625\n",
            "2024-12-29 02:29:30,207 [nnabla][INFO]: iter=29 {Training loss}=0.6205330491065979\n",
            "2024-12-29 02:29:30,207 [nnabla][INFO]: iter=29 {Training error}=0.09609375\n",
            "2024-12-29 02:29:30,248 [nnabla][INFO]: iter=39 {Training loss}=0.2791147828102112\n",
            "2024-12-29 02:29:30,249 [nnabla][INFO]: iter=39 {Training error}=0.05625\n",
            "2024-12-29 02:29:30,291 [nnabla][INFO]: iter=49 {Training loss}=0.13953574001789093\n",
            "2024-12-29 02:29:30,291 [nnabla][INFO]: iter=49 {Training error}=0.025\n",
            "2024-12-29 02:29:30,336 [nnabla][INFO]: iter=59 {Training loss}=0.08245708793401718\n",
            "2024-12-29 02:29:30,337 [nnabla][INFO]: iter=59 {Training error}=0.01328125\n",
            "2024-12-29 02:29:30,381 [nnabla][INFO]: iter=69 {Training loss}=0.05365035682916641\n",
            "2024-12-29 02:29:30,382 [nnabla][INFO]: iter=69 {Training error}=0.01015625\n",
            "2024-12-29 02:29:30,432 [nnabla][INFO]: iter=79 {Training loss}=0.04328387975692749\n",
            "2024-12-29 02:29:30,432 [nnabla][INFO]: iter=79 {Training error}=0.0109375\n",
            "2024-12-29 02:29:30,474 [nnabla][INFO]: iter=89 {Training loss}=0.028502831235527992\n",
            "2024-12-29 02:29:30,474 [nnabla][INFO]: iter=89 {Training error}=0.00703125\n",
            "2024-12-29 02:29:30,518 [nnabla][INFO]: iter=99 {Training loss}=0.023415718227624893\n",
            "2024-12-29 02:29:30,518 [nnabla][INFO]: iter=99 {Training error}=0.00625\n",
            "2024-12-29 02:29:30,518 [nnabla][INFO]: iter=99 {Training time}=4.020266532897949[sec/100iter] 4.020266532897949[sec]\n",
            "2024-12-29 02:29:30,543 [nnabla][INFO]: iter=100 {Test error}=0.50703125\n",
            "2024-12-29 02:29:30,585 [nnabla][INFO]: iter=109 {Training loss}=0.01878131367266178\n",
            "2024-12-29 02:29:30,585 [nnabla][INFO]: iter=109 {Training error}=0.00546875\n",
            "2024-12-29 02:29:30,630 [nnabla][INFO]: iter=119 {Training loss}=0.015664029866456985\n",
            "2024-12-29 02:29:30,630 [nnabla][INFO]: iter=119 {Training error}=0.00546875\n",
            "2024-12-29 02:29:30,671 [nnabla][INFO]: iter=129 {Training loss}=0.012193573638796806\n",
            "2024-12-29 02:29:30,671 [nnabla][INFO]: iter=129 {Training error}=0.003125\n",
            "2024-12-29 02:29:30,713 [nnabla][INFO]: iter=139 {Training loss}=0.009837423451244831\n",
            "2024-12-29 02:29:30,713 [nnabla][INFO]: iter=139 {Training error}=0.00078125\n",
            "2024-12-29 02:29:30,753 [nnabla][INFO]: iter=149 {Training loss}=0.007645691744983196\n",
            "2024-12-29 02:29:30,754 [nnabla][INFO]: iter=149 {Training error}=0.00078125\n",
            "2024-12-29 02:29:30,794 [nnabla][INFO]: iter=159 {Training loss}=0.0067941294983029366\n",
            "2024-12-29 02:29:30,794 [nnabla][INFO]: iter=159 {Training error}=0.0\n",
            "2024-12-29 02:29:30,835 [nnabla][INFO]: iter=169 {Training loss}=0.005111034493893385\n",
            "2024-12-29 02:29:30,836 [nnabla][INFO]: iter=169 {Training error}=0.0\n",
            "2024-12-29 02:29:30,875 [nnabla][INFO]: iter=179 {Training loss}=0.0049238973297178745\n",
            "2024-12-29 02:29:30,875 [nnabla][INFO]: iter=179 {Training error}=0.0\n",
            "2024-12-29 02:29:30,914 [nnabla][INFO]: iter=189 {Training loss}=0.004013560246676207\n",
            "2024-12-29 02:29:30,915 [nnabla][INFO]: iter=189 {Training error}=0.0\n",
            "2024-12-29 02:29:30,954 [nnabla][INFO]: iter=199 {Training loss}=0.003762058215215802\n",
            "2024-12-29 02:29:30,954 [nnabla][INFO]: iter=199 {Training error}=0.0\n",
            "2024-12-29 02:29:30,954 [nnabla][INFO]: iter=199 {Training time}=0.4357283115386963[sec/100iter] 4.4559948444366455[sec]\n",
            "2024-12-29 02:29:30,977 [nnabla][INFO]: iter=200 {Test error}=0.01484375\n",
            "2024-12-29 02:29:31,016 [nnabla][INFO]: iter=209 {Training loss}=0.002942307386547327\n",
            "2024-12-29 02:29:31,016 [nnabla][INFO]: iter=209 {Training error}=0.0\n",
            "2024-12-29 02:29:31,056 [nnabla][INFO]: iter=219 {Training loss}=0.0027607183437794447\n",
            "2024-12-29 02:29:31,056 [nnabla][INFO]: iter=219 {Training error}=0.0\n",
            "2024-12-29 02:29:31,096 [nnabla][INFO]: iter=229 {Training loss}=0.0023501086980104446\n",
            "2024-12-29 02:29:31,096 [nnabla][INFO]: iter=229 {Training error}=0.0\n",
            "2024-12-29 02:29:31,135 [nnabla][INFO]: iter=239 {Training loss}=0.002086831256747246\n",
            "2024-12-29 02:29:31,136 [nnabla][INFO]: iter=239 {Training error}=0.0\n",
            "2024-12-29 02:29:31,175 [nnabla][INFO]: iter=249 {Training loss}=0.001831362722441554\n",
            "2024-12-29 02:29:31,175 [nnabla][INFO]: iter=249 {Training error}=0.0\n",
            "2024-12-29 02:29:31,215 [nnabla][INFO]: iter=259 {Training loss}=0.0016856621950864792\n",
            "2024-12-29 02:29:31,216 [nnabla][INFO]: iter=259 {Training error}=0.0\n",
            "2024-12-29 02:29:31,256 [nnabla][INFO]: iter=269 {Training loss}=0.0016300259158015251\n",
            "2024-12-29 02:29:31,256 [nnabla][INFO]: iter=269 {Training error}=0.0\n",
            "2024-12-29 02:29:31,298 [nnabla][INFO]: iter=279 {Training loss}=0.0014387925621122122\n",
            "2024-12-29 02:29:31,299 [nnabla][INFO]: iter=279 {Training error}=0.0\n",
            "2024-12-29 02:29:31,340 [nnabla][INFO]: iter=289 {Training loss}=0.0013215624494478106\n",
            "2024-12-29 02:29:31,341 [nnabla][INFO]: iter=289 {Training error}=0.0\n",
            "2024-12-29 02:29:31,385 [nnabla][INFO]: iter=299 {Training loss}=0.001221094629727304\n",
            "2024-12-29 02:29:31,385 [nnabla][INFO]: iter=299 {Training error}=0.0\n",
            "2024-12-29 02:29:31,385 [nnabla][INFO]: iter=299 {Training time}=0.4308350086212158[sec/100iter] 4.886829853057861[sec]\n",
            "2024-12-29 02:29:31,409 [nnabla][INFO]: iter=300 {Test error}=0.0140625\n",
            "2024-12-29 02:29:31,448 [nnabla][INFO]: iter=309 {Training loss}=0.0011411302257329226\n",
            "2024-12-29 02:29:31,448 [nnabla][INFO]: iter=309 {Training error}=0.0\n",
            "2024-12-29 02:29:31,487 [nnabla][INFO]: iter=319 {Training loss}=0.001070867758244276\n",
            "2024-12-29 02:29:31,488 [nnabla][INFO]: iter=319 {Training error}=0.0\n",
            "2024-12-29 02:29:31,527 [nnabla][INFO]: iter=329 {Training loss}=0.0010142948012799025\n",
            "2024-12-29 02:29:31,527 [nnabla][INFO]: iter=329 {Training error}=0.0\n",
            "2024-12-29 02:29:31,569 [nnabla][INFO]: iter=339 {Training loss}=0.0008928283350542188\n",
            "2024-12-29 02:29:31,569 [nnabla][INFO]: iter=339 {Training error}=0.0\n",
            "2024-12-29 02:29:31,611 [nnabla][INFO]: iter=349 {Training loss}=0.0008814923348836601\n",
            "2024-12-29 02:29:31,611 [nnabla][INFO]: iter=349 {Training error}=0.0\n",
            "2024-12-29 02:29:31,649 [nnabla][INFO]: iter=359 {Training loss}=0.0008083037100732327\n",
            "2024-12-29 02:29:31,650 [nnabla][INFO]: iter=359 {Training error}=0.0\n",
            "2024-12-29 02:29:31,689 [nnabla][INFO]: iter=369 {Training loss}=0.0007613962516188622\n",
            "2024-12-29 02:29:31,689 [nnabla][INFO]: iter=369 {Training error}=0.0\n",
            "2024-12-29 02:29:31,729 [nnabla][INFO]: iter=379 {Training loss}=0.0007201050757430494\n",
            "2024-12-29 02:29:31,729 [nnabla][INFO]: iter=379 {Training error}=0.0\n",
            "2024-12-29 02:29:31,769 [nnabla][INFO]: iter=389 {Training loss}=0.0007051745196804404\n",
            "2024-12-29 02:29:31,769 [nnabla][INFO]: iter=389 {Training error}=0.0\n",
            "2024-12-29 02:29:31,810 [nnabla][INFO]: iter=399 {Training loss}=0.0006385042215697467\n",
            "2024-12-29 02:29:31,811 [nnabla][INFO]: iter=399 {Training error}=0.0\n",
            "2024-12-29 02:29:31,811 [nnabla][INFO]: iter=399 {Training time}=0.42578768730163574[sec/100iter] 5.312617540359497[sec]\n",
            "2024-12-29 02:29:31,834 [nnabla][INFO]: iter=400 {Test error}=0.0140625\n",
            "2024-12-29 02:29:31,874 [nnabla][INFO]: iter=409 {Training loss}=0.0006317088264040649\n",
            "2024-12-29 02:29:31,874 [nnabla][INFO]: iter=409 {Training error}=0.0\n",
            "2024-12-29 02:29:31,914 [nnabla][INFO]: iter=419 {Training loss}=0.0005720877088606358\n",
            "2024-12-29 02:29:31,914 [nnabla][INFO]: iter=419 {Training error}=0.0\n",
            "2024-12-29 02:29:31,953 [nnabla][INFO]: iter=429 {Training loss}=0.0005530788330361247\n",
            "2024-12-29 02:29:31,954 [nnabla][INFO]: iter=429 {Training error}=0.0\n",
            "2024-12-29 02:29:31,992 [nnabla][INFO]: iter=439 {Training loss}=0.0005310798878781497\n",
            "2024-12-29 02:29:31,992 [nnabla][INFO]: iter=439 {Training error}=0.0\n",
            "2024-12-29 02:29:32,032 [nnabla][INFO]: iter=449 {Training loss}=0.0004979857476428151\n",
            "2024-12-29 02:29:32,032 [nnabla][INFO]: iter=449 {Training error}=0.0\n",
            "2024-12-29 02:29:32,071 [nnabla][INFO]: iter=459 {Training loss}=0.00047355369315482676\n",
            "2024-12-29 02:29:32,071 [nnabla][INFO]: iter=459 {Training error}=0.0\n",
            "2024-12-29 02:29:32,111 [nnabla][INFO]: iter=469 {Training loss}=0.00045744291855953634\n",
            "2024-12-29 02:29:32,111 [nnabla][INFO]: iter=469 {Training error}=0.0\n",
            "2024-12-29 02:29:32,150 [nnabla][INFO]: iter=479 {Training loss}=0.00042914444929920137\n",
            "2024-12-29 02:29:32,151 [nnabla][INFO]: iter=479 {Training error}=0.0\n",
            "2024-12-29 02:29:32,189 [nnabla][INFO]: iter=489 {Training loss}=0.0004321309388615191\n",
            "2024-12-29 02:29:32,190 [nnabla][INFO]: iter=489 {Training error}=0.0\n",
            "2024-12-29 02:29:32,232 [nnabla][INFO]: iter=499 {Training loss}=0.0004067704430781305\n",
            "2024-12-29 02:29:32,233 [nnabla][INFO]: iter=499 {Training error}=0.0\n",
            "2024-12-29 02:29:32,233 [nnabla][INFO]: iter=499 {Training time}=0.42203402519226074[sec/100iter] 5.734651565551758[sec]\n",
            "2024-12-29 02:29:32,257 [nnabla][INFO]: iter=500 {Test error}=0.01484375\n",
            "2024-12-29 02:29:32,295 [nnabla][INFO]: iter=509 {Training loss}=0.0003822562866844237\n",
            "2024-12-29 02:29:32,295 [nnabla][INFO]: iter=509 {Training error}=0.0\n",
            "2024-12-29 02:29:32,334 [nnabla][INFO]: iter=519 {Training loss}=0.000373974849935621\n",
            "2024-12-29 02:29:32,335 [nnabla][INFO]: iter=519 {Training error}=0.0\n",
            "2024-12-29 02:29:32,372 [nnabla][INFO]: iter=529 {Training loss}=0.00035412644501775503\n",
            "2024-12-29 02:29:32,373 [nnabla][INFO]: iter=529 {Training error}=0.0\n",
            "2024-12-29 02:29:32,416 [nnabla][INFO]: iter=539 {Training loss}=0.0003424934402573854\n",
            "2024-12-29 02:29:32,416 [nnabla][INFO]: iter=539 {Training error}=0.0\n",
            "2024-12-29 02:29:32,454 [nnabla][INFO]: iter=549 {Training loss}=0.0003227688721381128\n",
            "2024-12-29 02:29:32,454 [nnabla][INFO]: iter=549 {Training error}=0.0\n",
            "2024-12-29 02:29:32,492 [nnabla][INFO]: iter=559 {Training loss}=0.0003228273126296699\n",
            "2024-12-29 02:29:32,492 [nnabla][INFO]: iter=559 {Training error}=0.0\n",
            "2024-12-29 02:29:32,530 [nnabla][INFO]: iter=569 {Training loss}=0.0003002993471454829\n",
            "2024-12-29 02:29:32,530 [nnabla][INFO]: iter=569 {Training error}=0.0\n",
            "2024-12-29 02:29:32,570 [nnabla][INFO]: iter=579 {Training loss}=0.00029300799360498786\n",
            "2024-12-29 02:29:32,571 [nnabla][INFO]: iter=579 {Training error}=0.0\n",
            "2024-12-29 02:29:32,608 [nnabla][INFO]: iter=589 {Training loss}=0.0002932459465228021\n",
            "2024-12-29 02:29:32,608 [nnabla][INFO]: iter=589 {Training error}=0.0\n",
            "2024-12-29 02:29:32,646 [nnabla][INFO]: iter=599 {Training loss}=0.0002813354367390275\n",
            "2024-12-29 02:29:32,646 [nnabla][INFO]: iter=599 {Training error}=0.0\n",
            "2024-12-29 02:29:32,647 [nnabla][INFO]: iter=599 {Training time}=0.41375184059143066[sec/100iter] 6.1484034061431885[sec]\n",
            "2024-12-29 02:29:32,669 [nnabla][INFO]: iter=600 {Test error}=0.0140625\n",
            "2024-12-29 02:29:32,709 [nnabla][INFO]: iter=609 {Training loss}=0.0002565588802099228\n",
            "2024-12-29 02:29:32,709 [nnabla][INFO]: iter=609 {Training error}=0.0\n",
            "2024-12-29 02:29:32,747 [nnabla][INFO]: iter=619 {Training loss}=0.0002524469164200127\n",
            "2024-12-29 02:29:32,747 [nnabla][INFO]: iter=619 {Training error}=0.0\n",
            "2024-12-29 02:29:32,787 [nnabla][INFO]: iter=629 {Training loss}=0.00025186582934111357\n",
            "2024-12-29 02:29:32,787 [nnabla][INFO]: iter=629 {Training error}=0.0\n",
            "2024-12-29 02:29:32,828 [nnabla][INFO]: iter=639 {Training loss}=0.00023921877436805516\n",
            "2024-12-29 02:29:32,828 [nnabla][INFO]: iter=639 {Training error}=0.0\n",
            "2024-12-29 02:29:32,867 [nnabla][INFO]: iter=649 {Training loss}=0.00023165713355410844\n",
            "2024-12-29 02:29:32,867 [nnabla][INFO]: iter=649 {Training error}=0.0\n",
            "2024-12-29 02:29:32,906 [nnabla][INFO]: iter=659 {Training loss}=0.00022660917602479458\n",
            "2024-12-29 02:29:32,906 [nnabla][INFO]: iter=659 {Training error}=0.0\n",
            "2024-12-29 02:29:32,943 [nnabla][INFO]: iter=669 {Training loss}=0.00021382971317507327\n",
            "2024-12-29 02:29:32,943 [nnabla][INFO]: iter=669 {Training error}=0.0\n",
            "2024-12-29 02:29:32,982 [nnabla][INFO]: iter=679 {Training loss}=0.00021822689450345933\n",
            "2024-12-29 02:29:32,982 [nnabla][INFO]: iter=679 {Training error}=0.0\n",
            "2024-12-29 02:29:33,022 [nnabla][INFO]: iter=689 {Training loss}=0.00020342094649095088\n",
            "2024-12-29 02:29:33,022 [nnabla][INFO]: iter=689 {Training error}=0.0\n",
            "2024-12-29 02:29:33,063 [nnabla][INFO]: iter=699 {Training loss}=0.00019753123342525214\n",
            "2024-12-29 02:29:33,063 [nnabla][INFO]: iter=699 {Training error}=0.0\n",
            "2024-12-29 02:29:33,063 [nnabla][INFO]: iter=699 {Training time}=0.4165182113647461[sec/100iter] 6.564921617507935[sec]\n",
            "2024-12-29 02:29:33,087 [nnabla][INFO]: iter=700 {Test error}=0.0140625\n",
            "2024-12-29 02:29:33,125 [nnabla][INFO]: iter=709 {Training loss}=0.00019562640227377415\n",
            "2024-12-29 02:29:33,125 [nnabla][INFO]: iter=709 {Training error}=0.0\n",
            "2024-12-29 02:29:33,163 [nnabla][INFO]: iter=719 {Training loss}=0.00018338749941904098\n",
            "2024-12-29 02:29:33,163 [nnabla][INFO]: iter=719 {Training error}=0.0\n",
            "2024-12-29 02:29:33,201 [nnabla][INFO]: iter=729 {Training loss}=0.00017777107132133096\n",
            "2024-12-29 02:29:33,201 [nnabla][INFO]: iter=729 {Training error}=0.0\n",
            "2024-12-29 02:29:33,241 [nnabla][INFO]: iter=739 {Training loss}=0.00018054692191071808\n",
            "2024-12-29 02:29:33,241 [nnabla][INFO]: iter=739 {Training error}=0.0\n",
            "2024-12-29 02:29:33,282 [nnabla][INFO]: iter=749 {Training loss}=0.00017603336891625077\n",
            "2024-12-29 02:29:33,282 [nnabla][INFO]: iter=749 {Training error}=0.0\n",
            "2024-12-29 02:29:33,320 [nnabla][INFO]: iter=759 {Training loss}=0.0001641942362766713\n",
            "2024-12-29 02:29:33,321 [nnabla][INFO]: iter=759 {Training error}=0.0\n",
            "2024-12-29 02:29:33,359 [nnabla][INFO]: iter=769 {Training loss}=0.0001624735741643235\n",
            "2024-12-29 02:29:33,360 [nnabla][INFO]: iter=769 {Training error}=0.0\n",
            "2024-12-29 02:29:33,398 [nnabla][INFO]: iter=779 {Training loss}=0.0001651403435971588\n",
            "2024-12-29 02:29:33,399 [nnabla][INFO]: iter=779 {Training error}=0.0\n",
            "2024-12-29 02:29:33,444 [nnabla][INFO]: iter=789 {Training loss}=0.00015368181630037725\n",
            "2024-12-29 02:29:33,444 [nnabla][INFO]: iter=789 {Training error}=0.0\n",
            "2024-12-29 02:29:33,487 [nnabla][INFO]: iter=799 {Training loss}=0.0001499108038842678\n",
            "2024-12-29 02:29:33,487 [nnabla][INFO]: iter=799 {Training error}=0.0\n",
            "2024-12-29 02:29:33,487 [nnabla][INFO]: iter=799 {Training time}=0.4242973327636719[sec/100iter] 6.9892189502716064[sec]\n",
            "2024-12-29 02:29:33,511 [nnabla][INFO]: iter=800 {Test error}=0.0140625\n",
            "2024-12-29 02:29:33,553 [nnabla][INFO]: iter=809 {Training loss}=0.00014533771900460124\n",
            "2024-12-29 02:29:33,553 [nnabla][INFO]: iter=809 {Training error}=0.0\n",
            "2024-12-29 02:29:33,591 [nnabla][INFO]: iter=819 {Training loss}=0.00014291953993961215\n",
            "2024-12-29 02:29:33,591 [nnabla][INFO]: iter=819 {Training error}=0.0\n",
            "2024-12-29 02:29:33,630 [nnabla][INFO]: iter=829 {Training loss}=0.00013994195614941418\n",
            "2024-12-29 02:29:33,630 [nnabla][INFO]: iter=829 {Training error}=0.0\n",
            "2024-12-29 02:29:33,668 [nnabla][INFO]: iter=839 {Training loss}=0.00013913294242229313\n",
            "2024-12-29 02:29:33,668 [nnabla][INFO]: iter=839 {Training error}=0.0\n",
            "2024-12-29 02:29:33,706 [nnabla][INFO]: iter=849 {Training loss}=0.00013321978622116148\n",
            "2024-12-29 02:29:33,706 [nnabla][INFO]: iter=849 {Training error}=0.0\n",
            "2024-12-29 02:29:33,746 [nnabla][INFO]: iter=859 {Training loss}=0.00012462759332265705\n",
            "2024-12-29 02:29:33,746 [nnabla][INFO]: iter=859 {Training error}=0.0\n",
            "2024-12-29 02:29:33,784 [nnabla][INFO]: iter=869 {Training loss}=0.00012910398072563112\n",
            "2024-12-29 02:29:33,784 [nnabla][INFO]: iter=869 {Training error}=0.0\n",
            "2024-12-29 02:29:33,822 [nnabla][INFO]: iter=879 {Training loss}=0.00012473644164856523\n",
            "2024-12-29 02:29:33,823 [nnabla][INFO]: iter=879 {Training error}=0.0\n",
            "2024-12-29 02:29:33,861 [nnabla][INFO]: iter=889 {Training loss}=0.00011664818885037675\n",
            "2024-12-29 02:29:33,862 [nnabla][INFO]: iter=889 {Training error}=0.0\n",
            "2024-12-29 02:29:33,900 [nnabla][INFO]: iter=899 {Training loss}=0.0001192751806229353\n",
            "2024-12-29 02:29:33,901 [nnabla][INFO]: iter=899 {Training error}=0.0\n",
            "2024-12-29 02:29:33,901 [nnabla][INFO]: iter=899 {Training time}=0.41341590881347656[sec/100iter] 7.402634859085083[sec]\n",
            "2024-12-29 02:29:33,924 [nnabla][INFO]: iter=900 {Test error}=0.01484375\n",
            "2024-12-29 02:29:33,962 [nnabla][INFO]: iter=909 {Training loss}=0.00011937275849049911\n",
            "2024-12-29 02:29:33,962 [nnabla][INFO]: iter=909 {Training error}=0.0\n",
            "2024-12-29 02:29:34,000 [nnabla][INFO]: iter=919 {Training loss}=0.00010985308472299948\n",
            "2024-12-29 02:29:34,000 [nnabla][INFO]: iter=919 {Training error}=0.0\n",
            "2024-12-29 02:29:34,041 [nnabla][INFO]: iter=929 {Training loss}=0.00011158876441186294\n",
            "2024-12-29 02:29:34,041 [nnabla][INFO]: iter=929 {Training error}=0.0\n",
            "2024-12-29 02:29:34,080 [nnabla][INFO]: iter=939 {Training loss}=0.00011075158545281738\n",
            "2024-12-29 02:29:34,080 [nnabla][INFO]: iter=939 {Training error}=0.0\n",
            "2024-12-29 02:29:34,118 [nnabla][INFO]: iter=949 {Training loss}=0.00010491651482880116\n",
            "2024-12-29 02:29:34,118 [nnabla][INFO]: iter=949 {Training error}=0.0\n",
            "2024-12-29 02:29:34,156 [nnabla][INFO]: iter=959 {Training loss}=0.00010260621638735756\n",
            "2024-12-29 02:29:34,156 [nnabla][INFO]: iter=959 {Training error}=0.0\n",
            "2024-12-29 02:29:34,194 [nnabla][INFO]: iter=969 {Training loss}=0.00010004905198002234\n",
            "2024-12-29 02:29:34,194 [nnabla][INFO]: iter=969 {Training error}=0.0\n",
            "2024-12-29 02:29:34,232 [nnabla][INFO]: iter=979 {Training loss}=9.753736958373338e-05\n",
            "2024-12-29 02:29:34,232 [nnabla][INFO]: iter=979 {Training error}=0.0\n",
            "2024-12-29 02:29:34,273 [nnabla][INFO]: iter=989 {Training loss}=9.840085112955421e-05\n",
            "2024-12-29 02:29:34,273 [nnabla][INFO]: iter=989 {Training error}=0.0\n",
            "2024-12-29 02:29:34,311 [nnabla][INFO]: iter=999 {Training loss}=9.53580456553027e-05\n",
            "2024-12-29 02:29:34,311 [nnabla][INFO]: iter=999 {Training error}=0.0\n",
            "2024-12-29 02:29:34,311 [nnabla][INFO]: iter=999 {Training time}=0.41007423400878906[sec/100iter] 7.812709093093872[sec]\n",
            "2024-12-29 02:29:34,334 [nnabla][INFO]: iter=1000 {Test error}=0.0140625\n",
            "2024-12-29 02:29:34,347 [nnabla][INFO]: Solver state save (.h5): output/states_1000.h5\n",
            "2024-12-29 02:29:34,353 [nnabla][INFO]: Parameter save (.h5): output/params_1000.h5\n",
            "2024-12-29 02:29:34,354 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_1000.json\n",
            "2024-12-29 02:29:34,392 [nnabla][INFO]: iter=1009 {Training loss}=9.210521966451779e-05\n",
            "2024-12-29 02:29:34,392 [nnabla][INFO]: iter=1009 {Training error}=0.0\n",
            "2024-12-29 02:29:34,430 [nnabla][INFO]: iter=1019 {Training loss}=9.015481191454455e-05\n",
            "2024-12-29 02:29:34,430 [nnabla][INFO]: iter=1019 {Training error}=0.0\n",
            "2024-12-29 02:29:34,472 [nnabla][INFO]: iter=1029 {Training loss}=8.944820729084313e-05\n",
            "2024-12-29 02:29:34,472 [nnabla][INFO]: iter=1029 {Training error}=0.0\n",
            "2024-12-29 02:29:34,511 [nnabla][INFO]: iter=1039 {Training loss}=8.685688953846693e-05\n",
            "2024-12-29 02:29:34,512 [nnabla][INFO]: iter=1039 {Training error}=0.0\n",
            "2024-12-29 02:29:34,552 [nnabla][INFO]: iter=1049 {Training loss}=8.44228416099213e-05\n",
            "2024-12-29 02:29:34,552 [nnabla][INFO]: iter=1049 {Training error}=0.0\n",
            "2024-12-29 02:29:34,590 [nnabla][INFO]: iter=1059 {Training loss}=8.577645348850638e-05\n",
            "2024-12-29 02:29:34,590 [nnabla][INFO]: iter=1059 {Training error}=0.0\n",
            "2024-12-29 02:29:34,628 [nnabla][INFO]: iter=1069 {Training loss}=8.119521953631192e-05\n",
            "2024-12-29 02:29:34,629 [nnabla][INFO]: iter=1069 {Training error}=0.0\n",
            "2024-12-29 02:29:34,666 [nnabla][INFO]: iter=1079 {Training loss}=8.350917778443545e-05\n",
            "2024-12-29 02:29:34,667 [nnabla][INFO]: iter=1079 {Training error}=0.0\n",
            "2024-12-29 02:29:34,704 [nnabla][INFO]: iter=1089 {Training loss}=8.195731788873672e-05\n",
            "2024-12-29 02:29:34,704 [nnabla][INFO]: iter=1089 {Training error}=0.0\n",
            "2024-12-29 02:29:34,743 [nnabla][INFO]: iter=1099 {Training loss}=7.493646262446418e-05\n",
            "2024-12-29 02:29:34,743 [nnabla][INFO]: iter=1099 {Training error}=0.0\n",
            "2024-12-29 02:29:34,744 [nnabla][INFO]: iter=1099 {Training time}=0.4327223300933838[sec/100iter] 8.245431423187256[sec]\n",
            "2024-12-29 02:29:34,766 [nnabla][INFO]: iter=1100 {Test error}=0.0140625\n",
            "2024-12-29 02:29:34,805 [nnabla][INFO]: iter=1109 {Training loss}=7.78667235863395e-05\n",
            "2024-12-29 02:29:34,805 [nnabla][INFO]: iter=1109 {Training error}=0.0\n",
            "2024-12-29 02:29:34,844 [nnabla][INFO]: iter=1119 {Training loss}=7.281488797161728e-05\n",
            "2024-12-29 02:29:34,844 [nnabla][INFO]: iter=1119 {Training error}=0.0\n",
            "2024-12-29 02:29:34,882 [nnabla][INFO]: iter=1129 {Training loss}=7.331615779548883e-05\n",
            "2024-12-29 02:29:34,882 [nnabla][INFO]: iter=1129 {Training error}=0.0\n",
            "2024-12-29 02:29:34,920 [nnabla][INFO]: iter=1139 {Training loss}=7.288991764653474e-05\n",
            "2024-12-29 02:29:34,920 [nnabla][INFO]: iter=1139 {Training error}=0.0\n",
            "2024-12-29 02:29:34,959 [nnabla][INFO]: iter=1149 {Training loss}=7.010500121396035e-05\n",
            "2024-12-29 02:29:34,960 [nnabla][INFO]: iter=1149 {Training error}=0.0\n",
            "2024-12-29 02:29:35,000 [nnabla][INFO]: iter=1159 {Training loss}=6.986005610087886e-05\n",
            "2024-12-29 02:29:35,000 [nnabla][INFO]: iter=1159 {Training error}=0.0\n",
            "2024-12-29 02:29:35,049 [nnabla][INFO]: iter=1169 {Training loss}=6.882362504256889e-05\n",
            "2024-12-29 02:29:35,051 [nnabla][INFO]: iter=1169 {Training error}=0.0\n",
            "2024-12-29 02:29:35,094 [nnabla][INFO]: iter=1179 {Training loss}=6.760875112377107e-05\n",
            "2024-12-29 02:29:35,095 [nnabla][INFO]: iter=1179 {Training error}=0.0\n",
            "2024-12-29 02:29:35,141 [nnabla][INFO]: iter=1189 {Training loss}=6.447652413044125e-05\n",
            "2024-12-29 02:29:35,141 [nnabla][INFO]: iter=1189 {Training error}=0.0\n",
            "2024-12-29 02:29:35,186 [nnabla][INFO]: iter=1199 {Training loss}=6.435612158384174e-05\n",
            "2024-12-29 02:29:35,186 [nnabla][INFO]: iter=1199 {Training error}=0.0\n",
            "2024-12-29 02:29:35,186 [nnabla][INFO]: iter=1199 {Training time}=0.4427964687347412[sec/100iter] 8.688227891921997[sec]\n",
            "2024-12-29 02:29:35,215 [nnabla][INFO]: iter=1200 {Test error}=0.01484375\n",
            "2024-12-29 02:29:35,264 [nnabla][INFO]: iter=1209 {Training loss}=6.631891301367432e-05\n",
            "2024-12-29 02:29:35,264 [nnabla][INFO]: iter=1209 {Training error}=0.0\n",
            "2024-12-29 02:29:35,308 [nnabla][INFO]: iter=1219 {Training loss}=6.129972462076694e-05\n",
            "2024-12-29 02:29:35,309 [nnabla][INFO]: iter=1219 {Training error}=0.0\n",
            "2024-12-29 02:29:35,350 [nnabla][INFO]: iter=1229 {Training loss}=6.27979970886372e-05\n",
            "2024-12-29 02:29:35,351 [nnabla][INFO]: iter=1229 {Training error}=0.0\n",
            "2024-12-29 02:29:35,394 [nnabla][INFO]: iter=1239 {Training loss}=5.858918302692473e-05\n",
            "2024-12-29 02:29:35,394 [nnabla][INFO]: iter=1239 {Training error}=0.0\n",
            "2024-12-29 02:29:35,437 [nnabla][INFO]: iter=1249 {Training loss}=5.9069985582027584e-05\n",
            "2024-12-29 02:29:35,437 [nnabla][INFO]: iter=1249 {Training error}=0.0\n",
            "2024-12-29 02:29:35,484 [nnabla][INFO]: iter=1259 {Training loss}=5.921867705183104e-05\n",
            "2024-12-29 02:29:35,485 [nnabla][INFO]: iter=1259 {Training error}=0.0\n",
            "2024-12-29 02:29:35,533 [nnabla][INFO]: iter=1269 {Training loss}=5.6592012697365135e-05\n",
            "2024-12-29 02:29:35,533 [nnabla][INFO]: iter=1269 {Training error}=0.0\n",
            "2024-12-29 02:29:35,577 [nnabla][INFO]: iter=1279 {Training loss}=5.7398043281864375e-05\n",
            "2024-12-29 02:29:35,577 [nnabla][INFO]: iter=1279 {Training error}=0.0\n",
            "2024-12-29 02:29:35,620 [nnabla][INFO]: iter=1289 {Training loss}=5.636819332721643e-05\n",
            "2024-12-29 02:29:35,621 [nnabla][INFO]: iter=1289 {Training error}=0.0\n",
            "2024-12-29 02:29:35,667 [nnabla][INFO]: iter=1299 {Training loss}=5.365294055081904e-05\n",
            "2024-12-29 02:29:35,667 [nnabla][INFO]: iter=1299 {Training error}=0.0\n",
            "2024-12-29 02:29:35,667 [nnabla][INFO]: iter=1299 {Training time}=0.4806692600250244[sec/100iter] 9.168897151947021[sec]\n",
            "2024-12-29 02:29:35,696 [nnabla][INFO]: iter=1300 {Test error}=0.0140625\n",
            "2024-12-29 02:29:35,738 [nnabla][INFO]: iter=1309 {Training loss}=5.4483964049723e-05\n",
            "2024-12-29 02:29:35,738 [nnabla][INFO]: iter=1309 {Training error}=0.0\n",
            "2024-12-29 02:29:35,783 [nnabla][INFO]: iter=1319 {Training loss}=5.212581163505092e-05\n",
            "2024-12-29 02:29:35,783 [nnabla][INFO]: iter=1319 {Training error}=0.0\n",
            "2024-12-29 02:29:35,825 [nnabla][INFO]: iter=1329 {Training loss}=5.276516458252445e-05\n",
            "2024-12-29 02:29:35,826 [nnabla][INFO]: iter=1329 {Training error}=0.0\n",
            "2024-12-29 02:29:35,868 [nnabla][INFO]: iter=1339 {Training loss}=5.013246482121758e-05\n",
            "2024-12-29 02:29:35,868 [nnabla][INFO]: iter=1339 {Training error}=0.0\n",
            "2024-12-29 02:29:35,913 [nnabla][INFO]: iter=1349 {Training loss}=5.094211155665107e-05\n",
            "2024-12-29 02:29:35,913 [nnabla][INFO]: iter=1349 {Training error}=0.0\n",
            "2024-12-29 02:29:35,955 [nnabla][INFO]: iter=1359 {Training loss}=4.894805533695035e-05\n",
            "2024-12-29 02:29:35,956 [nnabla][INFO]: iter=1359 {Training error}=0.0\n",
            "2024-12-29 02:29:36,001 [nnabla][INFO]: iter=1369 {Training loss}=4.9177750042872503e-05\n",
            "2024-12-29 02:29:36,001 [nnabla][INFO]: iter=1369 {Training error}=0.0\n",
            "2024-12-29 02:29:36,050 [nnabla][INFO]: iter=1379 {Training loss}=4.9003523599822074e-05\n",
            "2024-12-29 02:29:36,050 [nnabla][INFO]: iter=1379 {Training error}=0.0\n",
            "2024-12-29 02:29:36,094 [nnabla][INFO]: iter=1389 {Training loss}=4.7315796109614894e-05\n",
            "2024-12-29 02:29:36,095 [nnabla][INFO]: iter=1389 {Training error}=0.0\n",
            "2024-12-29 02:29:36,140 [nnabla][INFO]: iter=1399 {Training loss}=4.7138240915955976e-05\n",
            "2024-12-29 02:29:36,140 [nnabla][INFO]: iter=1399 {Training error}=0.0\n",
            "2024-12-29 02:29:36,140 [nnabla][INFO]: iter=1399 {Training time}=0.4733257293701172[sec/100iter] 9.642222881317139[sec]\n",
            "2024-12-29 02:29:36,166 [nnabla][INFO]: iter=1400 {Test error}=0.0140625\n",
            "2024-12-29 02:29:36,208 [nnabla][INFO]: iter=1409 {Training loss}=4.58154063380789e-05\n",
            "2024-12-29 02:29:36,208 [nnabla][INFO]: iter=1409 {Training error}=0.0\n",
            "2024-12-29 02:29:36,249 [nnabla][INFO]: iter=1419 {Training loss}=4.517627530731261e-05\n",
            "2024-12-29 02:29:36,249 [nnabla][INFO]: iter=1419 {Training error}=0.0\n",
            "2024-12-29 02:29:36,294 [nnabla][INFO]: iter=1429 {Training loss}=4.400048783281818e-05\n",
            "2024-12-29 02:29:36,294 [nnabla][INFO]: iter=1429 {Training error}=0.0\n",
            "2024-12-29 02:29:36,335 [nnabla][INFO]: iter=1439 {Training loss}=4.428510874276981e-05\n",
            "2024-12-29 02:29:36,335 [nnabla][INFO]: iter=1439 {Training error}=0.0\n",
            "2024-12-29 02:29:36,377 [nnabla][INFO]: iter=1449 {Training loss}=4.2210656829411164e-05\n",
            "2024-12-29 02:29:36,377 [nnabla][INFO]: iter=1449 {Training error}=0.0\n",
            "2024-12-29 02:29:36,418 [nnabla][INFO]: iter=1459 {Training loss}=4.40958610852249e-05\n",
            "2024-12-29 02:29:36,418 [nnabla][INFO]: iter=1459 {Training error}=0.0\n",
            "2024-12-29 02:29:36,459 [nnabla][INFO]: iter=1469 {Training loss}=4.169734165770933e-05\n",
            "2024-12-29 02:29:36,459 [nnabla][INFO]: iter=1469 {Training error}=0.0\n",
            "2024-12-29 02:29:36,500 [nnabla][INFO]: iter=1479 {Training loss}=4.103147512068972e-05\n",
            "2024-12-29 02:29:36,500 [nnabla][INFO]: iter=1479 {Training error}=0.0\n",
            "2024-12-29 02:29:36,557 [nnabla][INFO]: iter=1489 {Training loss}=4.13206362281926e-05\n",
            "2024-12-29 02:29:36,557 [nnabla][INFO]: iter=1489 {Training error}=0.0\n",
            "2024-12-29 02:29:36,611 [nnabla][INFO]: iter=1499 {Training loss}=3.923859912902117e-05\n",
            "2024-12-29 02:29:36,612 [nnabla][INFO]: iter=1499 {Training error}=0.0\n",
            "2024-12-29 02:29:36,612 [nnabla][INFO]: iter=1499 {Training time}=0.4714193344116211[sec/100iter] 10.11364221572876[sec]\n",
            "2024-12-29 02:29:36,640 [nnabla][INFO]: iter=1500 {Test error}=0.0140625\n",
            "2024-12-29 02:29:36,684 [nnabla][INFO]: iter=1509 {Training loss}=3.864949394483119e-05\n",
            "2024-12-29 02:29:36,684 [nnabla][INFO]: iter=1509 {Training error}=0.0\n",
            "2024-12-29 02:29:36,730 [nnabla][INFO]: iter=1519 {Training loss}=4.132877802476287e-05\n",
            "2024-12-29 02:29:36,730 [nnabla][INFO]: iter=1519 {Training error}=0.0\n",
            "2024-12-29 02:29:36,772 [nnabla][INFO]: iter=1529 {Training loss}=3.759265746339224e-05\n",
            "2024-12-29 02:29:36,772 [nnabla][INFO]: iter=1529 {Training error}=0.0\n",
            "2024-12-29 02:29:36,824 [nnabla][INFO]: iter=1539 {Training loss}=3.787465539062396e-05\n",
            "2024-12-29 02:29:36,824 [nnabla][INFO]: iter=1539 {Training error}=0.0\n",
            "2024-12-29 02:29:36,866 [nnabla][INFO]: iter=1549 {Training loss}=3.7460435123648494e-05\n",
            "2024-12-29 02:29:36,866 [nnabla][INFO]: iter=1549 {Training error}=0.0\n",
            "2024-12-29 02:29:36,911 [nnabla][INFO]: iter=1559 {Training loss}=3.681372254504822e-05\n",
            "2024-12-29 02:29:36,911 [nnabla][INFO]: iter=1559 {Training error}=0.0\n",
            "2024-12-29 02:29:36,953 [nnabla][INFO]: iter=1569 {Training loss}=3.7004905607318506e-05\n",
            "2024-12-29 02:29:36,954 [nnabla][INFO]: iter=1569 {Training error}=0.0\n",
            "2024-12-29 02:29:37,002 [nnabla][INFO]: iter=1579 {Training loss}=3.550561814336106e-05\n",
            "2024-12-29 02:29:37,002 [nnabla][INFO]: iter=1579 {Training error}=0.0\n",
            "2024-12-29 02:29:37,051 [nnabla][INFO]: iter=1589 {Training loss}=3.5262703022453934e-05\n",
            "2024-12-29 02:29:37,052 [nnabla][INFO]: iter=1589 {Training error}=0.0\n",
            "2024-12-29 02:29:37,107 [nnabla][INFO]: iter=1599 {Training loss}=3.495702549116686e-05\n",
            "2024-12-29 02:29:37,107 [nnabla][INFO]: iter=1599 {Training error}=0.0\n",
            "2024-12-29 02:29:37,108 [nnabla][INFO]: iter=1599 {Training time}=0.4958326816558838[sec/100iter] 10.609474897384644[sec]\n",
            "2024-12-29 02:29:37,139 [nnabla][INFO]: iter=1600 {Test error}=0.01484375\n",
            "2024-12-29 02:29:37,188 [nnabla][INFO]: iter=1609 {Training loss}=3.4811651858035475e-05\n",
            "2024-12-29 02:29:37,188 [nnabla][INFO]: iter=1609 {Training error}=0.0\n",
            "2024-12-29 02:29:37,232 [nnabla][INFO]: iter=1619 {Training loss}=3.380441194167361e-05\n",
            "2024-12-29 02:29:37,232 [nnabla][INFO]: iter=1619 {Training error}=0.0\n",
            "2024-12-29 02:29:37,277 [nnabla][INFO]: iter=1629 {Training loss}=3.215015385649167e-05\n",
            "2024-12-29 02:29:37,277 [nnabla][INFO]: iter=1629 {Training error}=0.0\n",
            "2024-12-29 02:29:37,326 [nnabla][INFO]: iter=1639 {Training loss}=3.395032399566844e-05\n",
            "2024-12-29 02:29:37,326 [nnabla][INFO]: iter=1639 {Training error}=0.0\n",
            "2024-12-29 02:29:37,372 [nnabla][INFO]: iter=1649 {Training loss}=3.352542262291536e-05\n",
            "2024-12-29 02:29:37,373 [nnabla][INFO]: iter=1649 {Training error}=0.0\n",
            "2024-12-29 02:29:37,420 [nnabla][INFO]: iter=1659 {Training loss}=3.110272155026905e-05\n",
            "2024-12-29 02:29:37,420 [nnabla][INFO]: iter=1659 {Training error}=0.0\n",
            "2024-12-29 02:29:37,464 [nnabla][INFO]: iter=1669 {Training loss}=3.091909093200229e-05\n",
            "2024-12-29 02:29:37,464 [nnabla][INFO]: iter=1669 {Training error}=0.0\n",
            "2024-12-29 02:29:37,513 [nnabla][INFO]: iter=1679 {Training loss}=3.16250734613277e-05\n",
            "2024-12-29 02:29:37,514 [nnabla][INFO]: iter=1679 {Training error}=0.0\n",
            "2024-12-29 02:29:37,559 [nnabla][INFO]: iter=1689 {Training loss}=3.196838224539533e-05\n",
            "2024-12-29 02:29:37,559 [nnabla][INFO]: iter=1689 {Training error}=0.0\n",
            "2024-12-29 02:29:37,614 [nnabla][INFO]: iter=1699 {Training loss}=2.9678174541913904e-05\n",
            "2024-12-29 02:29:37,614 [nnabla][INFO]: iter=1699 {Training error}=0.0\n",
            "2024-12-29 02:29:37,614 [nnabla][INFO]: iter=1699 {Training time}=0.5064170360565186[sec/100iter] 11.115891933441162[sec]\n",
            "2024-12-29 02:29:37,653 [nnabla][INFO]: iter=1700 {Test error}=0.0140625\n",
            "2024-12-29 02:29:37,699 [nnabla][INFO]: iter=1709 {Training loss}=3.106593794655055e-05\n",
            "2024-12-29 02:29:37,699 [nnabla][INFO]: iter=1709 {Training error}=0.0\n",
            "2024-12-29 02:29:37,746 [nnabla][INFO]: iter=1719 {Training loss}=2.8801889129681513e-05\n",
            "2024-12-29 02:29:37,746 [nnabla][INFO]: iter=1719 {Training error}=0.0\n",
            "2024-12-29 02:29:37,794 [nnabla][INFO]: iter=1729 {Training loss}=2.993560701725073e-05\n",
            "2024-12-29 02:29:37,794 [nnabla][INFO]: iter=1729 {Training error}=0.0\n",
            "2024-12-29 02:29:37,842 [nnabla][INFO]: iter=1739 {Training loss}=2.979546297865454e-05\n",
            "2024-12-29 02:29:37,843 [nnabla][INFO]: iter=1739 {Training error}=0.0\n",
            "2024-12-29 02:29:37,885 [nnabla][INFO]: iter=1749 {Training loss}=2.819716428348329e-05\n",
            "2024-12-29 02:29:37,886 [nnabla][INFO]: iter=1749 {Training error}=0.0\n",
            "2024-12-29 02:29:37,926 [nnabla][INFO]: iter=1759 {Training loss}=2.811658487189561e-05\n",
            "2024-12-29 02:29:37,926 [nnabla][INFO]: iter=1759 {Training error}=0.0\n",
            "2024-12-29 02:29:37,964 [nnabla][INFO]: iter=1769 {Training loss}=2.7496771508594975e-05\n",
            "2024-12-29 02:29:37,964 [nnabla][INFO]: iter=1769 {Training error}=0.0\n",
            "2024-12-29 02:29:38,006 [nnabla][INFO]: iter=1779 {Training loss}=2.810108162520919e-05\n",
            "2024-12-29 02:29:38,006 [nnabla][INFO]: iter=1779 {Training error}=0.0\n",
            "2024-12-29 02:29:38,046 [nnabla][INFO]: iter=1789 {Training loss}=2.6148274628212675e-05\n",
            "2024-12-29 02:29:38,046 [nnabla][INFO]: iter=1789 {Training error}=0.0\n",
            "2024-12-29 02:29:38,086 [nnabla][INFO]: iter=1799 {Training loss}=2.7439116820460185e-05\n",
            "2024-12-29 02:29:38,086 [nnabla][INFO]: iter=1799 {Training error}=0.0\n",
            "2024-12-29 02:29:38,086 [nnabla][INFO]: iter=1799 {Training time}=0.4722895622253418[sec/100iter] 11.588181495666504[sec]\n",
            "2024-12-29 02:29:38,110 [nnabla][INFO]: iter=1800 {Test error}=0.0140625\n",
            "2024-12-29 02:29:38,150 [nnabla][INFO]: iter=1809 {Training loss}=2.7135960408486426e-05\n",
            "2024-12-29 02:29:38,150 [nnabla][INFO]: iter=1809 {Training error}=0.0\n",
            "2024-12-29 02:29:38,193 [nnabla][INFO]: iter=1819 {Training loss}=2.5667628506198525e-05\n",
            "2024-12-29 02:29:38,193 [nnabla][INFO]: iter=1819 {Training error}=0.0\n",
            "2024-12-29 02:29:38,234 [nnabla][INFO]: iter=1829 {Training loss}=2.5478007955825888e-05\n",
            "2024-12-29 02:29:38,234 [nnabla][INFO]: iter=1829 {Training error}=0.0\n",
            "2024-12-29 02:29:38,273 [nnabla][INFO]: iter=1839 {Training loss}=2.647132714628242e-05\n",
            "2024-12-29 02:29:38,274 [nnabla][INFO]: iter=1839 {Training error}=0.0\n",
            "2024-12-29 02:29:38,315 [nnabla][INFO]: iter=1849 {Training loss}=2.478270289429929e-05\n",
            "2024-12-29 02:29:38,315 [nnabla][INFO]: iter=1849 {Training error}=0.0\n",
            "2024-12-29 02:29:38,353 [nnabla][INFO]: iter=1859 {Training loss}=2.4962073439382948e-05\n",
            "2024-12-29 02:29:38,354 [nnabla][INFO]: iter=1859 {Training error}=0.0\n",
            "2024-12-29 02:29:38,392 [nnabla][INFO]: iter=1869 {Training loss}=2.4976165150292218e-05\n",
            "2024-12-29 02:29:38,393 [nnabla][INFO]: iter=1869 {Training error}=0.0\n",
            "2024-12-29 02:29:38,431 [nnabla][INFO]: iter=1879 {Training loss}=2.4429009499726817e-05\n",
            "2024-12-29 02:29:38,432 [nnabla][INFO]: iter=1879 {Training error}=0.0\n",
            "2024-12-29 02:29:38,470 [nnabla][INFO]: iter=1889 {Training loss}=2.402606696705334e-05\n",
            "2024-12-29 02:29:38,471 [nnabla][INFO]: iter=1889 {Training error}=0.0\n",
            "2024-12-29 02:29:38,509 [nnabla][INFO]: iter=1899 {Training loss}=2.3354765289695933e-05\n",
            "2024-12-29 02:29:38,509 [nnabla][INFO]: iter=1899 {Training error}=0.0\n",
            "2024-12-29 02:29:38,509 [nnabla][INFO]: iter=1899 {Training time}=0.4226365089416504[sec/100iter] 12.010818004608154[sec]\n",
            "2024-12-29 02:29:38,531 [nnabla][INFO]: iter=1900 {Test error}=0.01484375\n",
            "2024-12-29 02:29:38,570 [nnabla][INFO]: iter=1909 {Training loss}=2.3582226276630536e-05\n",
            "2024-12-29 02:29:38,571 [nnabla][INFO]: iter=1909 {Training error}=0.0\n",
            "2024-12-29 02:29:38,613 [nnabla][INFO]: iter=1919 {Training loss}=2.3736994990031235e-05\n",
            "2024-12-29 02:29:38,613 [nnabla][INFO]: iter=1919 {Training error}=0.0\n",
            "2024-12-29 02:29:38,655 [nnabla][INFO]: iter=1929 {Training loss}=2.256536390632391e-05\n",
            "2024-12-29 02:29:38,655 [nnabla][INFO]: iter=1929 {Training error}=0.0\n",
            "2024-12-29 02:29:38,695 [nnabla][INFO]: iter=1939 {Training loss}=2.3091037292033434e-05\n",
            "2024-12-29 02:29:38,695 [nnabla][INFO]: iter=1939 {Training error}=0.0\n",
            "2024-12-29 02:29:38,733 [nnabla][INFO]: iter=1949 {Training loss}=2.2680387701257132e-05\n",
            "2024-12-29 02:29:38,734 [nnabla][INFO]: iter=1949 {Training error}=0.0\n",
            "2024-12-29 02:29:38,772 [nnabla][INFO]: iter=1959 {Training loss}=2.10408543352969e-05\n",
            "2024-12-29 02:29:38,772 [nnabla][INFO]: iter=1959 {Training error}=0.0\n",
            "2024-12-29 02:29:38,813 [nnabla][INFO]: iter=1969 {Training loss}=2.2093632651376538e-05\n",
            "2024-12-29 02:29:38,813 [nnabla][INFO]: iter=1969 {Training error}=0.0\n",
            "2024-12-29 02:29:38,850 [nnabla][INFO]: iter=1979 {Training loss}=2.2022786652087234e-05\n",
            "2024-12-29 02:29:38,851 [nnabla][INFO]: iter=1979 {Training error}=0.0\n",
            "2024-12-29 02:29:38,888 [nnabla][INFO]: iter=1989 {Training loss}=2.1817975721205585e-05\n",
            "2024-12-29 02:29:38,888 [nnabla][INFO]: iter=1989 {Training error}=0.0\n",
            "2024-12-29 02:29:38,927 [nnabla][INFO]: iter=1999 {Training loss}=2.0641380615415983e-05\n",
            "2024-12-29 02:29:38,927 [nnabla][INFO]: iter=1999 {Training error}=0.0\n",
            "2024-12-29 02:29:38,927 [nnabla][INFO]: iter=1999 {Training time}=0.418241024017334[sec/100iter] 12.429059028625488[sec]\n",
            "2024-12-29 02:29:38,958 [nnabla][INFO]: iter=2000 {Test error}=0.0140625\n",
            "2024-12-29 02:29:38,974 [nnabla][INFO]: Solver state save (.h5): output/states_2000.h5\n",
            "2024-12-29 02:29:38,980 [nnabla][INFO]: Parameter save (.h5): output/params_2000.h5\n",
            "2024-12-29 02:29:38,980 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_2000.json\n",
            "2024-12-29 02:29:39,019 [nnabla][INFO]: iter=2009 {Training loss}=2.080473495880142e-05\n",
            "2024-12-29 02:29:39,019 [nnabla][INFO]: iter=2009 {Training error}=0.0\n",
            "2024-12-29 02:29:39,057 [nnabla][INFO]: iter=2019 {Training loss}=2.1479274437297136e-05\n",
            "2024-12-29 02:29:39,057 [nnabla][INFO]: iter=2019 {Training error}=0.0\n",
            "2024-12-29 02:29:39,095 [nnabla][INFO]: iter=2029 {Training loss}=1.9966097170254216e-05\n",
            "2024-12-29 02:29:39,095 [nnabla][INFO]: iter=2029 {Training error}=0.0\n",
            "2024-12-29 02:29:39,135 [nnabla][INFO]: iter=2039 {Training loss}=2.0249561202945188e-05\n",
            "2024-12-29 02:29:39,135 [nnabla][INFO]: iter=2039 {Training error}=0.0\n",
            "2024-12-29 02:29:39,173 [nnabla][INFO]: iter=2049 {Training loss}=1.9919472833862528e-05\n",
            "2024-12-29 02:29:39,173 [nnabla][INFO]: iter=2049 {Training error}=0.0\n",
            "2024-12-29 02:29:39,211 [nnabla][INFO]: iter=2059 {Training loss}=1.9197515939595178e-05\n",
            "2024-12-29 02:29:39,211 [nnabla][INFO]: iter=2059 {Training error}=0.0\n",
            "2024-12-29 02:29:39,249 [nnabla][INFO]: iter=2069 {Training loss}=2.0282797777326778e-05\n",
            "2024-12-29 02:29:39,250 [nnabla][INFO]: iter=2069 {Training error}=0.0\n",
            "2024-12-29 02:29:39,288 [nnabla][INFO]: iter=2079 {Training loss}=1.9163029719493352e-05\n",
            "2024-12-29 02:29:39,288 [nnabla][INFO]: iter=2079 {Training error}=0.0\n",
            "2024-12-29 02:29:39,326 [nnabla][INFO]: iter=2089 {Training loss}=1.9244092982262373e-05\n",
            "2024-12-29 02:29:39,326 [nnabla][INFO]: iter=2089 {Training error}=0.0\n",
            "2024-12-29 02:29:39,363 [nnabla][INFO]: iter=2099 {Training loss}=1.8819750039256178e-05\n",
            "2024-12-29 02:29:39,363 [nnabla][INFO]: iter=2099 {Training error}=0.0\n",
            "2024-12-29 02:29:39,363 [nnabla][INFO]: iter=2099 {Training time}=0.43624305725097656[sec/100iter] 12.865302085876465[sec]\n",
            "2024-12-29 02:29:39,386 [nnabla][INFO]: iter=2100 {Test error}=0.0140625\n",
            "2024-12-29 02:29:39,425 [nnabla][INFO]: iter=2109 {Training loss}=1.870865344244521e-05\n",
            "2024-12-29 02:29:39,425 [nnabla][INFO]: iter=2109 {Training error}=0.0\n",
            "2024-12-29 02:29:39,462 [nnabla][INFO]: iter=2119 {Training loss}=1.8466935216565616e-05\n",
            "2024-12-29 02:29:39,463 [nnabla][INFO]: iter=2119 {Training error}=0.0\n",
            "2024-12-29 02:29:39,499 [nnabla][INFO]: iter=2129 {Training loss}=1.871335734904278e-05\n",
            "2024-12-29 02:29:39,499 [nnabla][INFO]: iter=2129 {Training error}=0.0\n",
            "2024-12-29 02:29:39,537 [nnabla][INFO]: iter=2139 {Training loss}=1.80872120836284e-05\n",
            "2024-12-29 02:29:39,537 [nnabla][INFO]: iter=2139 {Training error}=0.0\n",
            "2024-12-29 02:29:39,573 [nnabla][INFO]: iter=2149 {Training loss}=1.7044278138200752e-05\n",
            "2024-12-29 02:29:39,573 [nnabla][INFO]: iter=2149 {Training error}=0.0\n",
            "2024-12-29 02:29:39,610 [nnabla][INFO]: iter=2159 {Training loss}=1.8499669749871828e-05\n",
            "2024-12-29 02:29:39,611 [nnabla][INFO]: iter=2159 {Training error}=0.0\n",
            "2024-12-29 02:29:39,651 [nnabla][INFO]: iter=2169 {Training loss}=1.7894119082484394e-05\n",
            "2024-12-29 02:29:39,652 [nnabla][INFO]: iter=2169 {Training error}=0.0\n",
            "2024-12-29 02:29:39,694 [nnabla][INFO]: iter=2179 {Training loss}=1.6843176126712933e-05\n",
            "2024-12-29 02:29:39,694 [nnabla][INFO]: iter=2179 {Training error}=0.0\n",
            "2024-12-29 02:29:39,733 [nnabla][INFO]: iter=2189 {Training loss}=1.7091724657802843e-05\n",
            "2024-12-29 02:29:39,733 [nnabla][INFO]: iter=2189 {Training error}=0.0\n",
            "2024-12-29 02:29:39,770 [nnabla][INFO]: iter=2199 {Training loss}=1.708828131086193e-05\n",
            "2024-12-29 02:29:39,770 [nnabla][INFO]: iter=2199 {Training error}=0.0\n",
            "2024-12-29 02:29:39,770 [nnabla][INFO]: iter=2199 {Training time}=0.40668702125549316[sec/100iter] 13.271989107131958[sec]\n",
            "2024-12-29 02:29:39,793 [nnabla][INFO]: iter=2200 {Test error}=0.0140625\n",
            "2024-12-29 02:29:39,830 [nnabla][INFO]: iter=2209 {Training loss}=1.6400128515670076e-05\n",
            "2024-12-29 02:29:39,831 [nnabla][INFO]: iter=2209 {Training error}=0.0\n",
            "2024-12-29 02:29:39,868 [nnabla][INFO]: iter=2219 {Training loss}=1.7720811229082756e-05\n",
            "2024-12-29 02:29:39,869 [nnabla][INFO]: iter=2219 {Training error}=0.0\n",
            "2024-12-29 02:29:39,910 [nnabla][INFO]: iter=2229 {Training loss}=1.6093492376967333e-05\n",
            "2024-12-29 02:29:39,910 [nnabla][INFO]: iter=2229 {Training error}=0.0\n",
            "2024-12-29 02:29:39,948 [nnabla][INFO]: iter=2239 {Training loss}=1.5550620446447283e-05\n",
            "2024-12-29 02:29:39,948 [nnabla][INFO]: iter=2239 {Training error}=0.0\n",
            "2024-12-29 02:29:39,985 [nnabla][INFO]: iter=2249 {Training loss}=1.5996651200111955e-05\n",
            "2024-12-29 02:29:39,985 [nnabla][INFO]: iter=2249 {Training error}=0.0\n",
            "2024-12-29 02:29:40,022 [nnabla][INFO]: iter=2259 {Training loss}=1.7237096471944824e-05\n",
            "2024-12-29 02:29:40,022 [nnabla][INFO]: iter=2259 {Training error}=0.0\n",
            "2024-12-29 02:29:40,061 [nnabla][INFO]: iter=2269 {Training loss}=1.5166227058216464e-05\n",
            "2024-12-29 02:29:40,061 [nnabla][INFO]: iter=2269 {Training error}=0.0\n",
            "2024-12-29 02:29:40,099 [nnabla][INFO]: iter=2279 {Training loss}=1.539084769319743e-05\n",
            "2024-12-29 02:29:40,100 [nnabla][INFO]: iter=2279 {Training error}=0.0\n",
            "2024-12-29 02:29:40,137 [nnabla][INFO]: iter=2289 {Training loss}=1.5489498764509335e-05\n",
            "2024-12-29 02:29:40,138 [nnabla][INFO]: iter=2289 {Training error}=0.0\n",
            "2024-12-29 02:29:40,175 [nnabla][INFO]: iter=2299 {Training loss}=1.5166141565714497e-05\n",
            "2024-12-29 02:29:40,176 [nnabla][INFO]: iter=2299 {Training error}=0.0\n",
            "2024-12-29 02:29:40,176 [nnabla][INFO]: iter=2299 {Training time}=0.40568017959594727[sec/100iter] 13.677669286727905[sec]\n",
            "2024-12-29 02:29:40,199 [nnabla][INFO]: iter=2300 {Test error}=0.01484375\n",
            "2024-12-29 02:29:40,239 [nnabla][INFO]: iter=2309 {Training loss}=1.569474807183724e-05\n",
            "2024-12-29 02:29:40,239 [nnabla][INFO]: iter=2309 {Training error}=0.0\n",
            "2024-12-29 02:29:40,277 [nnabla][INFO]: iter=2319 {Training loss}=1.4917279258952476e-05\n",
            "2024-12-29 02:29:40,277 [nnabla][INFO]: iter=2319 {Training error}=0.0\n",
            "2024-12-29 02:29:40,318 [nnabla][INFO]: iter=2329 {Training loss}=1.4373700651049148e-05\n",
            "2024-12-29 02:29:40,318 [nnabla][INFO]: iter=2329 {Training error}=0.0\n",
            "2024-12-29 02:29:40,357 [nnabla][INFO]: iter=2339 {Training loss}=1.4979408661019988e-05\n",
            "2024-12-29 02:29:40,358 [nnabla][INFO]: iter=2339 {Training error}=0.0\n",
            "2024-12-29 02:29:40,397 [nnabla][INFO]: iter=2349 {Training loss}=1.471930772822816e-05\n",
            "2024-12-29 02:29:40,398 [nnabla][INFO]: iter=2349 {Training error}=0.0\n",
            "2024-12-29 02:29:40,437 [nnabla][INFO]: iter=2359 {Training loss}=1.4159098100208212e-05\n",
            "2024-12-29 02:29:40,438 [nnabla][INFO]: iter=2359 {Training error}=0.0\n",
            "2024-12-29 02:29:40,477 [nnabla][INFO]: iter=2369 {Training loss}=1.4608242963731755e-05\n",
            "2024-12-29 02:29:40,477 [nnabla][INFO]: iter=2369 {Training error}=0.0\n",
            "2024-12-29 02:29:40,517 [nnabla][INFO]: iter=2379 {Training loss}=1.365269417874515e-05\n",
            "2024-12-29 02:29:40,517 [nnabla][INFO]: iter=2379 {Training error}=0.0\n",
            "2024-12-29 02:29:40,555 [nnabla][INFO]: iter=2389 {Training loss}=1.3748709534411319e-05\n",
            "2024-12-29 02:29:40,556 [nnabla][INFO]: iter=2389 {Training error}=0.0\n",
            "2024-12-29 02:29:40,595 [nnabla][INFO]: iter=2399 {Training loss}=1.4172263036016375e-05\n",
            "2024-12-29 02:29:40,595 [nnabla][INFO]: iter=2399 {Training error}=0.0\n",
            "2024-12-29 02:29:40,595 [nnabla][INFO]: iter=2399 {Training time}=0.41919398307800293[sec/100iter] 14.096863269805908[sec]\n",
            "2024-12-29 02:29:40,620 [nnabla][INFO]: iter=2400 {Test error}=0.0140625\n",
            "2024-12-29 02:29:40,660 [nnabla][INFO]: iter=2409 {Training loss}=1.3543867680709809e-05\n",
            "2024-12-29 02:29:40,660 [nnabla][INFO]: iter=2409 {Training error}=0.0\n",
            "2024-12-29 02:29:40,699 [nnabla][INFO]: iter=2419 {Training loss}=1.3372127796174027e-05\n",
            "2024-12-29 02:29:40,699 [nnabla][INFO]: iter=2419 {Training error}=0.0\n",
            "2024-12-29 02:29:40,742 [nnabla][INFO]: iter=2429 {Training loss}=1.3840496649208944e-05\n",
            "2024-12-29 02:29:40,742 [nnabla][INFO]: iter=2429 {Training error}=0.0\n",
            "2024-12-29 02:29:40,780 [nnabla][INFO]: iter=2439 {Training loss}=1.3121019946993329e-05\n",
            "2024-12-29 02:29:40,781 [nnabla][INFO]: iter=2439 {Training error}=0.0\n",
            "2024-12-29 02:29:40,821 [nnabla][INFO]: iter=2449 {Training loss}=1.319372677244246e-05\n",
            "2024-12-29 02:29:40,821 [nnabla][INFO]: iter=2449 {Training error}=0.0\n",
            "2024-12-29 02:29:40,859 [nnabla][INFO]: iter=2459 {Training loss}=1.2860376955359243e-05\n",
            "2024-12-29 02:29:40,859 [nnabla][INFO]: iter=2459 {Training error}=0.0\n",
            "2024-12-29 02:29:40,898 [nnabla][INFO]: iter=2469 {Training loss}=1.3274935554363765e-05\n",
            "2024-12-29 02:29:40,898 [nnabla][INFO]: iter=2469 {Training error}=0.0\n",
            "2024-12-29 02:29:40,936 [nnabla][INFO]: iter=2479 {Training loss}=1.2273880201973952e-05\n",
            "2024-12-29 02:29:40,936 [nnabla][INFO]: iter=2479 {Training error}=0.0\n",
            "2024-12-29 02:29:40,974 [nnabla][INFO]: iter=2489 {Training loss}=1.3368054169404786e-05\n",
            "2024-12-29 02:29:40,974 [nnabla][INFO]: iter=2489 {Training error}=0.0\n",
            "2024-12-29 02:29:41,011 [nnabla][INFO]: iter=2499 {Training loss}=1.2173010873084422e-05\n",
            "2024-12-29 02:29:41,012 [nnabla][INFO]: iter=2499 {Training error}=0.0\n",
            "2024-12-29 02:29:41,012 [nnabla][INFO]: iter=2499 {Training time}=0.4167001247406006[sec/100iter] 14.513563394546509[sec]\n",
            "2024-12-29 02:29:41,039 [nnabla][INFO]: iter=2500 {Test error}=0.0140625\n",
            "2024-12-29 02:29:41,076 [nnabla][INFO]: iter=2509 {Training loss}=1.2486761079344433e-05\n",
            "2024-12-29 02:29:41,077 [nnabla][INFO]: iter=2509 {Training error}=0.0\n",
            "2024-12-29 02:29:41,114 [nnabla][INFO]: iter=2519 {Training loss}=1.2177817552583292e-05\n",
            "2024-12-29 02:29:41,114 [nnabla][INFO]: iter=2519 {Training error}=0.0\n",
            "2024-12-29 02:29:41,151 [nnabla][INFO]: iter=2529 {Training loss}=1.1890215318999253e-05\n",
            "2024-12-29 02:29:41,151 [nnabla][INFO]: iter=2529 {Training error}=0.0\n",
            "2024-12-29 02:29:41,189 [nnabla][INFO]: iter=2539 {Training loss}=1.249724482477177e-05\n",
            "2024-12-29 02:29:41,189 [nnabla][INFO]: iter=2539 {Training error}=0.0\n",
            "2024-12-29 02:29:41,227 [nnabla][INFO]: iter=2549 {Training loss}=1.184249049401842e-05\n",
            "2024-12-29 02:29:41,227 [nnabla][INFO]: iter=2549 {Training error}=0.0\n",
            "2024-12-29 02:29:41,265 [nnabla][INFO]: iter=2559 {Training loss}=1.1801577784353867e-05\n",
            "2024-12-29 02:29:41,265 [nnabla][INFO]: iter=2559 {Training error}=0.0\n",
            "2024-12-29 02:29:41,302 [nnabla][INFO]: iter=2569 {Training loss}=1.1471951438579708e-05\n",
            "2024-12-29 02:29:41,303 [nnabla][INFO]: iter=2569 {Training error}=0.0\n",
            "2024-12-29 02:29:41,343 [nnabla][INFO]: iter=2579 {Training loss}=1.2060332664987072e-05\n",
            "2024-12-29 02:29:41,343 [nnabla][INFO]: iter=2579 {Training error}=0.0\n",
            "2024-12-29 02:29:41,380 [nnabla][INFO]: iter=2589 {Training loss}=1.1617296877375338e-05\n",
            "2024-12-29 02:29:41,380 [nnabla][INFO]: iter=2589 {Training error}=0.0\n",
            "2024-12-29 02:29:41,417 [nnabla][INFO]: iter=2599 {Training loss}=1.0977430974890012e-05\n",
            "2024-12-29 02:29:41,417 [nnabla][INFO]: iter=2599 {Training error}=0.0\n",
            "2024-12-29 02:29:41,417 [nnabla][INFO]: iter=2599 {Training time}=0.40561723709106445[sec/100iter] 14.919180631637573[sec]\n",
            "2024-12-29 02:29:41,439 [nnabla][INFO]: iter=2600 {Test error}=0.01484375\n",
            "2024-12-29 02:29:41,476 [nnabla][INFO]: iter=2609 {Training loss}=1.153260291175684e-05\n",
            "2024-12-29 02:29:41,476 [nnabla][INFO]: iter=2609 {Training error}=0.0\n",
            "2024-12-29 02:29:41,513 [nnabla][INFO]: iter=2619 {Training loss}=1.0798732546390966e-05\n",
            "2024-12-29 02:29:41,513 [nnabla][INFO]: iter=2619 {Training error}=0.0\n",
            "2024-12-29 02:29:41,551 [nnabla][INFO]: iter=2629 {Training loss}=1.139786127168918e-05\n",
            "2024-12-29 02:29:41,551 [nnabla][INFO]: iter=2629 {Training error}=0.0\n",
            "2024-12-29 02:29:41,588 [nnabla][INFO]: iter=2639 {Training loss}=1.1077801900682971e-05\n",
            "2024-12-29 02:29:41,588 [nnabla][INFO]: iter=2639 {Training error}=0.0\n",
            "2024-12-29 02:29:41,625 [nnabla][INFO]: iter=2649 {Training loss}=1.0594420018605888e-05\n",
            "2024-12-29 02:29:41,625 [nnabla][INFO]: iter=2649 {Training error}=0.0\n",
            "2024-12-29 02:29:41,662 [nnabla][INFO]: iter=2659 {Training loss}=1.0989801921823528e-05\n",
            "2024-12-29 02:29:41,662 [nnabla][INFO]: iter=2659 {Training error}=0.0\n",
            "2024-12-29 02:29:41,698 [nnabla][INFO]: iter=2669 {Training loss}=1.086772681446746e-05\n",
            "2024-12-29 02:29:41,699 [nnabla][INFO]: iter=2669 {Training error}=0.0\n",
            "2024-12-29 02:29:41,736 [nnabla][INFO]: iter=2679 {Training loss}=1.0343452231609263e-05\n",
            "2024-12-29 02:29:41,737 [nnabla][INFO]: iter=2679 {Training error}=0.0\n",
            "2024-12-29 02:29:41,777 [nnabla][INFO]: iter=2689 {Training loss}=1.0329777069273405e-05\n",
            "2024-12-29 02:29:41,778 [nnabla][INFO]: iter=2689 {Training error}=0.0\n",
            "2024-12-29 02:29:41,816 [nnabla][INFO]: iter=2699 {Training loss}=1.0532571650401223e-05\n",
            "2024-12-29 02:29:41,816 [nnabla][INFO]: iter=2699 {Training error}=0.0\n",
            "2024-12-29 02:29:41,816 [nnabla][INFO]: iter=2699 {Training time}=0.39874792098999023[sec/100iter] 15.317928552627563[sec]\n",
            "2024-12-29 02:29:41,842 [nnabla][INFO]: iter=2700 {Test error}=0.0140625\n",
            "2024-12-29 02:29:41,879 [nnabla][INFO]: iter=2709 {Training loss}=1.0100422514369711e-05\n",
            "2024-12-29 02:29:41,880 [nnabla][INFO]: iter=2709 {Training error}=0.0\n",
            "2024-12-29 02:29:41,919 [nnabla][INFO]: iter=2719 {Training loss}=1.0386464055045508e-05\n",
            "2024-12-29 02:29:41,919 [nnabla][INFO]: iter=2719 {Training error}=0.0\n",
            "2024-12-29 02:29:41,957 [nnabla][INFO]: iter=2729 {Training loss}=1.0108960850629956e-05\n",
            "2024-12-29 02:29:41,957 [nnabla][INFO]: iter=2729 {Training error}=0.0\n",
            "2024-12-29 02:29:41,994 [nnabla][INFO]: iter=2739 {Training loss}=1.0092315278598107e-05\n",
            "2024-12-29 02:29:41,994 [nnabla][INFO]: iter=2739 {Training error}=0.0\n",
            "2024-12-29 02:29:42,035 [nnabla][INFO]: iter=2749 {Training loss}=9.881918231258169e-06\n",
            "2024-12-29 02:29:42,035 [nnabla][INFO]: iter=2749 {Training error}=0.0\n",
            "2024-12-29 02:29:42,072 [nnabla][INFO]: iter=2759 {Training loss}=9.730913006933406e-06\n",
            "2024-12-29 02:29:42,072 [nnabla][INFO]: iter=2759 {Training error}=0.0\n",
            "2024-12-29 02:29:42,109 [nnabla][INFO]: iter=2769 {Training loss}=9.459813554713037e-06\n",
            "2024-12-29 02:29:42,110 [nnabla][INFO]: iter=2769 {Training error}=0.0\n",
            "2024-12-29 02:29:42,147 [nnabla][INFO]: iter=2779 {Training loss}=9.98995437839767e-06\n",
            "2024-12-29 02:29:42,147 [nnabla][INFO]: iter=2779 {Training error}=0.0\n",
            "2024-12-29 02:29:42,184 [nnabla][INFO]: iter=2789 {Training loss}=9.72930411080597e-06\n",
            "2024-12-29 02:29:42,184 [nnabla][INFO]: iter=2789 {Training error}=0.0\n",
            "2024-12-29 02:29:42,223 [nnabla][INFO]: iter=2799 {Training loss}=9.209967174683698e-06\n",
            "2024-12-29 02:29:42,223 [nnabla][INFO]: iter=2799 {Training error}=0.0\n",
            "2024-12-29 02:29:42,223 [nnabla][INFO]: iter=2799 {Training time}=0.40702342987060547[sec/100iter] 15.724951982498169[sec]\n",
            "2024-12-29 02:29:42,246 [nnabla][INFO]: iter=2800 {Test error}=0.0140625\n",
            "2024-12-29 02:29:42,283 [nnabla][INFO]: iter=2809 {Training loss}=9.504780791758094e-06\n",
            "2024-12-29 02:29:42,283 [nnabla][INFO]: iter=2809 {Training error}=0.0\n",
            "2024-12-29 02:29:42,322 [nnabla][INFO]: iter=2819 {Training loss}=9.410267921339255e-06\n",
            "2024-12-29 02:29:42,322 [nnabla][INFO]: iter=2819 {Training error}=0.0\n",
            "2024-12-29 02:29:42,361 [nnabla][INFO]: iter=2829 {Training loss}=9.076896276383195e-06\n",
            "2024-12-29 02:29:42,361 [nnabla][INFO]: iter=2829 {Training error}=0.0\n",
            "2024-12-29 02:29:42,399 [nnabla][INFO]: iter=2839 {Training loss}=8.975724995252676e-06\n",
            "2024-12-29 02:29:42,399 [nnabla][INFO]: iter=2839 {Training error}=0.0\n",
            "2024-12-29 02:29:42,435 [nnabla][INFO]: iter=2849 {Training loss}=9.107363439397886e-06\n",
            "2024-12-29 02:29:42,435 [nnabla][INFO]: iter=2849 {Training error}=0.0\n",
            "2024-12-29 02:29:42,473 [nnabla][INFO]: iter=2859 {Training loss}=9.274680451198947e-06\n",
            "2024-12-29 02:29:42,473 [nnabla][INFO]: iter=2859 {Training error}=0.0\n",
            "2024-12-29 02:29:42,511 [nnabla][INFO]: iter=2869 {Training loss}=8.76604735822184e-06\n",
            "2024-12-29 02:29:42,511 [nnabla][INFO]: iter=2869 {Training error}=0.0\n",
            "2024-12-29 02:29:42,549 [nnabla][INFO]: iter=2879 {Training loss}=8.951070412877016e-06\n",
            "2024-12-29 02:29:42,549 [nnabla][INFO]: iter=2879 {Training error}=0.0\n",
            "2024-12-29 02:29:42,585 [nnabla][INFO]: iter=2889 {Training loss}=8.514616638422012e-06\n",
            "2024-12-29 02:29:42,585 [nnabla][INFO]: iter=2889 {Training error}=0.0\n",
            "2024-12-29 02:29:42,621 [nnabla][INFO]: iter=2899 {Training loss}=8.89287366589997e-06\n",
            "2024-12-29 02:29:42,622 [nnabla][INFO]: iter=2899 {Training error}=0.0\n",
            "2024-12-29 02:29:42,622 [nnabla][INFO]: iter=2899 {Training time}=0.3985922336578369[sec/100iter] 16.123544216156006[sec]\n",
            "2024-12-29 02:29:42,646 [nnabla][INFO]: iter=2900 {Test error}=0.0140625\n",
            "2024-12-29 02:29:42,683 [nnabla][INFO]: iter=2909 {Training loss}=8.702525519765913e-06\n",
            "2024-12-29 02:29:42,683 [nnabla][INFO]: iter=2909 {Training error}=0.0\n",
            "2024-12-29 02:29:42,719 [nnabla][INFO]: iter=2919 {Training loss}=8.584373063058592e-06\n",
            "2024-12-29 02:29:42,719 [nnabla][INFO]: iter=2919 {Training error}=0.0\n",
            "2024-12-29 02:29:42,756 [nnabla][INFO]: iter=2929 {Training loss}=8.357115802937187e-06\n",
            "2024-12-29 02:29:42,756 [nnabla][INFO]: iter=2929 {Training error}=0.0\n",
            "2024-12-29 02:29:42,796 [nnabla][INFO]: iter=2939 {Training loss}=8.184959369827993e-06\n",
            "2024-12-29 02:29:42,797 [nnabla][INFO]: iter=2939 {Training error}=0.0\n",
            "2024-12-29 02:29:42,835 [nnabla][INFO]: iter=2949 {Training loss}=8.469623026030604e-06\n",
            "2024-12-29 02:29:42,835 [nnabla][INFO]: iter=2949 {Training error}=0.0\n",
            "2024-12-29 02:29:42,872 [nnabla][INFO]: iter=2959 {Training loss}=8.153207090799697e-06\n",
            "2024-12-29 02:29:42,872 [nnabla][INFO]: iter=2959 {Training error}=0.0\n",
            "2024-12-29 02:29:42,909 [nnabla][INFO]: iter=2969 {Training loss}=8.336177415912971e-06\n",
            "2024-12-29 02:29:42,910 [nnabla][INFO]: iter=2969 {Training error}=0.0\n",
            "2024-12-29 02:29:42,949 [nnabla][INFO]: iter=2979 {Training loss}=8.106338100333232e-06\n",
            "2024-12-29 02:29:42,950 [nnabla][INFO]: iter=2979 {Training error}=0.0\n",
            "2024-12-29 02:29:42,987 [nnabla][INFO]: iter=2989 {Training loss}=7.95038249634672e-06\n",
            "2024-12-29 02:29:42,987 [nnabla][INFO]: iter=2989 {Training error}=0.0\n",
            "2024-12-29 02:29:43,024 [nnabla][INFO]: iter=2999 {Training loss}=8.121896826196462e-06\n",
            "2024-12-29 02:29:43,024 [nnabla][INFO]: iter=2999 {Training error}=0.0\n",
            "2024-12-29 02:29:43,024 [nnabla][INFO]: iter=2999 {Training time}=0.4023118019104004[sec/100iter] 16.525856018066406[sec]\n",
            "2024-12-29 02:29:43,049 [nnabla][INFO]: iter=3000 {Test error}=0.01484375\n",
            "2024-12-29 02:29:43,062 [nnabla][INFO]: Solver state save (.h5): output/states_3000.h5\n",
            "2024-12-29 02:29:43,068 [nnabla][INFO]: Parameter save (.h5): output/params_3000.h5\n",
            "2024-12-29 02:29:43,068 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_3000.json\n",
            "2024-12-29 02:29:43,106 [nnabla][INFO]: iter=3009 {Training loss}=7.624903901159996e-06\n",
            "2024-12-29 02:29:43,106 [nnabla][INFO]: iter=3009 {Training error}=0.0\n",
            "2024-12-29 02:29:43,145 [nnabla][INFO]: iter=3019 {Training loss}=7.79968650022056e-06\n",
            "2024-12-29 02:29:43,145 [nnabla][INFO]: iter=3019 {Training error}=0.0\n",
            "2024-12-29 02:29:43,184 [nnabla][INFO]: iter=3029 {Training loss}=8.0799027273315e-06\n",
            "2024-12-29 02:29:43,184 [nnabla][INFO]: iter=3029 {Training error}=0.0\n",
            "2024-12-29 02:29:43,223 [nnabla][INFO]: iter=3039 {Training loss}=7.613729394506663e-06\n",
            "2024-12-29 02:29:43,224 [nnabla][INFO]: iter=3039 {Training error}=0.0\n",
            "2024-12-29 02:29:43,262 [nnabla][INFO]: iter=3049 {Training loss}=7.481866305170115e-06\n",
            "2024-12-29 02:29:43,262 [nnabla][INFO]: iter=3049 {Training error}=0.0\n",
            "2024-12-29 02:29:43,300 [nnabla][INFO]: iter=3059 {Training loss}=7.690915481362026e-06\n",
            "2024-12-29 02:29:43,301 [nnabla][INFO]: iter=3059 {Training error}=0.0\n",
            "2024-12-29 02:29:43,338 [nnabla][INFO]: iter=3069 {Training loss}=7.428041953971842e-06\n",
            "2024-12-29 02:29:43,338 [nnabla][INFO]: iter=3069 {Training error}=0.0\n",
            "2024-12-29 02:29:43,379 [nnabla][INFO]: iter=3079 {Training loss}=7.461919267370831e-06\n",
            "2024-12-29 02:29:43,379 [nnabla][INFO]: iter=3079 {Training error}=0.0\n",
            "2024-12-29 02:29:43,417 [nnabla][INFO]: iter=3089 {Training loss}=7.127873686840758e-06\n",
            "2024-12-29 02:29:43,417 [nnabla][INFO]: iter=3089 {Training error}=0.0\n",
            "2024-12-29 02:29:43,454 [nnabla][INFO]: iter=3099 {Training loss}=7.486623417207738e-06\n",
            "2024-12-29 02:29:43,454 [nnabla][INFO]: iter=3099 {Training error}=0.0\n",
            "2024-12-29 02:29:43,454 [nnabla][INFO]: iter=3099 {Training time}=0.4304208755493164[sec/100iter] 16.956276893615723[sec]\n",
            "2024-12-29 02:29:43,477 [nnabla][INFO]: iter=3100 {Test error}=0.0140625\n",
            "2024-12-29 02:29:43,516 [nnabla][INFO]: iter=3109 {Training loss}=7.4059598773601465e-06\n",
            "2024-12-29 02:29:43,516 [nnabla][INFO]: iter=3109 {Training error}=0.0\n",
            "2024-12-29 02:29:43,554 [nnabla][INFO]: iter=3119 {Training loss}=7.084870503604179e-06\n",
            "2024-12-29 02:29:43,554 [nnabla][INFO]: iter=3119 {Training error}=0.0\n",
            "2024-12-29 02:29:43,591 [nnabla][INFO]: iter=3129 {Training loss}=7.001501217018813e-06\n",
            "2024-12-29 02:29:43,591 [nnabla][INFO]: iter=3129 {Training error}=0.0\n",
            "2024-12-29 02:29:43,629 [nnabla][INFO]: iter=3139 {Training loss}=7.1184940679813735e-06\n",
            "2024-12-29 02:29:43,629 [nnabla][INFO]: iter=3139 {Training error}=0.0\n",
            "2024-12-29 02:29:43,668 [nnabla][INFO]: iter=3149 {Training loss}=7.1841373028291855e-06\n",
            "2024-12-29 02:29:43,668 [nnabla][INFO]: iter=3149 {Training error}=0.0\n",
            "2024-12-29 02:29:43,705 [nnabla][INFO]: iter=3159 {Training loss}=6.88223462930182e-06\n",
            "2024-12-29 02:29:43,705 [nnabla][INFO]: iter=3159 {Training error}=0.0\n",
            "2024-12-29 02:29:43,742 [nnabla][INFO]: iter=3169 {Training loss}=6.99164002071484e-06\n",
            "2024-12-29 02:29:43,743 [nnabla][INFO]: iter=3169 {Training error}=0.0\n",
            "2024-12-29 02:29:43,780 [nnabla][INFO]: iter=3179 {Training loss}=6.787241090933094e-06\n",
            "2024-12-29 02:29:43,780 [nnabla][INFO]: iter=3179 {Training error}=0.0\n",
            "2024-12-29 02:29:43,822 [nnabla][INFO]: iter=3189 {Training loss}=6.840220066806069e-06\n",
            "2024-12-29 02:29:43,823 [nnabla][INFO]: iter=3189 {Training error}=0.0\n",
            "2024-12-29 02:29:43,861 [nnabla][INFO]: iter=3199 {Training loss}=6.627624770771945e-06\n",
            "2024-12-29 02:29:43,861 [nnabla][INFO]: iter=3199 {Training error}=0.0\n",
            "2024-12-29 02:29:43,861 [nnabla][INFO]: iter=3199 {Training time}=0.40674686431884766[sec/100iter] 17.36302375793457[sec]\n",
            "2024-12-29 02:29:43,886 [nnabla][INFO]: iter=3200 {Test error}=0.0140625\n",
            "2024-12-29 02:29:43,925 [nnabla][INFO]: iter=3209 {Training loss}=6.844958079454955e-06\n",
            "2024-12-29 02:29:43,925 [nnabla][INFO]: iter=3209 {Training error}=0.0\n",
            "2024-12-29 02:29:43,966 [nnabla][INFO]: iter=3219 {Training loss}=6.548564215336228e-06\n",
            "2024-12-29 02:29:43,966 [nnabla][INFO]: iter=3219 {Training error}=0.0\n",
            "2024-12-29 02:29:44,003 [nnabla][INFO]: iter=3229 {Training loss}=6.398343884939095e-06\n",
            "2024-12-29 02:29:44,003 [nnabla][INFO]: iter=3229 {Training error}=0.0\n",
            "2024-12-29 02:29:44,042 [nnabla][INFO]: iter=3239 {Training loss}=6.640001629421022e-06\n",
            "2024-12-29 02:29:44,042 [nnabla][INFO]: iter=3239 {Training error}=0.0\n",
            "2024-12-29 02:29:44,081 [nnabla][INFO]: iter=3249 {Training loss}=6.4377463786513545e-06\n",
            "2024-12-29 02:29:44,081 [nnabla][INFO]: iter=3249 {Training error}=0.0\n",
            "2024-12-29 02:29:44,118 [nnabla][INFO]: iter=3259 {Training loss}=6.530855898745358e-06\n",
            "2024-12-29 02:29:44,119 [nnabla][INFO]: iter=3259 {Training error}=0.0\n",
            "2024-12-29 02:29:44,155 [nnabla][INFO]: iter=3269 {Training loss}=6.354949618980754e-06\n",
            "2024-12-29 02:29:44,155 [nnabla][INFO]: iter=3269 {Training error}=0.0\n",
            "2024-12-29 02:29:44,192 [nnabla][INFO]: iter=3279 {Training loss}=6.383253094099928e-06\n",
            "2024-12-29 02:29:44,192 [nnabla][INFO]: iter=3279 {Training error}=0.0\n",
            "2024-12-29 02:29:44,230 [nnabla][INFO]: iter=3289 {Training loss}=6.112170467531541e-06\n",
            "2024-12-29 02:29:44,230 [nnabla][INFO]: iter=3289 {Training error}=0.0\n",
            "2024-12-29 02:29:44,269 [nnabla][INFO]: iter=3299 {Training loss}=6.162169938761508e-06\n",
            "2024-12-29 02:29:44,269 [nnabla][INFO]: iter=3299 {Training error}=0.0\n",
            "2024-12-29 02:29:44,269 [nnabla][INFO]: iter=3299 {Training time}=0.4078230857849121[sec/100iter] 17.770846843719482[sec]\n",
            "2024-12-29 02:29:44,291 [nnabla][INFO]: iter=3300 {Test error}=0.01484375\n",
            "2024-12-29 02:29:44,328 [nnabla][INFO]: iter=3309 {Training loss}=5.9725725805037655e-06\n",
            "2024-12-29 02:29:44,328 [nnabla][INFO]: iter=3309 {Training error}=0.0\n",
            "2024-12-29 02:29:44,365 [nnabla][INFO]: iter=3319 {Training loss}=6.474527708633104e-06\n",
            "2024-12-29 02:29:44,365 [nnabla][INFO]: iter=3319 {Training error}=0.0\n",
            "2024-12-29 02:29:44,401 [nnabla][INFO]: iter=3329 {Training loss}=6.068669790693093e-06\n",
            "2024-12-29 02:29:44,402 [nnabla][INFO]: iter=3329 {Training error}=0.0\n",
            "2024-12-29 02:29:44,440 [nnabla][INFO]: iter=3339 {Training loss}=5.955335836915765e-06\n",
            "2024-12-29 02:29:44,440 [nnabla][INFO]: iter=3339 {Training error}=0.0\n",
            "2024-12-29 02:29:44,478 [nnabla][INFO]: iter=3349 {Training loss}=5.961214355920674e-06\n",
            "2024-12-29 02:29:44,478 [nnabla][INFO]: iter=3349 {Training error}=0.0\n",
            "2024-12-29 02:29:44,515 [nnabla][INFO]: iter=3359 {Training loss}=5.980307378194993e-06\n",
            "2024-12-29 02:29:44,515 [nnabla][INFO]: iter=3359 {Training error}=0.0\n",
            "2024-12-29 02:29:44,552 [nnabla][INFO]: iter=3369 {Training loss}=5.726056315324968e-06\n",
            "2024-12-29 02:29:44,552 [nnabla][INFO]: iter=3369 {Training error}=0.0\n",
            "2024-12-29 02:29:44,589 [nnabla][INFO]: iter=3379 {Training loss}=5.812676590721821e-06\n",
            "2024-12-29 02:29:44,589 [nnabla][INFO]: iter=3379 {Training error}=0.0\n",
            "2024-12-29 02:29:44,625 [nnabla][INFO]: iter=3389 {Training loss}=5.821143076900626e-06\n",
            "2024-12-29 02:29:44,626 [nnabla][INFO]: iter=3389 {Training error}=0.0\n",
            "2024-12-29 02:29:44,663 [nnabla][INFO]: iter=3399 {Training loss}=5.799167865916388e-06\n",
            "2024-12-29 02:29:44,663 [nnabla][INFO]: iter=3399 {Training error}=0.0\n",
            "2024-12-29 02:29:44,663 [nnabla][INFO]: iter=3399 {Training time}=0.3940298557281494[sec/100iter] 18.164876699447632[sec]\n",
            "2024-12-29 02:29:44,685 [nnabla][INFO]: iter=3400 {Test error}=0.0140625\n",
            "2024-12-29 02:29:44,721 [nnabla][INFO]: iter=3409 {Training loss}=5.5708233048790134e-06\n",
            "2024-12-29 02:29:44,721 [nnabla][INFO]: iter=3409 {Training error}=0.0\n",
            "2024-12-29 02:29:44,761 [nnabla][INFO]: iter=3419 {Training loss}=5.800938197353389e-06\n",
            "2024-12-29 02:29:44,762 [nnabla][INFO]: iter=3419 {Training error}=0.0\n",
            "2024-12-29 02:29:44,798 [nnabla][INFO]: iter=3429 {Training loss}=5.534877800528193e-06\n",
            "2024-12-29 02:29:44,798 [nnabla][INFO]: iter=3429 {Training error}=0.0\n",
            "2024-12-29 02:29:44,838 [nnabla][INFO]: iter=3439 {Training loss}=5.591773515334353e-06\n",
            "2024-12-29 02:29:44,839 [nnabla][INFO]: iter=3439 {Training error}=0.0\n",
            "2024-12-29 02:29:44,877 [nnabla][INFO]: iter=3449 {Training loss}=5.577338015427813e-06\n",
            "2024-12-29 02:29:44,877 [nnabla][INFO]: iter=3449 {Training error}=0.0\n",
            "2024-12-29 02:29:44,914 [nnabla][INFO]: iter=3459 {Training loss}=5.44920203537913e-06\n",
            "2024-12-29 02:29:44,914 [nnabla][INFO]: iter=3459 {Training error}=0.0\n",
            "2024-12-29 02:29:44,953 [nnabla][INFO]: iter=3469 {Training loss}=5.53198833586066e-06\n",
            "2024-12-29 02:29:44,953 [nnabla][INFO]: iter=3469 {Training error}=0.0\n",
            "2024-12-29 02:29:44,990 [nnabla][INFO]: iter=3479 {Training loss}=5.2345408221299294e-06\n",
            "2024-12-29 02:29:44,990 [nnabla][INFO]: iter=3479 {Training error}=0.0\n",
            "2024-12-29 02:29:45,029 [nnabla][INFO]: iter=3489 {Training loss}=5.284361577650998e-06\n",
            "2024-12-29 02:29:45,029 [nnabla][INFO]: iter=3489 {Training error}=0.0\n",
            "2024-12-29 02:29:45,069 [nnabla][INFO]: iter=3499 {Training loss}=5.330364729161374e-06\n",
            "2024-12-29 02:29:45,069 [nnabla][INFO]: iter=3499 {Training error}=0.0\n",
            "2024-12-29 02:29:45,069 [nnabla][INFO]: iter=3499 {Training time}=0.4062795639038086[sec/100iter] 18.57115626335144[sec]\n",
            "2024-12-29 02:29:45,092 [nnabla][INFO]: iter=3500 {Test error}=0.0140625\n",
            "2024-12-29 02:29:45,131 [nnabla][INFO]: iter=3509 {Training loss}=5.338104529073462e-06\n",
            "2024-12-29 02:29:45,131 [nnabla][INFO]: iter=3509 {Training error}=0.0\n",
            "2024-12-29 02:29:45,167 [nnabla][INFO]: iter=3519 {Training loss}=5.201857675274368e-06\n",
            "2024-12-29 02:29:45,168 [nnabla][INFO]: iter=3519 {Training error}=0.0\n",
            "2024-12-29 02:29:45,205 [nnabla][INFO]: iter=3529 {Training loss}=5.14923067385098e-06\n",
            "2024-12-29 02:29:45,205 [nnabla][INFO]: iter=3529 {Training error}=0.0\n",
            "2024-12-29 02:29:45,242 [nnabla][INFO]: iter=3539 {Training loss}=5.12920905748615e-06\n",
            "2024-12-29 02:29:45,242 [nnabla][INFO]: iter=3539 {Training error}=0.0\n",
            "2024-12-29 02:29:45,282 [nnabla][INFO]: iter=3549 {Training loss}=5.187976057641208e-06\n",
            "2024-12-29 02:29:45,282 [nnabla][INFO]: iter=3549 {Training error}=0.0\n",
            "2024-12-29 02:29:45,319 [nnabla][INFO]: iter=3559 {Training loss}=4.953856659994926e-06\n",
            "2024-12-29 02:29:45,320 [nnabla][INFO]: iter=3559 {Training error}=0.0\n",
            "2024-12-29 02:29:45,356 [nnabla][INFO]: iter=3569 {Training loss}=5.08563562107156e-06\n",
            "2024-12-29 02:29:45,356 [nnabla][INFO]: iter=3569 {Training error}=0.0\n",
            "2024-12-29 02:29:45,392 [nnabla][INFO]: iter=3579 {Training loss}=4.982723112334497e-06\n",
            "2024-12-29 02:29:45,393 [nnabla][INFO]: iter=3579 {Training error}=0.0\n",
            "2024-12-29 02:29:45,429 [nnabla][INFO]: iter=3589 {Training loss}=4.742268629343016e-06\n",
            "2024-12-29 02:29:45,429 [nnabla][INFO]: iter=3589 {Training error}=0.0\n",
            "2024-12-29 02:29:45,467 [nnabla][INFO]: iter=3599 {Training loss}=4.957205874234205e-06\n",
            "2024-12-29 02:29:45,468 [nnabla][INFO]: iter=3599 {Training error}=0.0\n",
            "2024-12-29 02:29:45,468 [nnabla][INFO]: iter=3599 {Training time}=0.3984827995300293[sec/100iter] 18.96963906288147[sec]\n",
            "2024-12-29 02:29:45,490 [nnabla][INFO]: iter=3600 {Test error}=0.0140625\n",
            "2024-12-29 02:29:45,526 [nnabla][INFO]: iter=3609 {Training loss}=4.760801857628394e-06\n",
            "2024-12-29 02:29:45,526 [nnabla][INFO]: iter=3609 {Training error}=0.0\n",
            "2024-12-29 02:29:45,563 [nnabla][INFO]: iter=3619 {Training loss}=5.007309937354876e-06\n",
            "2024-12-29 02:29:45,564 [nnabla][INFO]: iter=3619 {Training error}=0.0\n",
            "2024-12-29 02:29:45,602 [nnabla][INFO]: iter=3629 {Training loss}=4.86361341245356e-06\n",
            "2024-12-29 02:29:45,603 [nnabla][INFO]: iter=3629 {Training error}=0.0\n",
            "2024-12-29 02:29:45,640 [nnabla][INFO]: iter=3639 {Training loss}=4.711259862233419e-06\n",
            "2024-12-29 02:29:45,640 [nnabla][INFO]: iter=3639 {Training error}=0.0\n",
            "2024-12-29 02:29:45,676 [nnabla][INFO]: iter=3649 {Training loss}=4.574546892399667e-06\n",
            "2024-12-29 02:29:45,676 [nnabla][INFO]: iter=3649 {Training error}=0.0\n",
            "2024-12-29 02:29:45,712 [nnabla][INFO]: iter=3659 {Training loss}=4.919487764709629e-06\n",
            "2024-12-29 02:29:45,712 [nnabla][INFO]: iter=3659 {Training error}=0.0\n",
            "2024-12-29 02:29:45,749 [nnabla][INFO]: iter=3669 {Training loss}=4.631449883163441e-06\n",
            "2024-12-29 02:29:45,749 [nnabla][INFO]: iter=3669 {Training error}=0.0\n",
            "2024-12-29 02:29:45,788 [nnabla][INFO]: iter=3679 {Training loss}=4.490359970077407e-06\n",
            "2024-12-29 02:29:45,788 [nnabla][INFO]: iter=3679 {Training error}=0.0\n",
            "2024-12-29 02:29:45,826 [nnabla][INFO]: iter=3689 {Training loss}=4.596988219418563e-06\n",
            "2024-12-29 02:29:45,826 [nnabla][INFO]: iter=3689 {Training error}=0.0\n",
            "2024-12-29 02:29:45,865 [nnabla][INFO]: iter=3699 {Training loss}=4.48495984528563e-06\n",
            "2024-12-29 02:29:45,865 [nnabla][INFO]: iter=3699 {Training error}=0.0\n",
            "2024-12-29 02:29:45,866 [nnabla][INFO]: iter=3699 {Training time}=0.39788389205932617[sec/100iter] 19.367522954940796[sec]\n",
            "2024-12-29 02:29:45,891 [nnabla][INFO]: iter=3700 {Test error}=0.01484375\n",
            "2024-12-29 02:29:45,928 [nnabla][INFO]: iter=3709 {Training loss}=4.435881237441208e-06\n",
            "2024-12-29 02:29:45,929 [nnabla][INFO]: iter=3709 {Training error}=0.0\n",
            "2024-12-29 02:29:45,968 [nnabla][INFO]: iter=3719 {Training loss}=4.609281859302428e-06\n",
            "2024-12-29 02:29:45,968 [nnabla][INFO]: iter=3719 {Training error}=0.0\n",
            "2024-12-29 02:29:46,007 [nnabla][INFO]: iter=3729 {Training loss}=4.4251655708649196e-06\n",
            "2024-12-29 02:29:46,007 [nnabla][INFO]: iter=3729 {Training error}=0.0\n",
            "2024-12-29 02:29:46,046 [nnabla][INFO]: iter=3739 {Training loss}=4.471452484722249e-06\n",
            "2024-12-29 02:29:46,046 [nnabla][INFO]: iter=3739 {Training error}=0.0\n",
            "2024-12-29 02:29:46,085 [nnabla][INFO]: iter=3749 {Training loss}=4.459904630493838e-06\n",
            "2024-12-29 02:29:46,086 [nnabla][INFO]: iter=3749 {Training error}=0.0\n",
            "2024-12-29 02:29:46,123 [nnabla][INFO]: iter=3759 {Training loss}=4.173170054855291e-06\n",
            "2024-12-29 02:29:46,123 [nnabla][INFO]: iter=3759 {Training error}=0.0\n",
            "2024-12-29 02:29:46,162 [nnabla][INFO]: iter=3769 {Training loss}=4.5042311285214964e-06\n",
            "2024-12-29 02:29:46,162 [nnabla][INFO]: iter=3769 {Training error}=0.0\n",
            "2024-12-29 02:29:46,200 [nnabla][INFO]: iter=3779 {Training loss}=4.162828190601431e-06\n",
            "2024-12-29 02:29:46,200 [nnabla][INFO]: iter=3779 {Training error}=0.0\n",
            "2024-12-29 02:29:46,238 [nnabla][INFO]: iter=3789 {Training loss}=4.3176032704650424e-06\n",
            "2024-12-29 02:29:46,238 [nnabla][INFO]: iter=3789 {Training error}=0.0\n",
            "2024-12-29 02:29:46,278 [nnabla][INFO]: iter=3799 {Training loss}=4.157149305683561e-06\n",
            "2024-12-29 02:29:46,278 [nnabla][INFO]: iter=3799 {Training error}=0.0\n",
            "2024-12-29 02:29:46,278 [nnabla][INFO]: iter=3799 {Training time}=0.4123380184173584[sec/100iter] 19.779860973358154[sec]\n",
            "2024-12-29 02:29:46,302 [nnabla][INFO]: iter=3800 {Test error}=0.0140625\n",
            "2024-12-29 02:29:46,339 [nnabla][INFO]: iter=3809 {Training loss}=4.093261850357521e-06\n",
            "2024-12-29 02:29:46,340 [nnabla][INFO]: iter=3809 {Training error}=0.0\n",
            "2024-12-29 02:29:46,381 [nnabla][INFO]: iter=3819 {Training loss}=4.2526967263256665e-06\n",
            "2024-12-29 02:29:46,381 [nnabla][INFO]: iter=3819 {Training error}=0.0\n",
            "2024-12-29 02:29:46,420 [nnabla][INFO]: iter=3829 {Training loss}=4.036359769088449e-06\n",
            "2024-12-29 02:29:46,420 [nnabla][INFO]: iter=3829 {Training error}=0.0\n",
            "2024-12-29 02:29:46,457 [nnabla][INFO]: iter=3839 {Training loss}=4.105086645722622e-06\n",
            "2024-12-29 02:29:46,457 [nnabla][INFO]: iter=3839 {Training error}=0.0\n",
            "2024-12-29 02:29:46,499 [nnabla][INFO]: iter=3849 {Training loss}=4.174282366875559e-06\n",
            "2024-12-29 02:29:46,499 [nnabla][INFO]: iter=3849 {Training error}=0.0\n",
            "2024-12-29 02:29:46,535 [nnabla][INFO]: iter=3859 {Training loss}=3.922276846424211e-06\n",
            "2024-12-29 02:29:46,535 [nnabla][INFO]: iter=3859 {Training error}=0.0\n",
            "2024-12-29 02:29:46,572 [nnabla][INFO]: iter=3869 {Training loss}=4.095962140127085e-06\n",
            "2024-12-29 02:29:46,572 [nnabla][INFO]: iter=3869 {Training error}=0.0\n",
            "2024-12-29 02:29:46,609 [nnabla][INFO]: iter=3879 {Training loss}=3.775505774683552e-06\n",
            "2024-12-29 02:29:46,609 [nnabla][INFO]: iter=3879 {Training error}=0.0\n",
            "2024-12-29 02:29:46,645 [nnabla][INFO]: iter=3889 {Training loss}=4.064948370796628e-06\n",
            "2024-12-29 02:29:46,646 [nnabla][INFO]: iter=3889 {Training error}=0.0\n",
            "2024-12-29 02:29:46,684 [nnabla][INFO]: iter=3899 {Training loss}=4.07743027608376e-06\n",
            "2024-12-29 02:29:46,684 [nnabla][INFO]: iter=3899 {Training error}=0.0\n",
            "2024-12-29 02:29:46,684 [nnabla][INFO]: iter=3899 {Training time}=0.4059925079345703[sec/100iter] 20.185853481292725[sec]\n",
            "2024-12-29 02:29:46,706 [nnabla][INFO]: iter=3900 {Test error}=0.0140625\n",
            "2024-12-29 02:29:46,743 [nnabla][INFO]: iter=3909 {Training loss}=3.7729914765805006e-06\n",
            "2024-12-29 02:29:46,743 [nnabla][INFO]: iter=3909 {Training error}=0.0\n",
            "2024-12-29 02:29:46,780 [nnabla][INFO]: iter=3919 {Training loss}=3.9376427594106644e-06\n",
            "2024-12-29 02:29:46,780 [nnabla][INFO]: iter=3919 {Training error}=0.0\n",
            "2024-12-29 02:29:46,819 [nnabla][INFO]: iter=3929 {Training loss}=3.7598620110657066e-06\n",
            "2024-12-29 02:29:46,820 [nnabla][INFO]: iter=3929 {Training error}=0.0\n",
            "2024-12-29 02:29:46,857 [nnabla][INFO]: iter=3939 {Training loss}=3.6842425288341474e-06\n",
            "2024-12-29 02:29:46,857 [nnabla][INFO]: iter=3939 {Training error}=0.0\n",
            "2024-12-29 02:29:46,900 [nnabla][INFO]: iter=3949 {Training loss}=3.849634140351554e-06\n",
            "2024-12-29 02:29:46,900 [nnabla][INFO]: iter=3949 {Training error}=0.0\n",
            "2024-12-29 02:29:46,939 [nnabla][INFO]: iter=3959 {Training loss}=3.7481252093130024e-06\n",
            "2024-12-29 02:29:46,939 [nnabla][INFO]: iter=3959 {Training error}=0.0\n",
            "2024-12-29 02:29:46,975 [nnabla][INFO]: iter=3969 {Training loss}=3.807822167800623e-06\n",
            "2024-12-29 02:29:46,975 [nnabla][INFO]: iter=3969 {Training error}=0.0\n",
            "2024-12-29 02:29:47,012 [nnabla][INFO]: iter=3979 {Training loss}=3.5578639199229656e-06\n",
            "2024-12-29 02:29:47,013 [nnabla][INFO]: iter=3979 {Training error}=0.0\n",
            "2024-12-29 02:29:47,050 [nnabla][INFO]: iter=3989 {Training loss}=3.659190497273812e-06\n",
            "2024-12-29 02:29:47,051 [nnabla][INFO]: iter=3989 {Training error}=0.0\n",
            "2024-12-29 02:29:47,090 [nnabla][INFO]: iter=3999 {Training loss}=3.6688743421109393e-06\n",
            "2024-12-29 02:29:47,091 [nnabla][INFO]: iter=3999 {Training error}=0.0\n",
            "2024-12-29 02:29:47,091 [nnabla][INFO]: iter=3999 {Training time}=0.40666723251342773[sec/100iter] 20.592520713806152[sec]\n",
            "2024-12-29 02:29:47,115 [nnabla][INFO]: iter=4000 {Test error}=0.01484375\n",
            "2024-12-29 02:29:47,132 [nnabla][INFO]: Solver state save (.h5): output/states_4000.h5\n",
            "2024-12-29 02:29:47,139 [nnabla][INFO]: Parameter save (.h5): output/params_4000.h5\n",
            "2024-12-29 02:29:47,139 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_4000.json\n",
            "2024-12-29 02:29:47,178 [nnabla][INFO]: iter=4009 {Training loss}=3.685451474666479e-06\n",
            "2024-12-29 02:29:47,178 [nnabla][INFO]: iter=4009 {Training error}=0.0\n",
            "2024-12-29 02:29:47,218 [nnabla][INFO]: iter=4019 {Training loss}=3.464735300440225e-06\n",
            "2024-12-29 02:29:47,218 [nnabla][INFO]: iter=4019 {Training error}=0.0\n",
            "2024-12-29 02:29:47,256 [nnabla][INFO]: iter=4029 {Training loss}=3.63544063475274e-06\n",
            "2024-12-29 02:29:47,256 [nnabla][INFO]: iter=4029 {Training error}=0.0\n",
            "2024-12-29 02:29:47,295 [nnabla][INFO]: iter=4039 {Training loss}=3.528620709403185e-06\n",
            "2024-12-29 02:29:47,295 [nnabla][INFO]: iter=4039 {Training error}=0.0\n",
            "2024-12-29 02:29:47,334 [nnabla][INFO]: iter=4049 {Training loss}=3.518380253808573e-06\n",
            "2024-12-29 02:29:47,334 [nnabla][INFO]: iter=4049 {Training error}=0.0\n",
            "2024-12-29 02:29:47,370 [nnabla][INFO]: iter=4059 {Training loss}=3.496771114441799e-06\n",
            "2024-12-29 02:29:47,371 [nnabla][INFO]: iter=4059 {Training error}=0.0\n",
            "2024-12-29 02:29:47,408 [nnabla][INFO]: iter=4069 {Training loss}=3.456262902545859e-06\n",
            "2024-12-29 02:29:47,408 [nnabla][INFO]: iter=4069 {Training error}=0.0\n",
            "2024-12-29 02:29:47,446 [nnabla][INFO]: iter=4079 {Training loss}=3.342458512634039e-06\n",
            "2024-12-29 02:29:47,446 [nnabla][INFO]: iter=4079 {Training error}=0.0\n",
            "2024-12-29 02:29:47,483 [nnabla][INFO]: iter=4089 {Training loss}=3.4717199923761655e-06\n",
            "2024-12-29 02:29:47,483 [nnabla][INFO]: iter=4089 {Training error}=0.0\n",
            "2024-12-29 02:29:47,523 [nnabla][INFO]: iter=4099 {Training loss}=3.4552365377749084e-06\n",
            "2024-12-29 02:29:47,523 [nnabla][INFO]: iter=4099 {Training error}=0.0\n",
            "2024-12-29 02:29:47,523 [nnabla][INFO]: iter=4099 {Training time}=0.4323756694793701[sec/100iter] 21.024896383285522[sec]\n",
            "2024-12-29 02:29:47,546 [nnabla][INFO]: iter=4100 {Test error}=0.0140625\n",
            "2024-12-29 02:29:47,583 [nnabla][INFO]: iter=4109 {Training loss}=3.380363295946154e-06\n",
            "2024-12-29 02:29:47,583 [nnabla][INFO]: iter=4109 {Training error}=0.0\n",
            "2024-12-29 02:29:47,621 [nnabla][INFO]: iter=4119 {Training loss}=3.2753100640547927e-06\n",
            "2024-12-29 02:29:47,622 [nnabla][INFO]: iter=4119 {Training error}=0.0\n",
            "2024-12-29 02:29:47,659 [nnabla][INFO]: iter=4129 {Training loss}=3.2727050438552396e-06\n",
            "2024-12-29 02:29:47,660 [nnabla][INFO]: iter=4129 {Training error}=0.0\n",
            "2024-12-29 02:29:47,699 [nnabla][INFO]: iter=4139 {Training loss}=3.3388241718057543e-06\n",
            "2024-12-29 02:29:47,699 [nnabla][INFO]: iter=4139 {Training error}=0.0\n",
            "2024-12-29 02:29:47,737 [nnabla][INFO]: iter=4149 {Training loss}=3.2284656299452763e-06\n",
            "2024-12-29 02:29:47,737 [nnabla][INFO]: iter=4149 {Training error}=0.0\n",
            "2024-12-29 02:29:47,775 [nnabla][INFO]: iter=4159 {Training loss}=3.2433697469969047e-06\n",
            "2024-12-29 02:29:47,775 [nnabla][INFO]: iter=4159 {Training error}=0.0\n",
            "2024-12-29 02:29:47,815 [nnabla][INFO]: iter=4169 {Training loss}=3.1262134143617004e-06\n",
            "2024-12-29 02:29:47,816 [nnabla][INFO]: iter=4169 {Training error}=0.0\n",
            "2024-12-29 02:29:47,856 [nnabla][INFO]: iter=4179 {Training loss}=3.277918267485802e-06\n",
            "2024-12-29 02:29:47,856 [nnabla][INFO]: iter=4179 {Training error}=0.0\n",
            "2024-12-29 02:29:47,903 [nnabla][INFO]: iter=4189 {Training loss}=3.220271992177004e-06\n",
            "2024-12-29 02:29:47,903 [nnabla][INFO]: iter=4189 {Training error}=0.0\n",
            "2024-12-29 02:29:47,966 [nnabla][INFO]: iter=4199 {Training loss}=3.1629065233573783e-06\n",
            "2024-12-29 02:29:47,966 [nnabla][INFO]: iter=4199 {Training error}=0.0\n",
            "2024-12-29 02:29:47,967 [nnabla][INFO]: iter=4199 {Training time}=0.44352149963378906[sec/100iter] 21.46841788291931[sec]\n",
            "2024-12-29 02:29:47,999 [nnabla][INFO]: iter=4200 {Test error}=0.0140625\n",
            "2024-12-29 02:29:48,048 [nnabla][INFO]: iter=4209 {Training loss}=2.9994637316121953e-06\n",
            "2024-12-29 02:29:48,048 [nnabla][INFO]: iter=4209 {Training error}=0.0\n",
            "2024-12-29 02:29:48,095 [nnabla][INFO]: iter=4219 {Training loss}=3.185533842042787e-06\n",
            "2024-12-29 02:29:48,096 [nnabla][INFO]: iter=4219 {Training error}=0.0\n",
            "2024-12-29 02:29:48,140 [nnabla][INFO]: iter=4229 {Training loss}=3.159086190862581e-06\n",
            "2024-12-29 02:29:48,140 [nnabla][INFO]: iter=4229 {Training error}=0.0\n",
            "2024-12-29 02:29:48,185 [nnabla][INFO]: iter=4239 {Training loss}=2.9853054002160206e-06\n",
            "2024-12-29 02:29:48,185 [nnabla][INFO]: iter=4239 {Training error}=0.0\n",
            "2024-12-29 02:29:48,234 [nnabla][INFO]: iter=4249 {Training loss}=3.0977166716184e-06\n",
            "2024-12-29 02:29:48,235 [nnabla][INFO]: iter=4249 {Training error}=0.0\n",
            "2024-12-29 02:29:48,279 [nnabla][INFO]: iter=4259 {Training loss}=3.050310169783188e-06\n",
            "2024-12-29 02:29:48,280 [nnabla][INFO]: iter=4259 {Training error}=0.0\n",
            "2024-12-29 02:29:48,331 [nnabla][INFO]: iter=4269 {Training loss}=2.9501989047275856e-06\n",
            "2024-12-29 02:29:48,331 [nnabla][INFO]: iter=4269 {Training error}=0.0\n",
            "2024-12-29 02:29:48,374 [nnabla][INFO]: iter=4279 {Training loss}=3.0043040624150308e-06\n",
            "2024-12-29 02:29:48,375 [nnabla][INFO]: iter=4279 {Training error}=0.0\n",
            "2024-12-29 02:29:48,418 [nnabla][INFO]: iter=4289 {Training loss}=2.919653070421191e-06\n",
            "2024-12-29 02:29:48,419 [nnabla][INFO]: iter=4289 {Training error}=0.0\n",
            "2024-12-29 02:29:48,464 [nnabla][INFO]: iter=4299 {Training loss}=2.894600129366154e-06\n",
            "2024-12-29 02:29:48,464 [nnabla][INFO]: iter=4299 {Training error}=0.0\n",
            "2024-12-29 02:29:48,465 [nnabla][INFO]: iter=4299 {Training time}=0.49797606468200684[sec/100iter] 21.96639394760132[sec]\n",
            "2024-12-29 02:29:48,491 [nnabla][INFO]: iter=4300 {Test error}=0.0140625\n",
            "2024-12-29 02:29:48,536 [nnabla][INFO]: iter=4309 {Training loss}=2.9176010230003158e-06\n",
            "2024-12-29 02:29:48,536 [nnabla][INFO]: iter=4309 {Training error}=0.0\n",
            "2024-12-29 02:29:48,577 [nnabla][INFO]: iter=4319 {Training loss}=2.9760874440398766e-06\n",
            "2024-12-29 02:29:48,577 [nnabla][INFO]: iter=4319 {Training error}=0.0\n",
            "2024-12-29 02:29:48,622 [nnabla][INFO]: iter=4329 {Training loss}=2.9145292046450777e-06\n",
            "2024-12-29 02:29:48,623 [nnabla][INFO]: iter=4329 {Training error}=0.0\n",
            "2024-12-29 02:29:48,664 [nnabla][INFO]: iter=4339 {Training loss}=2.8037047741236165e-06\n",
            "2024-12-29 02:29:48,664 [nnabla][INFO]: iter=4339 {Training error}=0.0\n",
            "2024-12-29 02:29:48,705 [nnabla][INFO]: iter=4349 {Training loss}=2.89087392957299e-06\n",
            "2024-12-29 02:29:48,705 [nnabla][INFO]: iter=4349 {Training error}=0.0\n",
            "2024-12-29 02:29:48,747 [nnabla][INFO]: iter=4359 {Training loss}=2.7633807349047856e-06\n",
            "2024-12-29 02:29:48,748 [nnabla][INFO]: iter=4359 {Training error}=0.0\n",
            "2024-12-29 02:29:48,790 [nnabla][INFO]: iter=4369 {Training loss}=2.6462223559065023e-06\n",
            "2024-12-29 02:29:48,790 [nnabla][INFO]: iter=4369 {Training error}=0.0\n",
            "2024-12-29 02:29:48,833 [nnabla][INFO]: iter=4379 {Training loss}=2.8538083824969362e-06\n",
            "2024-12-29 02:29:48,834 [nnabla][INFO]: iter=4379 {Training error}=0.0\n",
            "2024-12-29 02:29:48,876 [nnabla][INFO]: iter=4389 {Training loss}=2.739725914580049e-06\n",
            "2024-12-29 02:29:48,876 [nnabla][INFO]: iter=4389 {Training error}=0.0\n",
            "2024-12-29 02:29:48,925 [nnabla][INFO]: iter=4399 {Training loss}=2.773530468402896e-06\n",
            "2024-12-29 02:29:48,926 [nnabla][INFO]: iter=4399 {Training error}=0.0\n",
            "2024-12-29 02:29:48,926 [nnabla][INFO]: iter=4399 {Training time}=0.46129918098449707[sec/100iter] 22.427693128585815[sec]\n",
            "2024-12-29 02:29:48,956 [nnabla][INFO]: iter=4400 {Test error}=0.01484375\n",
            "2024-12-29 02:29:49,013 [nnabla][INFO]: iter=4409 {Training loss}=2.785730885079829e-06\n",
            "2024-12-29 02:29:49,015 [nnabla][INFO]: iter=4409 {Training error}=0.0\n",
            "2024-12-29 02:29:49,058 [nnabla][INFO]: iter=4419 {Training loss}=2.596678541522124e-06\n",
            "2024-12-29 02:29:49,058 [nnabla][INFO]: iter=4419 {Training error}=0.0\n",
            "2024-12-29 02:29:49,101 [nnabla][INFO]: iter=4429 {Training loss}=2.7476405648485525e-06\n",
            "2024-12-29 02:29:49,101 [nnabla][INFO]: iter=4429 {Training error}=0.0\n",
            "2024-12-29 02:29:49,147 [nnabla][INFO]: iter=4439 {Training loss}=2.6476204766368028e-06\n",
            "2024-12-29 02:29:49,147 [nnabla][INFO]: iter=4439 {Training error}=0.0\n",
            "2024-12-29 02:29:49,190 [nnabla][INFO]: iter=4449 {Training loss}=2.666617092472734e-06\n",
            "2024-12-29 02:29:49,190 [nnabla][INFO]: iter=4449 {Training error}=0.0\n",
            "2024-12-29 02:29:49,240 [nnabla][INFO]: iter=4459 {Training loss}=2.678166538316873e-06\n",
            "2024-12-29 02:29:49,241 [nnabla][INFO]: iter=4459 {Training error}=0.0\n",
            "2024-12-29 02:29:49,304 [nnabla][INFO]: iter=4469 {Training loss}=2.6194006750301924e-06\n",
            "2024-12-29 02:29:49,304 [nnabla][INFO]: iter=4469 {Training error}=0.0\n",
            "2024-12-29 02:29:49,355 [nnabla][INFO]: iter=4479 {Training loss}=2.4685330117790727e-06\n",
            "2024-12-29 02:29:49,355 [nnabla][INFO]: iter=4479 {Training error}=0.0\n",
            "2024-12-29 02:29:49,400 [nnabla][INFO]: iter=4489 {Training loss}=2.647805786182289e-06\n",
            "2024-12-29 02:29:49,401 [nnabla][INFO]: iter=4489 {Training error}=0.0\n",
            "2024-12-29 02:29:49,443 [nnabla][INFO]: iter=4499 {Training loss}=2.4825017135299277e-06\n",
            "2024-12-29 02:29:49,443 [nnabla][INFO]: iter=4499 {Training error}=0.0\n",
            "2024-12-29 02:29:49,444 [nnabla][INFO]: iter=4499 {Training time}=0.5177600383758545[sec/100iter] 22.94545316696167[sec]\n",
            "2024-12-29 02:29:49,471 [nnabla][INFO]: iter=4500 {Test error}=0.0140625\n",
            "2024-12-29 02:29:49,514 [nnabla][INFO]: iter=4509 {Training loss}=2.5645467758295126e-06\n",
            "2024-12-29 02:29:49,515 [nnabla][INFO]: iter=4509 {Training error}=0.0\n",
            "2024-12-29 02:29:49,566 [nnabla][INFO]: iter=4519 {Training loss}=2.5554211333655985e-06\n",
            "2024-12-29 02:29:49,566 [nnabla][INFO]: iter=4519 {Training error}=0.0\n",
            "2024-12-29 02:29:49,610 [nnabla][INFO]: iter=4529 {Training loss}=2.5123013074335176e-06\n",
            "2024-12-29 02:29:49,610 [nnabla][INFO]: iter=4529 {Training error}=0.0\n",
            "2024-12-29 02:29:49,658 [nnabla][INFO]: iter=4539 {Training loss}=2.4978687633847585e-06\n",
            "2024-12-29 02:29:49,659 [nnabla][INFO]: iter=4539 {Training error}=0.0\n",
            "2024-12-29 02:29:49,706 [nnabla][INFO]: iter=4549 {Training loss}=2.4853873128449777e-06\n",
            "2024-12-29 02:29:49,706 [nnabla][INFO]: iter=4549 {Training error}=0.0\n",
            "2024-12-29 02:29:49,752 [nnabla][INFO]: iter=4559 {Training loss}=2.4857617972884327e-06\n",
            "2024-12-29 02:29:49,753 [nnabla][INFO]: iter=4559 {Training error}=0.0\n",
            "2024-12-29 02:29:49,799 [nnabla][INFO]: iter=4569 {Training loss}=2.417495352347032e-06\n",
            "2024-12-29 02:29:49,799 [nnabla][INFO]: iter=4569 {Training error}=0.0\n",
            "2024-12-29 02:29:49,846 [nnabla][INFO]: iter=4579 {Training loss}=2.3822008188290056e-06\n",
            "2024-12-29 02:29:49,846 [nnabla][INFO]: iter=4579 {Training error}=0.0\n",
            "2024-12-29 02:29:49,888 [nnabla][INFO]: iter=4589 {Training loss}=2.373259576415876e-06\n",
            "2024-12-29 02:29:49,889 [nnabla][INFO]: iter=4589 {Training error}=0.0\n",
            "2024-12-29 02:29:49,937 [nnabla][INFO]: iter=4599 {Training loss}=2.392816440988099e-06\n",
            "2024-12-29 02:29:49,937 [nnabla][INFO]: iter=4599 {Training error}=0.0\n",
            "2024-12-29 02:29:49,937 [nnabla][INFO]: iter=4599 {Training time}=0.4937608242034912[sec/100iter] 23.43921399116516[sec]\n",
            "2024-12-29 02:29:49,968 [nnabla][INFO]: iter=4600 {Test error}=0.0140625\n",
            "2024-12-29 02:29:50,018 [nnabla][INFO]: iter=4609 {Training loss}=2.4229907467088196e-06\n",
            "2024-12-29 02:29:50,020 [nnabla][INFO]: iter=4609 {Training error}=0.0\n",
            "2024-12-29 02:29:50,081 [nnabla][INFO]: iter=4619 {Training loss}=2.2848794287710916e-06\n",
            "2024-12-29 02:29:50,082 [nnabla][INFO]: iter=4619 {Training error}=0.0\n",
            "2024-12-29 02:29:50,132 [nnabla][INFO]: iter=4629 {Training loss}=2.3728864562144736e-06\n",
            "2024-12-29 02:29:50,133 [nnabla][INFO]: iter=4629 {Training error}=0.0\n",
            "2024-12-29 02:29:50,175 [nnabla][INFO]: iter=4639 {Training loss}=2.3036902803141857e-06\n",
            "2024-12-29 02:29:50,175 [nnabla][INFO]: iter=4639 {Training error}=0.0\n",
            "2024-12-29 02:29:50,223 [nnabla][INFO]: iter=4649 {Training loss}=2.386392679909477e-06\n",
            "2024-12-29 02:29:50,224 [nnabla][INFO]: iter=4649 {Training error}=0.0\n",
            "2024-12-29 02:29:50,280 [nnabla][INFO]: iter=4659 {Training loss}=2.2586148133996176e-06\n",
            "2024-12-29 02:29:50,280 [nnabla][INFO]: iter=4659 {Training error}=0.0\n",
            "2024-12-29 02:29:50,330 [nnabla][INFO]: iter=4669 {Training loss}=2.2294677819445496e-06\n",
            "2024-12-29 02:29:50,331 [nnabla][INFO]: iter=4669 {Training error}=0.0\n",
            "2024-12-29 02:29:50,376 [nnabla][INFO]: iter=4679 {Training loss}=2.263458100060234e-06\n",
            "2024-12-29 02:29:50,376 [nnabla][INFO]: iter=4679 {Training error}=0.0\n",
            "2024-12-29 02:29:50,426 [nnabla][INFO]: iter=4689 {Training loss}=2.2864619495521765e-06\n",
            "2024-12-29 02:29:50,427 [nnabla][INFO]: iter=4689 {Training error}=0.0\n",
            "2024-12-29 02:29:50,474 [nnabla][INFO]: iter=4699 {Training loss}=2.2443684883910464e-06\n",
            "2024-12-29 02:29:50,474 [nnabla][INFO]: iter=4699 {Training error}=0.0\n",
            "2024-12-29 02:29:50,474 [nnabla][INFO]: iter=4699 {Training time}=0.5370938777923584[sec/100iter] 23.97630786895752[sec]\n",
            "2024-12-29 02:29:50,503 [nnabla][INFO]: iter=4700 {Test error}=0.01484375\n",
            "2024-12-29 02:29:50,548 [nnabla][INFO]: iter=4709 {Training loss}=2.2519111553265247e-06\n",
            "2024-12-29 02:29:50,548 [nnabla][INFO]: iter=4709 {Training error}=0.0\n",
            "2024-12-29 02:29:50,598 [nnabla][INFO]: iter=4719 {Training loss}=2.1193870907154633e-06\n",
            "2024-12-29 02:29:50,599 [nnabla][INFO]: iter=4719 {Training error}=0.0\n",
            "2024-12-29 02:29:50,649 [nnabla][INFO]: iter=4729 {Training loss}=2.278639612995903e-06\n",
            "2024-12-29 02:29:50,650 [nnabla][INFO]: iter=4729 {Training error}=0.0\n",
            "2024-12-29 02:29:50,697 [nnabla][INFO]: iter=4739 {Training loss}=2.070120899588801e-06\n",
            "2024-12-29 02:29:50,697 [nnabla][INFO]: iter=4739 {Training error}=0.0\n",
            "2024-12-29 02:29:50,744 [nnabla][INFO]: iter=4749 {Training loss}=2.1840189674549038e-06\n",
            "2024-12-29 02:29:50,744 [nnabla][INFO]: iter=4749 {Training error}=0.0\n",
            "2024-12-29 02:29:50,792 [nnabla][INFO]: iter=4759 {Training loss}=2.079713794955751e-06\n",
            "2024-12-29 02:29:50,792 [nnabla][INFO]: iter=4759 {Training error}=0.0\n",
            "2024-12-29 02:29:50,840 [nnabla][INFO]: iter=4769 {Training loss}=2.1814116735185962e-06\n",
            "2024-12-29 02:29:50,840 [nnabla][INFO]: iter=4769 {Training error}=0.0\n",
            "2024-12-29 02:29:50,891 [nnabla][INFO]: iter=4779 {Training loss}=2.1015996480855392e-06\n",
            "2024-12-29 02:29:50,891 [nnabla][INFO]: iter=4779 {Training error}=0.0\n",
            "2024-12-29 02:29:50,932 [nnabla][INFO]: iter=4789 {Training loss}=2.1051373551017605e-06\n",
            "2024-12-29 02:29:50,932 [nnabla][INFO]: iter=4789 {Training error}=0.0\n",
            "2024-12-29 02:29:50,976 [nnabla][INFO]: iter=4799 {Training loss}=2.0907023099425714e-06\n",
            "2024-12-29 02:29:50,976 [nnabla][INFO]: iter=4799 {Training error}=0.0\n",
            "2024-12-29 02:29:50,976 [nnabla][INFO]: iter=4799 {Training time}=0.5018954277038574[sec/100iter] 24.478203296661377[sec]\n",
            "2024-12-29 02:29:51,000 [nnabla][INFO]: iter=4800 {Test error}=0.0140625\n",
            "2024-12-29 02:29:51,042 [nnabla][INFO]: iter=4809 {Training loss}=2.06332333618775e-06\n",
            "2024-12-29 02:29:51,042 [nnabla][INFO]: iter=4809 {Training error}=0.0\n",
            "2024-12-29 02:29:51,089 [nnabla][INFO]: iter=4819 {Training loss}=2.105137582475436e-06\n",
            "2024-12-29 02:29:51,089 [nnabla][INFO]: iter=4819 {Training error}=0.0\n",
            "2024-12-29 02:29:51,128 [nnabla][INFO]: iter=4829 {Training loss}=1.971123992916546e-06\n",
            "2024-12-29 02:29:51,128 [nnabla][INFO]: iter=4829 {Training error}=0.0\n",
            "2024-12-29 02:29:51,171 [nnabla][INFO]: iter=4839 {Training loss}=2.0206680346745998e-06\n",
            "2024-12-29 02:29:51,171 [nnabla][INFO]: iter=4839 {Training error}=0.0\n",
            "2024-12-29 02:29:51,212 [nnabla][INFO]: iter=4849 {Training loss}=2.0410654997249367e-06\n",
            "2024-12-29 02:29:51,212 [nnabla][INFO]: iter=4849 {Training error}=0.0\n",
            "2024-12-29 02:29:51,252 [nnabla][INFO]: iter=4859 {Training loss}=2.0676998246926814e-06\n",
            "2024-12-29 02:29:51,252 [nnabla][INFO]: iter=4859 {Training error}=0.0\n",
            "2024-12-29 02:29:51,291 [nnabla][INFO]: iter=4869 {Training loss}=1.9063979834754718e-06\n",
            "2024-12-29 02:29:51,291 [nnabla][INFO]: iter=4869 {Training error}=0.0\n",
            "2024-12-29 02:29:51,330 [nnabla][INFO]: iter=4879 {Training loss}=2.001669599849265e-06\n",
            "2024-12-29 02:29:51,330 [nnabla][INFO]: iter=4879 {Training error}=0.0\n",
            "2024-12-29 02:29:51,371 [nnabla][INFO]: iter=4889 {Training loss}=1.93219534594391e-06\n",
            "2024-12-29 02:29:51,371 [nnabla][INFO]: iter=4889 {Training error}=0.0\n",
            "2024-12-29 02:29:51,410 [nnabla][INFO]: iter=4899 {Training loss}=1.9877938939316664e-06\n",
            "2024-12-29 02:29:51,410 [nnabla][INFO]: iter=4899 {Training error}=0.0\n",
            "2024-12-29 02:29:51,411 [nnabla][INFO]: iter=4899 {Training time}=0.4342532157897949[sec/100iter] 24.912456512451172[sec]\n",
            "2024-12-29 02:29:51,435 [nnabla][INFO]: iter=4900 {Test error}=0.0140625\n",
            "2024-12-29 02:29:51,474 [nnabla][INFO]: iter=4909 {Training loss}=1.9792255443462636e-06\n",
            "2024-12-29 02:29:51,474 [nnabla][INFO]: iter=4909 {Training error}=0.0\n",
            "2024-12-29 02:29:51,512 [nnabla][INFO]: iter=4919 {Training loss}=1.922788669617148e-06\n",
            "2024-12-29 02:29:51,512 [nnabla][INFO]: iter=4919 {Training error}=0.0\n",
            "2024-12-29 02:29:51,551 [nnabla][INFO]: iter=4929 {Training loss}=1.9285637335997308e-06\n",
            "2024-12-29 02:29:51,551 [nnabla][INFO]: iter=4929 {Training error}=0.0\n",
            "2024-12-29 02:29:51,589 [nnabla][INFO]: iter=4939 {Training loss}=1.8754792563413503e-06\n",
            "2024-12-29 02:29:51,589 [nnabla][INFO]: iter=4939 {Training error}=0.0\n",
            "2024-12-29 02:29:51,627 [nnabla][INFO]: iter=4949 {Training loss}=1.8311477560928324e-06\n",
            "2024-12-29 02:29:51,628 [nnabla][INFO]: iter=4949 {Training error}=0.0\n",
            "2024-12-29 02:29:51,667 [nnabla][INFO]: iter=4959 {Training loss}=1.8568528048490407e-06\n",
            "2024-12-29 02:29:51,667 [nnabla][INFO]: iter=4959 {Training error}=0.0\n",
            "2024-12-29 02:29:51,707 [nnabla][INFO]: iter=4969 {Training loss}=1.9206470369681483e-06\n",
            "2024-12-29 02:29:51,707 [nnabla][INFO]: iter=4969 {Training error}=0.0\n",
            "2024-12-29 02:29:51,744 [nnabla][INFO]: iter=4979 {Training loss}=1.8053517578664469e-06\n",
            "2024-12-29 02:29:51,744 [nnabla][INFO]: iter=4979 {Training error}=0.0\n",
            "2024-12-29 02:29:51,782 [nnabla][INFO]: iter=4989 {Training loss}=1.8787379758578027e-06\n",
            "2024-12-29 02:29:51,783 [nnabla][INFO]: iter=4989 {Training error}=0.0\n",
            "2024-12-29 02:29:51,822 [nnabla][INFO]: iter=4999 {Training loss}=1.7752705616658204e-06\n",
            "2024-12-29 02:29:51,822 [nnabla][INFO]: iter=4999 {Training error}=0.0\n",
            "2024-12-29 02:29:51,822 [nnabla][INFO]: iter=4999 {Training time}=0.4117395877838135[sec/100iter] 25.324196100234985[sec]\n",
            "2024-12-29 02:29:51,856 [nnabla][INFO]: iter=5000 {Test error}=0.0140625\n",
            "2024-12-29 02:29:51,875 [nnabla][INFO]: Solver state save (.h5): output/states_5000.h5\n",
            "2024-12-29 02:29:51,884 [nnabla][INFO]: Parameter save (.h5): output/params_5000.h5\n",
            "2024-12-29 02:29:51,884 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_5000.json\n",
            "2024-12-29 02:29:51,926 [nnabla][INFO]: iter=5009 {Training loss}=1.834966724345577e-06\n",
            "2024-12-29 02:29:51,926 [nnabla][INFO]: iter=5009 {Training error}=0.0\n",
            "2024-12-29 02:29:51,967 [nnabla][INFO]: iter=5019 {Training loss}=1.7969701957554207e-06\n",
            "2024-12-29 02:29:51,967 [nnabla][INFO]: iter=5019 {Training error}=0.0\n",
            "2024-12-29 02:29:52,005 [nnabla][INFO]: iter=5029 {Training loss}=1.8812521602740162e-06\n",
            "2024-12-29 02:29:52,005 [nnabla][INFO]: iter=5029 {Training error}=0.0\n",
            "2024-12-29 02:29:52,045 [nnabla][INFO]: iter=5039 {Training loss}=1.7329896309092874e-06\n",
            "2024-12-29 02:29:52,045 [nnabla][INFO]: iter=5039 {Training error}=0.0\n",
            "2024-12-29 02:29:52,087 [nnabla][INFO]: iter=5049 {Training loss}=1.7411845192327746e-06\n",
            "2024-12-29 02:29:52,087 [nnabla][INFO]: iter=5049 {Training error}=0.0\n",
            "2024-12-29 02:29:52,132 [nnabla][INFO]: iter=5059 {Training loss}=1.7498456372777582e-06\n",
            "2024-12-29 02:29:52,132 [nnabla][INFO]: iter=5059 {Training error}=0.0\n",
            "2024-12-29 02:29:52,170 [nnabla][INFO]: iter=5069 {Training loss}=1.7414631656720303e-06\n",
            "2024-12-29 02:29:52,170 [nnabla][INFO]: iter=5069 {Training error}=0.0\n",
            "2024-12-29 02:29:52,208 [nnabla][INFO]: iter=5079 {Training loss}=1.754317054292187e-06\n",
            "2024-12-29 02:29:52,208 [nnabla][INFO]: iter=5079 {Training error}=0.0\n",
            "2024-12-29 02:29:52,248 [nnabla][INFO]: iter=5089 {Training loss}=1.721068315418961e-06\n",
            "2024-12-29 02:29:52,249 [nnabla][INFO]: iter=5089 {Training error}=0.0\n",
            "2024-12-29 02:29:52,289 [nnabla][INFO]: iter=5099 {Training loss}=1.6970409433270106e-06\n",
            "2024-12-29 02:29:52,289 [nnabla][INFO]: iter=5099 {Training error}=0.0\n",
            "2024-12-29 02:29:52,289 [nnabla][INFO]: iter=5099 {Training time}=0.46660923957824707[sec/100iter] 25.790805339813232[sec]\n",
            "2024-12-29 02:29:52,312 [nnabla][INFO]: iter=5100 {Test error}=0.01484375\n",
            "2024-12-29 02:29:52,351 [nnabla][INFO]: iter=5109 {Training loss}=1.6794392649899237e-06\n",
            "2024-12-29 02:29:52,351 [nnabla][INFO]: iter=5109 {Training error}=0.0\n",
            "2024-12-29 02:29:52,389 [nnabla][INFO]: iter=5119 {Training loss}=1.7326167380815605e-06\n",
            "2024-12-29 02:29:52,389 [nnabla][INFO]: iter=5119 {Training error}=0.0\n",
            "2024-12-29 02:29:52,428 [nnabla][INFO]: iter=5129 {Training loss}=1.6718018969186232e-06\n",
            "2024-12-29 02:29:52,428 [nnabla][INFO]: iter=5129 {Training error}=0.0\n",
            "2024-12-29 02:29:52,466 [nnabla][INFO]: iter=5139 {Training loss}=1.693687977422087e-06\n",
            "2024-12-29 02:29:52,466 [nnabla][INFO]: iter=5139 {Training error}=0.0\n",
            "2024-12-29 02:29:52,505 [nnabla][INFO]: iter=5149 {Training loss}=1.6014888615245582e-06\n",
            "2024-12-29 02:29:52,505 [nnabla][INFO]: iter=5149 {Training error}=0.0\n",
            "2024-12-29 02:29:52,544 [nnabla][INFO]: iter=5159 {Training loss}=1.6537351257284172e-06\n",
            "2024-12-29 02:29:52,544 [nnabla][INFO]: iter=5159 {Training error}=0.0\n",
            "2024-12-29 02:29:52,584 [nnabla][INFO]: iter=5169 {Training loss}=1.6744099866627948e-06\n",
            "2024-12-29 02:29:52,584 [nnabla][INFO]: iter=5169 {Training error}=0.0\n",
            "2024-12-29 02:29:52,624 [nnabla][INFO]: iter=5179 {Training loss}=1.6214183915508329e-06\n",
            "2024-12-29 02:29:52,625 [nnabla][INFO]: iter=5179 {Training error}=0.0\n",
            "2024-12-29 02:29:52,662 [nnabla][INFO]: iter=5189 {Training loss}=1.5958081576172845e-06\n",
            "2024-12-29 02:29:52,662 [nnabla][INFO]: iter=5189 {Training error}=0.0\n",
            "2024-12-29 02:29:52,703 [nnabla][INFO]: iter=5199 {Training loss}=1.6029783864723868e-06\n",
            "2024-12-29 02:29:52,703 [nnabla][INFO]: iter=5199 {Training error}=0.0\n",
            "2024-12-29 02:29:52,703 [nnabla][INFO]: iter=5199 {Training time}=0.41407060623168945[sec/100iter] 26.204875946044922[sec]\n",
            "2024-12-29 02:29:52,725 [nnabla][INFO]: iter=5200 {Test error}=0.0140625\n",
            "2024-12-29 02:29:52,762 [nnabla][INFO]: iter=5209 {Training loss}=1.639113520468527e-06\n",
            "2024-12-29 02:29:52,762 [nnabla][INFO]: iter=5209 {Training error}=0.0\n",
            "2024-12-29 02:29:52,800 [nnabla][INFO]: iter=5219 {Training loss}=1.5606044598825974e-06\n",
            "2024-12-29 02:29:52,800 [nnabla][INFO]: iter=5219 {Training error}=0.0\n",
            "2024-12-29 02:29:52,839 [nnabla][INFO]: iter=5229 {Training loss}=1.5013731626822846e-06\n",
            "2024-12-29 02:29:52,839 [nnabla][INFO]: iter=5229 {Training error}=0.0\n",
            "2024-12-29 02:29:52,878 [nnabla][INFO]: iter=5239 {Training loss}=1.588170789545984e-06\n",
            "2024-12-29 02:29:52,878 [nnabla][INFO]: iter=5239 {Training error}=0.0\n",
            "2024-12-29 02:29:52,915 [nnabla][INFO]: iter=5249 {Training loss}=1.5939456261548912e-06\n",
            "2024-12-29 02:29:52,916 [nnabla][INFO]: iter=5249 {Training error}=0.0\n",
            "2024-12-29 02:29:52,954 [nnabla][INFO]: iter=5259 {Training loss}=1.5180431773842429e-06\n",
            "2024-12-29 02:29:52,954 [nnabla][INFO]: iter=5259 {Training error}=0.0\n",
            "2024-12-29 02:29:52,995 [nnabla][INFO]: iter=5269 {Training loss}=1.561162889629486e-06\n",
            "2024-12-29 02:29:52,995 [nnabla][INFO]: iter=5269 {Training error}=0.0\n",
            "2024-12-29 02:29:53,034 [nnabla][INFO]: iter=5279 {Training loss}=1.5091032992131659e-06\n",
            "2024-12-29 02:29:53,034 [nnabla][INFO]: iter=5279 {Training error}=0.0\n",
            "2024-12-29 02:29:53,073 [nnabla][INFO]: iter=5289 {Training loss}=1.4778104286961025e-06\n",
            "2024-12-29 02:29:53,074 [nnabla][INFO]: iter=5289 {Training error}=0.0\n",
            "2024-12-29 02:29:53,113 [nnabla][INFO]: iter=5299 {Training loss}=1.5173923202382866e-06\n",
            "2024-12-29 02:29:53,113 [nnabla][INFO]: iter=5299 {Training error}=0.0\n",
            "2024-12-29 02:29:53,113 [nnabla][INFO]: iter=5299 {Training time}=0.4099736213684082[sec/100iter] 26.61484956741333[sec]\n",
            "2024-12-29 02:29:53,141 [nnabla][INFO]: iter=5300 {Test error}=0.0140625\n",
            "2024-12-29 02:29:53,180 [nnabla][INFO]: iter=5309 {Training loss}=1.5065882053022506e-06\n",
            "2024-12-29 02:29:53,181 [nnabla][INFO]: iter=5309 {Training error}=0.0\n",
            "2024-12-29 02:29:53,219 [nnabla][INFO]: iter=5319 {Training loss}=1.4938299273126177e-06\n",
            "2024-12-29 02:29:53,219 [nnabla][INFO]: iter=5319 {Training error}=0.0\n",
            "2024-12-29 02:29:53,258 [nnabla][INFO]: iter=5329 {Training loss}=1.4737131550646154e-06\n",
            "2024-12-29 02:29:53,259 [nnabla][INFO]: iter=5329 {Training error}=0.0\n",
            "2024-12-29 02:29:53,299 [nnabla][INFO]: iter=5339 {Training loss}=1.4714785265823593e-06\n",
            "2024-12-29 02:29:53,299 [nnabla][INFO]: iter=5339 {Training error}=0.0\n",
            "2024-12-29 02:29:53,337 [nnabla][INFO]: iter=5349 {Training loss}=1.433573515896569e-06\n",
            "2024-12-29 02:29:53,337 [nnabla][INFO]: iter=5349 {Training error}=0.0\n",
            "2024-12-29 02:29:53,376 [nnabla][INFO]: iter=5359 {Training loss}=1.4671948065370088e-06\n",
            "2024-12-29 02:29:53,376 [nnabla][INFO]: iter=5359 {Training error}=0.0\n",
            "2024-12-29 02:29:53,414 [nnabla][INFO]: iter=5369 {Training loss}=1.3910123470850522e-06\n",
            "2024-12-29 02:29:53,415 [nnabla][INFO]: iter=5369 {Training error}=0.0\n",
            "2024-12-29 02:29:53,456 [nnabla][INFO]: iter=5379 {Training loss}=1.4404661214939551e-06\n",
            "2024-12-29 02:29:53,457 [nnabla][INFO]: iter=5379 {Training error}=0.0\n",
            "2024-12-29 02:29:53,495 [nnabla][INFO]: iter=5389 {Training loss}=1.466076582801179e-06\n",
            "2024-12-29 02:29:53,495 [nnabla][INFO]: iter=5389 {Training error}=0.0\n",
            "2024-12-29 02:29:53,533 [nnabla][INFO]: iter=5399 {Training loss}=1.3811411463393597e-06\n",
            "2024-12-29 02:29:53,533 [nnabla][INFO]: iter=5399 {Training error}=0.0\n",
            "2024-12-29 02:29:53,533 [nnabla][INFO]: iter=5399 {Training time}=0.4200713634490967[sec/100iter] 27.034920930862427[sec]\n",
            "2024-12-29 02:29:53,556 [nnabla][INFO]: iter=5400 {Test error}=0.01484375\n",
            "2024-12-29 02:29:53,598 [nnabla][INFO]: iter=5409 {Training loss}=1.396321749780327e-06\n",
            "2024-12-29 02:29:53,598 [nnabla][INFO]: iter=5409 {Training error}=0.0\n",
            "2024-12-29 02:29:53,636 [nnabla][INFO]: iter=5419 {Training loss}=1.3811408052788465e-06\n",
            "2024-12-29 02:29:53,636 [nnabla][INFO]: iter=5419 {Training error}=0.0\n",
            "2024-12-29 02:29:53,673 [nnabla][INFO]: iter=5429 {Training loss}=1.336810782959219e-06\n",
            "2024-12-29 02:29:53,673 [nnabla][INFO]: iter=5429 {Training error}=0.0\n",
            "2024-12-29 02:29:53,711 [nnabla][INFO]: iter=5439 {Training loss}=1.4220256616681581e-06\n",
            "2024-12-29 02:29:53,711 [nnabla][INFO]: iter=5439 {Training error}=0.0\n",
            "2024-12-29 02:29:53,749 [nnabla][INFO]: iter=5449 {Training loss}=1.3719209164264612e-06\n",
            "2024-12-29 02:29:53,749 [nnabla][INFO]: iter=5449 {Training error}=0.0\n",
            "2024-12-29 02:29:53,790 [nnabla][INFO]: iter=5459 {Training loss}=1.337183675786946e-06\n",
            "2024-12-29 02:29:53,790 [nnabla][INFO]: iter=5459 {Training error}=0.0\n",
            "2024-12-29 02:29:53,830 [nnabla][INFO]: iter=5469 {Training loss}=1.3315958540260908e-06\n",
            "2024-12-29 02:29:53,831 [nnabla][INFO]: iter=5469 {Training error}=0.0\n",
            "2024-12-29 02:29:53,869 [nnabla][INFO]: iter=5479 {Training loss}=1.4236085235097562e-06\n",
            "2024-12-29 02:29:53,869 [nnabla][INFO]: iter=5479 {Training error}=0.0\n",
            "2024-12-29 02:29:53,907 [nnabla][INFO]: iter=5489 {Training loss}=1.2323177998041501e-06\n",
            "2024-12-29 02:29:53,907 [nnabla][INFO]: iter=5489 {Training error}=0.0\n",
            "2024-12-29 02:29:53,945 [nnabla][INFO]: iter=5499 {Training loss}=1.3694068456970854e-06\n",
            "2024-12-29 02:29:53,945 [nnabla][INFO]: iter=5499 {Training error}=0.0\n",
            "2024-12-29 02:29:53,945 [nnabla][INFO]: iter=5499 {Training time}=0.41196250915527344[sec/100iter] 27.4468834400177[sec]\n",
            "2024-12-29 02:29:53,967 [nnabla][INFO]: iter=5500 {Test error}=0.0140625\n",
            "2024-12-29 02:29:54,010 [nnabla][INFO]: iter=5509 {Training loss}=1.3009556596443872e-06\n",
            "2024-12-29 02:29:54,011 [nnabla][INFO]: iter=5509 {Training error}=0.0\n",
            "2024-12-29 02:29:54,052 [nnabla][INFO]: iter=5519 {Training loss}=1.2865203871115227e-06\n",
            "2024-12-29 02:29:54,052 [nnabla][INFO]: iter=5519 {Training error}=0.0\n",
            "2024-12-29 02:29:54,090 [nnabla][INFO]: iter=5529 {Training loss}=1.3009552048970363e-06\n",
            "2024-12-29 02:29:54,091 [nnabla][INFO]: iter=5529 {Training error}=0.0\n",
            "2024-12-29 02:29:54,128 [nnabla][INFO]: iter=5539 {Training loss}=1.3349482514968258e-06\n",
            "2024-12-29 02:29:54,129 [nnabla][INFO]: iter=5539 {Training error}=0.0\n",
            "2024-12-29 02:29:54,182 [nnabla][INFO]: iter=5549 {Training loss}=1.2180687463114737e-06\n",
            "2024-12-29 02:29:54,182 [nnabla][INFO]: iter=5549 {Training error}=0.0\n",
            "2024-12-29 02:29:54,224 [nnabla][INFO]: iter=5559 {Training loss}=1.2970439229320618e-06\n",
            "2024-12-29 02:29:54,224 [nnabla][INFO]: iter=5559 {Training error}=0.0\n",
            "2024-12-29 02:29:54,262 [nnabla][INFO]: iter=5569 {Training loss}=1.2512238072304172e-06\n",
            "2024-12-29 02:29:54,262 [nnabla][INFO]: iter=5569 {Training error}=0.0\n",
            "2024-12-29 02:29:54,300 [nnabla][INFO]: iter=5579 {Training loss}=1.2263571989024058e-06\n",
            "2024-12-29 02:29:54,300 [nnabla][INFO]: iter=5579 {Training error}=0.0\n",
            "2024-12-29 02:29:54,337 [nnabla][INFO]: iter=5589 {Training loss}=1.238837285200134e-06\n",
            "2024-12-29 02:29:54,337 [nnabla][INFO]: iter=5589 {Training error}=0.0\n",
            "2024-12-29 02:29:54,374 [nnabla][INFO]: iter=5599 {Training loss}=1.2705016843028716e-06\n",
            "2024-12-29 02:29:54,374 [nnabla][INFO]: iter=5599 {Training error}=0.0\n",
            "2024-12-29 02:29:54,374 [nnabla][INFO]: iter=5599 {Training time}=0.42936062812805176[sec/100iter] 27.876244068145752[sec]\n",
            "2024-12-29 02:29:54,396 [nnabla][INFO]: iter=5600 {Test error}=0.0140625\n",
            "2024-12-29 02:29:54,433 [nnabla][INFO]: iter=5609 {Training loss}=1.2155544482084224e-06\n",
            "2024-12-29 02:29:54,434 [nnabla][INFO]: iter=5609 {Training error}=0.0\n",
            "2024-12-29 02:29:54,471 [nnabla][INFO]: iter=5619 {Training loss}=1.24060636608192e-06\n",
            "2024-12-29 02:29:54,471 [nnabla][INFO]: iter=5619 {Training error}=0.0\n",
            "2024-12-29 02:29:54,509 [nnabla][INFO]: iter=5629 {Training loss}=1.2424692386048264e-06\n",
            "2024-12-29 02:29:54,509 [nnabla][INFO]: iter=5629 {Training error}=0.0\n",
            "2024-12-29 02:29:54,548 [nnabla][INFO]: iter=5639 {Training loss}=1.1673124618027941e-06\n",
            "2024-12-29 02:29:54,548 [nnabla][INFO]: iter=5639 {Training error}=0.0\n",
            "2024-12-29 02:29:54,585 [nnabla][INFO]: iter=5649 {Training loss}=1.2406998166625272e-06\n",
            "2024-12-29 02:29:54,586 [nnabla][INFO]: iter=5649 {Training error}=0.0\n",
            "2024-12-29 02:29:54,622 [nnabla][INFO]: iter=5659 {Training loss}=1.1483136859169463e-06\n",
            "2024-12-29 02:29:54,622 [nnabla][INFO]: iter=5659 {Training error}=0.0\n",
            "2024-12-29 02:29:54,659 [nnabla][INFO]: iter=5669 {Training loss}=1.200187625727267e-06\n",
            "2024-12-29 02:29:54,659 [nnabla][INFO]: iter=5669 {Training error}=0.0\n",
            "2024-12-29 02:29:54,695 [nnabla][INFO]: iter=5679 {Training loss}=1.1879877774845227e-06\n",
            "2024-12-29 02:29:54,696 [nnabla][INFO]: iter=5679 {Training error}=0.0\n",
            "2024-12-29 02:29:54,733 [nnabla][INFO]: iter=5689 {Training loss}=1.1372305834811414e-06\n",
            "2024-12-29 02:29:54,733 [nnabla][INFO]: iter=5689 {Training error}=0.0\n",
            "2024-12-29 02:29:54,770 [nnabla][INFO]: iter=5699 {Training loss}=1.1861252460221294e-06\n",
            "2024-12-29 02:29:54,770 [nnabla][INFO]: iter=5699 {Training error}=0.0\n",
            "2024-12-29 02:29:54,770 [nnabla][INFO]: iter=5699 {Training time}=0.39562129974365234[sec/100iter] 28.271865367889404[sec]\n",
            "2024-12-29 02:29:54,793 [nnabla][INFO]: iter=5700 {Test error}=0.0140625\n",
            "2024-12-29 02:29:54,830 [nnabla][INFO]: iter=5709 {Training loss}=1.1364857073203893e-06\n",
            "2024-12-29 02:29:54,830 [nnabla][INFO]: iter=5709 {Training error}=0.0\n",
            "2024-12-29 02:29:54,868 [nnabla][INFO]: iter=5719 {Training loss}=1.1391865655241418e-06\n",
            "2024-12-29 02:29:54,868 [nnabla][INFO]: iter=5719 {Training error}=0.0\n",
            "2024-12-29 02:29:54,905 [nnabla][INFO]: iter=5729 {Training loss}=1.1296876891719876e-06\n",
            "2024-12-29 02:29:54,905 [nnabla][INFO]: iter=5729 {Training error}=0.0\n",
            "2024-12-29 02:29:54,942 [nnabla][INFO]: iter=5739 {Training loss}=1.1403975577195524e-06\n",
            "2024-12-29 02:29:54,942 [nnabla][INFO]: iter=5739 {Training error}=0.0\n",
            "2024-12-29 02:29:54,979 [nnabla][INFO]: iter=5749 {Training loss}=1.1205603414055076e-06\n",
            "2024-12-29 02:29:54,979 [nnabla][INFO]: iter=5749 {Training error}=0.0\n",
            "2024-12-29 02:29:55,018 [nnabla][INFO]: iter=5759 {Training loss}=1.112179006668157e-06\n",
            "2024-12-29 02:29:55,019 [nnabla][INFO]: iter=5759 {Training error}=0.0\n",
            "2024-12-29 02:29:55,056 [nnabla][INFO]: iter=5769 {Training loss}=1.1656359220069135e-06\n",
            "2024-12-29 02:29:55,057 [nnabla][INFO]: iter=5769 {Training error}=0.0\n",
            "2024-12-29 02:29:55,094 [nnabla][INFO]: iter=5779 {Training loss}=1.0488495263416553e-06\n",
            "2024-12-29 02:29:55,094 [nnabla][INFO]: iter=5779 {Training error}=0.0\n",
            "2024-12-29 02:29:55,131 [nnabla][INFO]: iter=5789 {Training loss}=1.1115266715933103e-06\n",
            "2024-12-29 02:29:55,131 [nnabla][INFO]: iter=5789 {Training error}=0.0\n",
            "2024-12-29 02:29:55,169 [nnabla][INFO]: iter=5799 {Training loss}=1.072691361514444e-06\n",
            "2024-12-29 02:29:55,169 [nnabla][INFO]: iter=5799 {Training error}=0.0\n",
            "2024-12-29 02:29:55,169 [nnabla][INFO]: iter=5799 {Training time}=0.3991374969482422[sec/100iter] 28.671002864837646[sec]\n",
            "2024-12-29 02:29:55,197 [nnabla][INFO]: iter=5800 {Test error}=0.01484375\n",
            "2024-12-29 02:29:55,239 [nnabla][INFO]: iter=5809 {Training loss}=1.101934344660549e-06\n",
            "2024-12-29 02:29:55,239 [nnabla][INFO]: iter=5809 {Training error}=0.0\n",
            "2024-12-29 02:29:55,276 [nnabla][INFO]: iter=5819 {Training loss}=1.0453106824570568e-06\n",
            "2024-12-29 02:29:55,276 [nnabla][INFO]: iter=5819 {Training error}=0.0\n",
            "2024-12-29 02:29:55,314 [nnabla][INFO]: iter=5829 {Training loss}=1.0923416766672744e-06\n",
            "2024-12-29 02:29:55,314 [nnabla][INFO]: iter=5829 {Training error}=0.0\n",
            "2024-12-29 02:29:55,351 [nnabla][INFO]: iter=5839 {Training loss}=1.0422370451124152e-06\n",
            "2024-12-29 02:29:55,352 [nnabla][INFO]: iter=5839 {Training error}=0.0\n",
            "2024-12-29 02:29:55,389 [nnabla][INFO]: iter=5849 {Training loss}=1.0444724694025354e-06\n",
            "2024-12-29 02:29:55,390 [nnabla][INFO]: iter=5849 {Training error}=0.0\n",
            "2024-12-29 02:29:55,426 [nnabla][INFO]: iter=5859 {Training loss}=1.02864009932091e-06\n",
            "2024-12-29 02:29:55,426 [nnabla][INFO]: iter=5859 {Training error}=0.0\n",
            "2024-12-29 02:29:55,463 [nnabla][INFO]: iter=5869 {Training loss}=1.075485101864615e-06\n",
            "2024-12-29 02:29:55,463 [nnabla][INFO]: iter=5869 {Training error}=0.0\n",
            "2024-12-29 02:29:55,499 [nnabla][INFO]: iter=5879 {Training loss}=1.0578831961538526e-06\n",
            "2024-12-29 02:29:55,499 [nnabla][INFO]: iter=5879 {Training error}=0.0\n",
            "2024-12-29 02:29:55,541 [nnabla][INFO]: iter=5889 {Training loss}=9.904563285090262e-07\n",
            "2024-12-29 02:29:55,541 [nnabla][INFO]: iter=5889 {Training error}=0.0\n",
            "2024-12-29 02:29:55,578 [nnabla][INFO]: iter=5899 {Training loss}=9.85520273388829e-07\n",
            "2024-12-29 02:29:55,578 [nnabla][INFO]: iter=5899 {Training error}=0.0\n",
            "2024-12-29 02:29:55,579 [nnabla][INFO]: iter=5899 {Training time}=0.40940093994140625[sec/100iter] 29.080403804779053[sec]\n",
            "2024-12-29 02:29:55,601 [nnabla][INFO]: iter=5900 {Test error}=0.0140625\n",
            "2024-12-29 02:29:55,637 [nnabla][INFO]: iter=5909 {Training loss}=1.074274223356042e-06\n",
            "2024-12-29 02:29:55,637 [nnabla][INFO]: iter=5909 {Training error}=0.0\n",
            "2024-12-29 02:29:55,674 [nnabla][INFO]: iter=5919 {Training loss}=9.666149480835884e-07\n",
            "2024-12-29 02:29:55,674 [nnabla][INFO]: iter=5919 {Training error}=0.0\n",
            "2024-12-29 02:29:55,711 [nnabla][INFO]: iter=5929 {Training loss}=1.0084304449264891e-06\n",
            "2024-12-29 02:29:55,712 [nnabla][INFO]: iter=5929 {Training error}=0.0\n",
            "2024-12-29 02:29:55,751 [nnabla][INFO]: iter=5939 {Training loss}=1.0090823252539849e-06\n",
            "2024-12-29 02:29:55,752 [nnabla][INFO]: iter=5939 {Training error}=0.0\n",
            "2024-12-29 02:29:55,788 [nnabla][INFO]: iter=5949 {Training loss}=9.902703368425136e-07\n",
            "2024-12-29 02:29:55,789 [nnabla][INFO]: iter=5949 {Training error}=0.0\n",
            "2024-12-29 02:29:55,827 [nnabla][INFO]: iter=5959 {Training loss}=9.871034762909403e-07\n",
            "2024-12-29 02:29:55,828 [nnabla][INFO]: iter=5959 {Training error}=0.0\n",
            "2024-12-29 02:29:55,865 [nnabla][INFO]: iter=5969 {Training loss}=9.42772999223962e-07\n",
            "2024-12-29 02:29:55,865 [nnabla][INFO]: iter=5969 {Training error}=0.0\n",
            "2024-12-29 02:29:55,902 [nnabla][INFO]: iter=5979 {Training loss}=9.980930144593003e-07\n",
            "2024-12-29 02:29:55,903 [nnabla][INFO]: iter=5979 {Training error}=0.0\n",
            "2024-12-29 02:29:55,941 [nnabla][INFO]: iter=5989 {Training loss}=9.76859382717521e-07\n",
            "2024-12-29 02:29:55,941 [nnabla][INFO]: iter=5989 {Training error}=0.0\n",
            "2024-12-29 02:29:55,979 [nnabla][INFO]: iter=5999 {Training loss}=9.502234092906292e-07\n",
            "2024-12-29 02:29:55,979 [nnabla][INFO]: iter=5999 {Training error}=0.0\n",
            "2024-12-29 02:29:55,979 [nnabla][INFO]: iter=5999 {Training time}=0.40061259269714355[sec/100iter] 29.481016397476196[sec]\n",
            "2024-12-29 02:29:56,002 [nnabla][INFO]: iter=6000 {Test error}=0.0140625\n",
            "2024-12-29 02:29:56,015 [nnabla][INFO]: Solver state save (.h5): output/states_6000.h5\n",
            "2024-12-29 02:29:56,021 [nnabla][INFO]: Parameter save (.h5): output/params_6000.h5\n",
            "2024-12-29 02:29:56,022 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_6000.json\n",
            "2024-12-29 02:29:56,060 [nnabla][INFO]: iter=6009 {Training loss}=9.735994126458536e-07\n",
            "2024-12-29 02:29:56,061 [nnabla][INFO]: iter=6009 {Training error}=0.0\n",
            "2024-12-29 02:29:56,096 [nnabla][INFO]: iter=6019 {Training loss}=9.048685569723602e-07\n",
            "2024-12-29 02:29:56,096 [nnabla][INFO]: iter=6019 {Training error}=0.0\n",
            "2024-12-29 02:29:56,133 [nnabla][INFO]: iter=6029 {Training loss}=9.280583981308155e-07\n",
            "2024-12-29 02:29:56,133 [nnabla][INFO]: iter=6029 {Training error}=0.0\n",
            "2024-12-29 02:29:56,172 [nnabla][INFO]: iter=6039 {Training loss}=9.6056123766175e-07\n",
            "2024-12-29 02:29:56,172 [nnabla][INFO]: iter=6039 {Training error}=0.0\n",
            "2024-12-29 02:29:56,209 [nnabla][INFO]: iter=6049 {Training loss}=9.491058108324069e-07\n",
            "2024-12-29 02:29:56,209 [nnabla][INFO]: iter=6049 {Training error}=0.0\n",
            "2024-12-29 02:29:56,256 [nnabla][INFO]: iter=6059 {Training loss}=8.868011036611279e-07\n",
            "2024-12-29 02:29:56,256 [nnabla][INFO]: iter=6059 {Training error}=0.0\n",
            "2024-12-29 02:29:56,293 [nnabla][INFO]: iter=6069 {Training loss}=9.488265391155437e-07\n",
            "2024-12-29 02:29:56,293 [nnabla][INFO]: iter=6069 {Training error}=0.0\n",
            "2024-12-29 02:29:56,330 [nnabla][INFO]: iter=6079 {Training loss}=9.342981002191664e-07\n",
            "2024-12-29 02:29:56,330 [nnabla][INFO]: iter=6079 {Training error}=0.0\n",
            "2024-12-29 02:29:56,366 [nnabla][INFO]: iter=6089 {Training loss}=8.749733524382464e-07\n",
            "2024-12-29 02:29:56,366 [nnabla][INFO]: iter=6089 {Training error}=0.0\n",
            "2024-12-29 02:29:56,403 [nnabla][INFO]: iter=6099 {Training loss}=9.115739771914377e-07\n",
            "2024-12-29 02:29:56,403 [nnabla][INFO]: iter=6099 {Training error}=0.0\n",
            "2024-12-29 02:29:56,403 [nnabla][INFO]: iter=6099 {Training time}=0.4241514205932617[sec/100iter] 29.905167818069458[sec]\n",
            "2024-12-29 02:29:56,425 [nnabla][INFO]: iter=6100 {Test error}=0.01484375\n",
            "2024-12-29 02:29:56,462 [nnabla][INFO]: iter=6109 {Training loss}=9.193040568789002e-07\n",
            "2024-12-29 02:29:56,462 [nnabla][INFO]: iter=6109 {Training error}=0.0\n",
            "2024-12-29 02:29:56,500 [nnabla][INFO]: iter=6119 {Training loss}=8.368826343030378e-07\n",
            "2024-12-29 02:29:56,501 [nnabla][INFO]: iter=6119 {Training error}=0.0\n",
            "2024-12-29 02:29:56,542 [nnabla][INFO]: iter=6129 {Training loss}=9.44263149449398e-07\n",
            "2024-12-29 02:29:56,542 [nnabla][INFO]: iter=6129 {Training error}=0.0\n",
            "2024-12-29 02:29:56,579 [nnabla][INFO]: iter=6139 {Training loss}=8.444262675766367e-07\n",
            "2024-12-29 02:29:56,579 [nnabla][INFO]: iter=6139 {Training error}=0.0\n",
            "2024-12-29 02:29:56,616 [nnabla][INFO]: iter=6149 {Training loss}=8.645424713904504e-07\n",
            "2024-12-29 02:29:56,616 [nnabla][INFO]: iter=6149 {Training error}=0.0\n",
            "2024-12-29 02:29:56,653 [nnabla][INFO]: iter=6159 {Training loss}=8.867081078278716e-07\n",
            "2024-12-29 02:29:56,653 [nnabla][INFO]: iter=6159 {Training error}=0.0\n",
            "2024-12-29 02:29:56,690 [nnabla][INFO]: iter=6169 {Training loss}=8.558815238757234e-07\n",
            "2024-12-29 02:29:56,690 [nnabla][INFO]: iter=6169 {Training error}=0.0\n",
            "2024-12-29 02:29:56,729 [nnabla][INFO]: iter=6179 {Training loss}=8.976041385722056e-07\n",
            "2024-12-29 02:29:56,729 [nnabla][INFO]: iter=6179 {Training error}=0.0\n",
            "2024-12-29 02:29:56,766 [nnabla][INFO]: iter=6189 {Training loss}=8.415393608629529e-07\n",
            "2024-12-29 02:29:56,766 [nnabla][INFO]: iter=6189 {Training error}=0.0\n",
            "2024-12-29 02:29:56,802 [nnabla][INFO]: iter=6199 {Training loss}=8.137860163515143e-07\n",
            "2024-12-29 02:29:56,803 [nnabla][INFO]: iter=6199 {Training error}=0.0\n",
            "2024-12-29 02:29:56,803 [nnabla][INFO]: iter=6199 {Training time}=0.3993690013885498[sec/100iter] 30.304536819458008[sec]\n",
            "2024-12-29 02:29:56,827 [nnabla][INFO]: iter=6200 {Test error}=0.0140625\n",
            "2024-12-29 02:29:56,864 [nnabla][INFO]: iter=6209 {Training loss}=8.614694024799974e-07\n",
            "2024-12-29 02:29:56,865 [nnabla][INFO]: iter=6209 {Training error}=0.0\n",
            "2024-12-29 02:29:56,901 [nnabla][INFO]: iter=6219 {Training loss}=8.518768481735606e-07\n",
            "2024-12-29 02:29:56,901 [nnabla][INFO]: iter=6219 {Training error}=0.0\n",
            "2024-12-29 02:29:56,939 [nnabla][INFO]: iter=6229 {Training loss}=8.081049713837274e-07\n",
            "2024-12-29 02:29:56,939 [nnabla][INFO]: iter=6229 {Training error}=0.0\n",
            "2024-12-29 02:29:56,976 [nnabla][INFO]: iter=6239 {Training loss}=8.328781291311316e-07\n",
            "2024-12-29 02:29:56,976 [nnabla][INFO]: iter=6239 {Training error}=0.0\n",
            "2024-12-29 02:29:57,014 [nnabla][INFO]: iter=6249 {Training loss}=8.14158568118728e-07\n",
            "2024-12-29 02:29:57,014 [nnabla][INFO]: iter=6249 {Training error}=0.0\n",
            "2024-12-29 02:29:57,052 [nnabla][INFO]: iter=6259 {Training loss}=8.279419603240967e-07\n",
            "2024-12-29 02:29:57,052 [nnabla][INFO]: iter=6259 {Training error}=0.0\n",
            "2024-12-29 02:29:57,089 [nnabla][INFO]: iter=6269 {Training loss}=7.830527692931355e-07\n",
            "2024-12-29 02:29:57,089 [nnabla][INFO]: iter=6269 {Training error}=0.0\n",
            "2024-12-29 02:29:57,126 [nnabla][INFO]: iter=6279 {Training loss}=8.431225069216453e-07\n",
            "2024-12-29 02:29:57,126 [nnabla][INFO]: iter=6279 {Training error}=0.0\n",
            "2024-12-29 02:29:57,164 [nnabla][INFO]: iter=6289 {Training loss}=7.697349246882368e-07\n",
            "2024-12-29 02:29:57,164 [nnabla][INFO]: iter=6289 {Training error}=0.0\n",
            "2024-12-29 02:29:57,203 [nnabla][INFO]: iter=6299 {Training loss}=7.813763431840925e-07\n",
            "2024-12-29 02:29:57,204 [nnabla][INFO]: iter=6299 {Training error}=0.0\n",
            "2024-12-29 02:29:57,205 [nnabla][INFO]: iter=6299 {Training time}=0.4018418788909912[sec/100iter] 30.706378698349[sec]\n",
            "2024-12-29 02:29:57,230 [nnabla][INFO]: iter=6300 {Test error}=0.0140625\n",
            "2024-12-29 02:29:57,275 [nnabla][INFO]: iter=6309 {Training loss}=7.964634960444528e-07\n",
            "2024-12-29 02:29:57,276 [nnabla][INFO]: iter=6309 {Training error}=0.0\n",
            "2024-12-29 02:29:57,314 [nnabla][INFO]: iter=6319 {Training loss}=8.062423830779153e-07\n",
            "2024-12-29 02:29:57,314 [nnabla][INFO]: iter=6319 {Training error}=0.0\n",
            "2024-12-29 02:29:57,352 [nnabla][INFO]: iter=6329 {Training loss}=7.623772830811504e-07\n",
            "2024-12-29 02:29:57,352 [nnabla][INFO]: iter=6329 {Training error}=0.0\n",
            "2024-12-29 02:29:57,389 [nnabla][INFO]: iter=6339 {Training loss}=7.832391020201612e-07\n",
            "2024-12-29 02:29:57,390 [nnabla][INFO]: iter=6339 {Training error}=0.0\n",
            "2024-12-29 02:29:57,427 [nnabla][INFO]: iter=6349 {Training loss}=7.715976835243055e-07\n",
            "2024-12-29 02:29:57,427 [nnabla][INFO]: iter=6349 {Training error}=0.0\n",
            "2024-12-29 02:29:57,467 [nnabla][INFO]: iter=6359 {Training loss}=7.580932788187056e-07\n",
            "2024-12-29 02:29:57,467 [nnabla][INFO]: iter=6359 {Training error}=0.0\n",
            "2024-12-29 02:29:57,504 [nnabla][INFO]: iter=6369 {Training loss}=7.450550469911832e-07\n",
            "2024-12-29 02:29:57,504 [nnabla][INFO]: iter=6369 {Training error}=0.0\n",
            "2024-12-29 02:29:57,542 [nnabla][INFO]: iter=6379 {Training loss}=8.040072998483083e-07\n",
            "2024-12-29 02:29:57,542 [nnabla][INFO]: iter=6379 {Training error}=0.0\n",
            "2024-12-29 02:29:57,579 [nnabla][INFO]: iter=6389 {Training loss}=7.390015639430203e-07\n",
            "2024-12-29 02:29:57,579 [nnabla][INFO]: iter=6389 {Training error}=0.0\n",
            "2024-12-29 02:29:57,615 [nnabla][INFO]: iter=6399 {Training loss}=7.334134579650708e-07\n",
            "2024-12-29 02:29:57,615 [nnabla][INFO]: iter=6399 {Training error}=0.0\n",
            "2024-12-29 02:29:57,615 [nnabla][INFO]: iter=6399 {Training time}=0.4108240604400635[sec/100iter] 31.117202758789062[sec]\n",
            "2024-12-29 02:29:57,637 [nnabla][INFO]: iter=6400 {Test error}=0.0140625\n",
            "2024-12-29 02:29:57,674 [nnabla][INFO]: iter=6409 {Training loss}=7.570689604108338e-07\n",
            "2024-12-29 02:29:57,674 [nnabla][INFO]: iter=6409 {Training error}=0.0\n",
            "2024-12-29 02:29:57,713 [nnabla][INFO]: iter=6419 {Training loss}=7.281051921381732e-07\n",
            "2024-12-29 02:29:57,713 [nnabla][INFO]: iter=6419 {Training error}=0.0\n",
            "2024-12-29 02:29:57,756 [nnabla][INFO]: iter=6429 {Training loss}=7.579072303087742e-07\n",
            "2024-12-29 02:29:57,756 [nnabla][INFO]: iter=6429 {Training error}=0.0\n",
            "2024-12-29 02:29:57,793 [nnabla][INFO]: iter=6439 {Training loss}=7.530643983955088e-07\n",
            "2024-12-29 02:29:57,793 [nnabla][INFO]: iter=6439 {Training error}=0.0\n",
            "2024-12-29 02:29:57,830 [nnabla][INFO]: iter=6449 {Training loss}=6.897348612255882e-07\n",
            "2024-12-29 02:29:57,831 [nnabla][INFO]: iter=6449 {Training error}=0.0\n",
            "2024-12-29 02:29:57,869 [nnabla][INFO]: iter=6459 {Training loss}=7.320165309465665e-07\n",
            "2024-12-29 02:29:57,869 [nnabla][INFO]: iter=6459 {Training error}=0.0\n",
            "2024-12-29 02:29:57,907 [nnabla][INFO]: iter=6469 {Training loss}=7.084544222379918e-07\n",
            "2024-12-29 02:29:57,907 [nnabla][INFO]: iter=6469 {Training error}=0.0\n",
            "2024-12-29 02:29:57,946 [nnabla][INFO]: iter=6479 {Training loss}=7.224240334835486e-07\n",
            "2024-12-29 02:29:57,946 [nnabla][INFO]: iter=6479 {Training error}=0.0\n",
            "2024-12-29 02:29:57,982 [nnabla][INFO]: iter=6489 {Training loss}=7.118070470824023e-07\n",
            "2024-12-29 02:29:57,983 [nnabla][INFO]: iter=6489 {Training error}=0.0\n",
            "2024-12-29 02:29:58,020 [nnabla][INFO]: iter=6499 {Training loss}=7.13669805918471e-07\n",
            "2024-12-29 02:29:58,020 [nnabla][INFO]: iter=6499 {Training error}=0.0\n",
            "2024-12-29 02:29:58,021 [nnabla][INFO]: iter=6499 {Training time}=0.4052269458770752[sec/100iter] 31.522429704666138[sec]\n",
            "2024-12-29 02:29:58,046 [nnabla][INFO]: iter=6500 {Test error}=0.01484375\n",
            "2024-12-29 02:29:58,084 [nnabla][INFO]: iter=6509 {Training loss}=6.737162721037748e-07\n",
            "2024-12-29 02:29:58,085 [nnabla][INFO]: iter=6509 {Training error}=0.0\n",
            "2024-12-29 02:29:58,123 [nnabla][INFO]: iter=6519 {Training loss}=7.035183671177947e-07\n",
            "2024-12-29 02:29:58,124 [nnabla][INFO]: iter=6519 {Training error}=0.0\n",
            "2024-12-29 02:29:58,165 [nnabla][INFO]: iter=6529 {Training loss}=7.241004595925915e-07\n",
            "2024-12-29 02:29:58,165 [nnabla][INFO]: iter=6529 {Training error}=0.0\n",
            "2024-12-29 02:29:58,204 [nnabla][INFO]: iter=6539 {Training loss}=6.545311634909012e-07\n",
            "2024-12-29 02:29:58,204 [nnabla][INFO]: iter=6539 {Training error}=0.0\n",
            "2024-12-29 02:29:58,243 [nnabla][INFO]: iter=6549 {Training loss}=6.759514690202195e-07\n",
            "2024-12-29 02:29:58,243 [nnabla][INFO]: iter=6549 {Training error}=0.0\n",
            "2024-12-29 02:29:58,280 [nnabla][INFO]: iter=6559 {Training loss}=6.869409503451607e-07\n",
            "2024-12-29 02:29:58,281 [nnabla][INFO]: iter=6559 {Training error}=0.0\n",
            "2024-12-29 02:29:58,322 [nnabla][INFO]: iter=6569 {Training loss}=6.867547313049727e-07\n",
            "2024-12-29 02:29:58,323 [nnabla][INFO]: iter=6569 {Training error}=0.0\n",
            "2024-12-29 02:29:58,361 [nnabla][INFO]: iter=6579 {Training loss}=6.468012543336954e-07\n",
            "2024-12-29 02:29:58,362 [nnabla][INFO]: iter=6579 {Training error}=0.0\n",
            "2024-12-29 02:29:58,399 [nnabla][INFO]: iter=6589 {Training loss}=7.020283874226152e-07\n",
            "2024-12-29 02:29:58,399 [nnabla][INFO]: iter=6589 {Training error}=0.0\n",
            "2024-12-29 02:29:58,435 [nnabla][INFO]: iter=6599 {Training loss}=6.605846465390641e-07\n",
            "2024-12-29 02:29:58,436 [nnabla][INFO]: iter=6599 {Training error}=0.0\n",
            "2024-12-29 02:29:58,436 [nnabla][INFO]: iter=6599 {Training time}=0.41537976264953613[sec/100iter] 31.937809467315674[sec]\n",
            "2024-12-29 02:29:58,462 [nnabla][INFO]: iter=6600 {Test error}=0.0140625\n",
            "2024-12-29 02:29:58,499 [nnabla][INFO]: iter=6609 {Training loss}=6.487570090030204e-07\n",
            "2024-12-29 02:29:58,499 [nnabla][INFO]: iter=6609 {Training error}=0.0\n",
            "2024-12-29 02:29:58,535 [nnabla][INFO]: iter=6619 {Training loss}=6.710154139000224e-07\n",
            "2024-12-29 02:29:58,536 [nnabla][INFO]: iter=6619 {Training error}=0.0\n",
            "2024-12-29 02:29:58,573 [nnabla][INFO]: iter=6629 {Training loss}=6.29106239102839e-07\n",
            "2024-12-29 02:29:58,574 [nnabla][INFO]: iter=6629 {Training error}=0.0\n",
            "2024-12-29 02:29:58,611 [nnabla][INFO]: iter=6639 {Training loss}=6.733438340233988e-07\n",
            "2024-12-29 02:29:58,611 [nnabla][INFO]: iter=6639 {Training error}=0.0\n",
            "2024-12-29 02:29:58,650 [nnabla][INFO]: iter=6649 {Training loss}=6.061958401915035e-07\n",
            "2024-12-29 02:29:58,650 [nnabla][INFO]: iter=6649 {Training error}=0.0\n",
            "2024-12-29 02:29:58,687 [nnabla][INFO]: iter=6659 {Training loss}=6.529480174322089e-07\n",
            "2024-12-29 02:29:58,687 [nnabla][INFO]: iter=6659 {Training error}=0.0\n",
            "2024-12-29 02:29:58,724 [nnabla][INFO]: iter=6669 {Training loss}=6.414927042897034e-07\n",
            "2024-12-29 02:29:58,724 [nnabla][INFO]: iter=6669 {Training error}=0.0\n",
            "2024-12-29 02:29:58,761 [nnabla][INFO]: iter=6679 {Training loss}=6.299443953139416e-07\n",
            "2024-12-29 02:29:58,761 [nnabla][INFO]: iter=6679 {Training error}=0.0\n",
            "2024-12-29 02:29:58,799 [nnabla][INFO]: iter=6689 {Training loss}=6.3646365333625e-07\n",
            "2024-12-29 02:29:58,799 [nnabla][INFO]: iter=6689 {Training error}=0.0\n",
            "2024-12-29 02:29:58,836 [nnabla][INFO]: iter=6699 {Training loss}=6.195136279529834e-07\n",
            "2024-12-29 02:29:58,836 [nnabla][INFO]: iter=6699 {Training error}=0.0\n",
            "2024-12-29 02:29:58,836 [nnabla][INFO]: iter=6699 {Training time}=0.40047788619995117[sec/100iter] 32.338287353515625[sec]\n",
            "2024-12-29 02:29:58,866 [nnabla][INFO]: iter=6700 {Test error}=0.0140625\n",
            "2024-12-29 02:29:58,904 [nnabla][INFO]: iter=6709 {Training loss}=6.111318953117006e-07\n",
            "2024-12-29 02:29:58,904 [nnabla][INFO]: iter=6709 {Training error}=0.0\n",
            "2024-12-29 02:29:58,942 [nnabla][INFO]: iter=6719 {Training loss}=6.183029768180859e-07\n",
            "2024-12-29 02:29:58,942 [nnabla][INFO]: iter=6719 {Training error}=0.0\n",
            "2024-12-29 02:29:58,980 [nnabla][INFO]: iter=6729 {Training loss}=6.306894420049503e-07\n",
            "2024-12-29 02:29:58,980 [nnabla][INFO]: iter=6729 {Training error}=0.0\n",
            "2024-12-29 02:29:59,017 [nnabla][INFO]: iter=6739 {Training loss}=6.114112807154015e-07\n",
            "2024-12-29 02:29:59,017 [nnabla][INFO]: iter=6739 {Training error}=0.0\n",
            "2024-12-29 02:29:59,058 [nnabla][INFO]: iter=6749 {Training loss}=5.844029828949715e-07\n",
            "2024-12-29 02:29:59,058 [nnabla][INFO]: iter=6749 {Training error}=0.0\n",
            "2024-12-29 02:29:59,095 [nnabla][INFO]: iter=6759 {Training loss}=6.401891141649685e-07\n",
            "2024-12-29 02:29:59,096 [nnabla][INFO]: iter=6759 {Training error}=0.0\n",
            "2024-12-29 02:29:59,132 [nnabla][INFO]: iter=6769 {Training loss}=5.683842800863204e-07\n",
            "2024-12-29 02:29:59,132 [nnabla][INFO]: iter=6769 {Training error}=0.0\n",
            "2024-12-29 02:29:59,173 [nnabla][INFO]: iter=6779 {Training loss}=6.021912213327596e-07\n",
            "2024-12-29 02:29:59,173 [nnabla][INFO]: iter=6779 {Training error}=0.0\n",
            "2024-12-29 02:29:59,213 [nnabla][INFO]: iter=6789 {Training loss}=5.945544785390666e-07\n",
            "2024-12-29 02:29:59,213 [nnabla][INFO]: iter=6789 {Training error}=0.0\n",
            "2024-12-29 02:29:59,250 [nnabla][INFO]: iter=6799 {Training loss}=5.859864131707582e-07\n",
            "2024-12-29 02:29:59,250 [nnabla][INFO]: iter=6799 {Training error}=0.0\n",
            "2024-12-29 02:29:59,250 [nnabla][INFO]: iter=6799 {Training time}=0.41359710693359375[sec/100iter] 32.75188446044922[sec]\n",
            "2024-12-29 02:29:59,272 [nnabla][INFO]: iter=6800 {Test error}=0.01484375\n",
            "2024-12-29 02:29:59,311 [nnabla][INFO]: iter=6809 {Training loss}=5.872900032954931e-07\n",
            "2024-12-29 02:29:59,311 [nnabla][INFO]: iter=6809 {Training error}=0.0\n",
            "2024-12-29 02:29:59,356 [nnabla][INFO]: iter=6819 {Training loss}=6.031225439073751e-07\n",
            "2024-12-29 02:29:59,356 [nnabla][INFO]: iter=6819 {Training error}=0.0\n",
            "2024-12-29 02:29:59,393 [nnabla][INFO]: iter=6829 {Training loss}=5.560910949498066e-07\n",
            "2024-12-29 02:29:59,393 [nnabla][INFO]: iter=6829 {Training error}=0.0\n",
            "2024-12-29 02:29:59,430 [nnabla][INFO]: iter=6839 {Training loss}=5.713645805371925e-07\n",
            "2024-12-29 02:29:59,430 [nnabla][INFO]: iter=6839 {Training error}=0.0\n",
            "2024-12-29 02:29:59,466 [nnabla][INFO]: iter=6849 {Training loss}=6.164403885122738e-07\n",
            "2024-12-29 02:29:59,467 [nnabla][INFO]: iter=6849 {Training error}=0.0\n",
            "2024-12-29 02:29:59,503 [nnabla][INFO]: iter=6859 {Training loss}=5.491061756401905e-07\n",
            "2024-12-29 02:29:59,504 [nnabla][INFO]: iter=6859 {Training error}=0.0\n",
            "2024-12-29 02:29:59,542 [nnabla][INFO]: iter=6869 {Training loss}=5.498512223311991e-07\n",
            "2024-12-29 02:29:59,542 [nnabla][INFO]: iter=6869 {Training error}=0.0\n",
            "2024-12-29 02:29:59,589 [nnabla][INFO]: iter=6879 {Training loss}=5.748104854319536e-07\n",
            "2024-12-29 02:29:59,589 [nnabla][INFO]: iter=6879 {Training error}=0.0\n",
            "2024-12-29 02:29:59,628 [nnabla][INFO]: iter=6889 {Training loss}=5.548803869714902e-07\n",
            "2024-12-29 02:29:59,628 [nnabla][INFO]: iter=6889 {Training error}=0.0\n",
            "2024-12-29 02:29:59,664 [nnabla][INFO]: iter=6899 {Training loss}=5.763936883340648e-07\n",
            "2024-12-29 02:29:59,665 [nnabla][INFO]: iter=6899 {Training error}=0.0\n",
            "2024-12-29 02:29:59,665 [nnabla][INFO]: iter=6899 {Training time}=0.41471004486083984[sec/100iter] 33.16659450531006[sec]\n",
            "2024-12-29 02:29:59,687 [nnabla][INFO]: iter=6900 {Test error}=0.0140625\n",
            "2024-12-29 02:29:59,723 [nnabla][INFO]: iter=6909 {Training loss}=5.399793963078992e-07\n",
            "2024-12-29 02:29:59,724 [nnabla][INFO]: iter=6909 {Training error}=0.0\n",
            "2024-12-29 02:29:59,761 [nnabla][INFO]: iter=6919 {Training loss}=5.70433257962577e-07\n",
            "2024-12-29 02:29:59,761 [nnabla][INFO]: iter=6919 {Training error}=0.0\n",
            "2024-12-29 02:29:59,798 [nnabla][INFO]: iter=6929 {Training loss}=5.396998972173606e-07\n",
            "2024-12-29 02:29:59,799 [nnabla][INFO]: iter=6929 {Training error}=0.0\n",
            "2024-12-29 02:29:59,839 [nnabla][INFO]: iter=6939 {Training loss}=5.537626748264302e-07\n",
            "2024-12-29 02:29:59,840 [nnabla][INFO]: iter=6939 {Training error}=0.0\n",
            "2024-12-29 02:29:59,879 [nnabla][INFO]: iter=6949 {Training loss}=5.226567623139999e-07\n",
            "2024-12-29 02:29:59,880 [nnabla][INFO]: iter=6949 {Training error}=0.0\n",
            "2024-12-29 02:29:59,919 [nnabla][INFO]: iter=6959 {Training loss}=5.361608828025055e-07\n",
            "2024-12-29 02:29:59,919 [nnabla][INFO]: iter=6959 {Training error}=0.0\n",
            "2024-12-29 02:29:59,956 [nnabla][INFO]: iter=6969 {Training loss}=5.418418140834547e-07\n",
            "2024-12-29 02:29:59,957 [nnabla][INFO]: iter=6969 {Training error}=0.0\n",
            "2024-12-29 02:29:59,995 [nnabla][INFO]: iter=6979 {Training loss}=5.293621825330774e-07\n",
            "2024-12-29 02:29:59,995 [nnabla][INFO]: iter=6979 {Training error}=0.0\n",
            "2024-12-29 02:30:00,033 [nnabla][INFO]: iter=6989 {Training loss}=5.250782351140515e-07\n",
            "2024-12-29 02:30:00,033 [nnabla][INFO]: iter=6989 {Training error}=0.0\n",
            "2024-12-29 02:30:00,075 [nnabla][INFO]: iter=6999 {Training loss}=5.269407665764447e-07\n",
            "2024-12-29 02:30:00,075 [nnabla][INFO]: iter=6999 {Training error}=0.0\n",
            "2024-12-29 02:30:00,075 [nnabla][INFO]: iter=6999 {Training time}=0.4107048511505127[sec/100iter] 33.57729935646057[sec]\n",
            "2024-12-29 02:30:00,098 [nnabla][INFO]: iter=7000 {Test error}=0.0140625\n",
            "2024-12-29 02:30:00,110 [nnabla][INFO]: Solver state save (.h5): output/states_7000.h5\n",
            "2024-12-29 02:30:00,116 [nnabla][INFO]: Parameter save (.h5): output/params_7000.h5\n",
            "2024-12-29 02:30:00,117 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_7000.json\n",
            "2024-12-29 02:30:00,159 [nnabla][INFO]: iter=7009 {Training loss}=5.175345449970337e-07\n",
            "2024-12-29 02:30:00,160 [nnabla][INFO]: iter=7009 {Training error}=0.0\n",
            "2024-12-29 02:30:00,197 [nnabla][INFO]: iter=7019 {Training loss}=5.095251935927081e-07\n",
            "2024-12-29 02:30:00,197 [nnabla][INFO]: iter=7019 {Training error}=0.0\n",
            "2024-12-29 02:30:00,235 [nnabla][INFO]: iter=7029 {Training loss}=5.242399652161112e-07\n",
            "2024-12-29 02:30:00,235 [nnabla][INFO]: iter=7029 {Training error}=0.0\n",
            "2024-12-29 02:30:00,272 [nnabla][INFO]: iter=7039 {Training loss}=5.019815603191091e-07\n",
            "2024-12-29 02:30:00,272 [nnabla][INFO]: iter=7039 {Training error}=0.0\n",
            "2024-12-29 02:30:00,308 [nnabla][INFO]: iter=7049 {Training loss}=5.332736918717274e-07\n",
            "2024-12-29 02:30:00,308 [nnabla][INFO]: iter=7049 {Training error}=0.0\n",
            "2024-12-29 02:30:00,347 [nnabla][INFO]: iter=7059 {Training loss}=5.017953412789211e-07\n",
            "2024-12-29 02:30:00,347 [nnabla][INFO]: iter=7059 {Training error}=0.0\n",
            "2024-12-29 02:30:00,388 [nnabla][INFO]: iter=7069 {Training loss}=5.070105544291437e-07\n",
            "2024-12-29 02:30:00,389 [nnabla][INFO]: iter=7069 {Training error}=0.0\n",
            "2024-12-29 02:30:00,429 [nnabla][INFO]: iter=7079 {Training loss}=4.899675332126208e-07\n",
            "2024-12-29 02:30:00,429 [nnabla][INFO]: iter=7079 {Training error}=0.0\n",
            "2024-12-29 02:30:00,470 [nnabla][INFO]: iter=7089 {Training loss}=4.910850179840054e-07\n",
            "2024-12-29 02:30:00,470 [nnabla][INFO]: iter=7089 {Training error}=0.0\n",
            "2024-12-29 02:30:00,506 [nnabla][INFO]: iter=7099 {Training loss}=4.944378702020913e-07\n",
            "2024-12-29 02:30:00,507 [nnabla][INFO]: iter=7099 {Training error}=0.0\n",
            "2024-12-29 02:30:00,507 [nnabla][INFO]: iter=7099 {Training time}=0.4313352108001709[sec/100iter] 34.00863456726074[sec]\n",
            "2024-12-29 02:30:00,528 [nnabla][INFO]: iter=7100 {Test error}=0.0140625\n",
            "2024-12-29 02:30:00,568 [nnabla][INFO]: iter=7109 {Training loss}=4.97138614719006e-07\n",
            "2024-12-29 02:30:00,568 [nnabla][INFO]: iter=7109 {Training error}=0.0\n",
            "2024-12-29 02:30:00,607 [nnabla][INFO]: iter=7119 {Training loss}=5.000257488063653e-07\n",
            "2024-12-29 02:30:00,607 [nnabla][INFO]: iter=7119 {Training error}=0.0\n",
            "2024-12-29 02:30:00,645 [nnabla][INFO]: iter=7129 {Training loss}=4.620279412392847e-07\n",
            "2024-12-29 02:30:00,645 [nnabla][INFO]: iter=7129 {Training error}=0.0\n",
            "2024-12-29 02:30:00,682 [nnabla][INFO]: iter=7139 {Training loss}=5.05986179177853e-07\n",
            "2024-12-29 02:30:00,682 [nnabla][INFO]: iter=7139 {Training error}=0.0\n",
            "2024-12-29 02:30:00,721 [nnabla][INFO]: iter=7149 {Training loss}=4.612829798134044e-07\n",
            "2024-12-29 02:30:00,721 [nnabla][INFO]: iter=7149 {Training error}=0.0\n",
            "2024-12-29 02:30:00,761 [nnabla][INFO]: iter=7159 {Training loss}=4.6007221499166917e-07\n",
            "2024-12-29 02:30:00,761 [nnabla][INFO]: iter=7159 {Training error}=0.0\n",
            "2024-12-29 02:30:00,800 [nnabla][INFO]: iter=7169 {Training loss}=4.808405833500728e-07\n",
            "2024-12-29 02:30:00,800 [nnabla][INFO]: iter=7169 {Training error}=0.0\n",
            "2024-12-29 02:30:00,837 [nnabla][INFO]: iter=7179 {Training loss}=4.6733643443985784e-07\n",
            "2024-12-29 02:30:00,837 [nnabla][INFO]: iter=7179 {Training error}=0.0\n",
            "2024-12-29 02:30:00,874 [nnabla][INFO]: iter=7189 {Training loss}=4.888499347543984e-07\n",
            "2024-12-29 02:30:00,874 [nnabla][INFO]: iter=7189 {Training error}=0.0\n",
            "2024-12-29 02:30:00,917 [nnabla][INFO]: iter=7199 {Training loss}=4.605378762789769e-07\n",
            "2024-12-29 02:30:00,917 [nnabla][INFO]: iter=7199 {Training error}=0.0\n",
            "2024-12-29 02:30:00,918 [nnabla][INFO]: iter=7199 {Training time}=0.4107522964477539[sec/100iter] 34.419386863708496[sec]\n",
            "2024-12-29 02:30:00,945 [nnabla][INFO]: iter=7200 {Test error}=0.01484375\n",
            "2024-12-29 02:30:00,989 [nnabla][INFO]: iter=7209 {Training loss}=4.386519378840603e-07\n",
            "2024-12-29 02:30:00,989 [nnabla][INFO]: iter=7209 {Training error}=0.0\n",
            "2024-12-29 02:30:01,039 [nnabla][INFO]: iter=7219 {Training loss}=4.719000230579695e-07\n",
            "2024-12-29 02:30:01,039 [nnabla][INFO]: iter=7219 {Training error}=0.0\n",
            "2024-12-29 02:30:01,086 [nnabla][INFO]: iter=7229 {Training loss}=4.5299415774024965e-07\n",
            "2024-12-29 02:30:01,086 [nnabla][INFO]: iter=7229 {Training error}=0.0\n",
            "2024-12-29 02:30:01,131 [nnabla][INFO]: iter=7239 {Training loss}=4.669639679377724e-07\n",
            "2024-12-29 02:30:01,131 [nnabla][INFO]: iter=7239 {Training error}=0.0\n",
            "2024-12-29 02:30:01,180 [nnabla][INFO]: iter=7249 {Training loss}=4.3976942265544494e-07\n",
            "2024-12-29 02:30:01,180 [nnabla][INFO]: iter=7249 {Training error}=0.0\n",
            "2024-12-29 02:30:01,224 [nnabla][INFO]: iter=7259 {Training loss}=4.572783041112416e-07\n",
            "2024-12-29 02:30:01,224 [nnabla][INFO]: iter=7259 {Training error}=0.0\n",
            "2024-12-29 02:30:01,269 [nnabla][INFO]: iter=7269 {Training loss}=4.5914083557363483e-07\n",
            "2024-12-29 02:30:01,269 [nnabla][INFO]: iter=7269 {Training error}=0.0\n",
            "2024-12-29 02:30:01,315 [nnabla][INFO]: iter=7279 {Training loss}=4.412596297242999e-07\n",
            "2024-12-29 02:30:01,316 [nnabla][INFO]: iter=7279 {Training error}=0.0\n",
            "2024-12-29 02:30:01,356 [nnabla][INFO]: iter=7289 {Training loss}=4.3939689930994064e-07\n",
            "2024-12-29 02:30:01,357 [nnabla][INFO]: iter=7289 {Training error}=0.0\n",
            "2024-12-29 02:30:01,423 [nnabla][INFO]: iter=7299 {Training loss}=4.2896621721411066e-07\n",
            "2024-12-29 02:30:01,423 [nnabla][INFO]: iter=7299 {Training error}=0.0\n",
            "2024-12-29 02:30:01,423 [nnabla][INFO]: iter=7299 {Training time}=0.5056853294372559[sec/100iter] 34.92507219314575[sec]\n",
            "2024-12-29 02:30:01,450 [nnabla][INFO]: iter=7300 {Test error}=0.0140625\n",
            "2024-12-29 02:30:01,492 [nnabla][INFO]: iter=7309 {Training loss}=4.3427468199297437e-07\n",
            "2024-12-29 02:30:01,492 [nnabla][INFO]: iter=7309 {Training error}=0.0\n",
            "2024-12-29 02:30:01,534 [nnabla][INFO]: iter=7319 {Training loss}=4.324121221088717e-07\n",
            "2024-12-29 02:30:01,535 [nnabla][INFO]: iter=7319 {Training error}=0.0\n",
            "2024-12-29 02:30:01,577 [nnabla][INFO]: iter=7329 {Training loss}=4.238439430537255e-07\n",
            "2024-12-29 02:30:01,578 [nnabla][INFO]: iter=7329 {Training error}=0.0\n",
            "2024-12-29 02:30:01,622 [nnabla][INFO]: iter=7339 {Training loss}=4.4992083303441177e-07\n",
            "2024-12-29 02:30:01,623 [nnabla][INFO]: iter=7339 {Training error}=0.0\n",
            "2024-12-29 02:30:01,670 [nnabla][INFO]: iter=7349 {Training loss}=4.290593551559141e-07\n",
            "2024-12-29 02:30:01,670 [nnabla][INFO]: iter=7349 {Training error}=0.0\n",
            "2024-12-29 02:30:01,714 [nnabla][INFO]: iter=7359 {Training loss}=4.287798560653755e-07\n",
            "2024-12-29 02:30:01,714 [nnabla][INFO]: iter=7359 {Training error}=0.0\n",
            "2024-12-29 02:30:01,756 [nnabla][INFO]: iter=7369 {Training loss}=4.125749910599552e-07\n",
            "2024-12-29 02:30:01,756 [nnabla][INFO]: iter=7369 {Training error}=0.0\n",
            "2024-12-29 02:30:01,800 [nnabla][INFO]: iter=7379 {Training loss}=4.292455741961021e-07\n",
            "2024-12-29 02:30:01,800 [nnabla][INFO]: iter=7379 {Training error}=0.0\n",
            "2024-12-29 02:30:01,843 [nnabla][INFO]: iter=7389 {Training loss}=4.043793921937322e-07\n",
            "2024-12-29 02:30:01,844 [nnabla][INFO]: iter=7389 {Training error}=0.0\n",
            "2024-12-29 02:30:01,892 [nnabla][INFO]: iter=7399 {Training loss}=4.262653305886488e-07\n",
            "2024-12-29 02:30:01,892 [nnabla][INFO]: iter=7399 {Training error}=0.0\n",
            "2024-12-29 02:30:01,893 [nnabla][INFO]: iter=7399 {Training time}=0.4693031311035156[sec/100iter] 35.39437532424927[sec]\n",
            "2024-12-29 02:30:01,922 [nnabla][INFO]: iter=7400 {Test error}=0.0140625\n",
            "2024-12-29 02:30:01,965 [nnabla][INFO]: iter=7409 {Training loss}=4.03168627371997e-07\n",
            "2024-12-29 02:30:01,965 [nnabla][INFO]: iter=7409 {Training error}=0.0\n",
            "2024-12-29 02:30:02,008 [nnabla][INFO]: iter=7419 {Training loss}=4.115505305435363e-07\n",
            "2024-12-29 02:30:02,008 [nnabla][INFO]: iter=7419 {Training error}=0.0\n",
            "2024-12-29 02:30:02,054 [nnabla][INFO]: iter=7429 {Training loss}=4.206774519843748e-07\n",
            "2024-12-29 02:30:02,054 [nnabla][INFO]: iter=7429 {Training error}=0.0\n",
            "2024-12-29 02:30:02,097 [nnabla][INFO]: iter=7439 {Training loss}=3.918065942798421e-07\n",
            "2024-12-29 02:30:02,097 [nnabla][INFO]: iter=7439 {Training error}=0.0\n",
            "2024-12-29 02:30:02,138 [nnabla][INFO]: iter=7449 {Training loss}=3.94973028505774e-07\n",
            "2024-12-29 02:30:02,138 [nnabla][INFO]: iter=7449 {Training error}=0.0\n",
            "2024-12-29 02:30:02,187 [nnabla][INFO]: iter=7459 {Training loss}=4.001884121862531e-07\n",
            "2024-12-29 02:30:02,188 [nnabla][INFO]: iter=7459 {Training error}=0.0\n",
            "2024-12-29 02:30:02,230 [nnabla][INFO]: iter=7469 {Training loss}=4.102466846234165e-07\n",
            "2024-12-29 02:30:02,230 [nnabla][INFO]: iter=7469 {Training error}=0.0\n",
            "2024-12-29 02:30:02,271 [nnabla][INFO]: iter=7479 {Training loss}=3.909683528036112e-07\n",
            "2024-12-29 02:30:02,271 [nnabla][INFO]: iter=7479 {Training error}=0.0\n",
            "2024-12-29 02:30:02,313 [nnabla][INFO]: iter=7489 {Training loss}=3.675923494483868e-07\n",
            "2024-12-29 02:30:02,313 [nnabla][INFO]: iter=7489 {Training error}=0.0\n",
            "2024-12-29 02:30:02,356 [nnabla][INFO]: iter=7499 {Training loss}=4.095016379324079e-07\n",
            "2024-12-29 02:30:02,356 [nnabla][INFO]: iter=7499 {Training error}=0.0\n",
            "2024-12-29 02:30:02,356 [nnabla][INFO]: iter=7499 {Training time}=0.4639859199523926[sec/100iter] 35.85836124420166[sec]\n",
            "2024-12-29 02:30:02,383 [nnabla][INFO]: iter=7500 {Test error}=0.01484375\n",
            "2024-12-29 02:30:02,424 [nnabla][INFO]: iter=7509 {Training loss}=3.899438922871923e-07\n",
            "2024-12-29 02:30:02,424 [nnabla][INFO]: iter=7509 {Training error}=0.0\n",
            "2024-12-29 02:30:02,488 [nnabla][INFO]: iter=7519 {Training loss}=3.8994394913061114e-07\n",
            "2024-12-29 02:30:02,489 [nnabla][INFO]: iter=7519 {Training error}=0.0\n",
            "2024-12-29 02:30:02,540 [nnabla][INFO]: iter=7529 {Training loss}=3.7681232356590044e-07\n",
            "2024-12-29 02:30:02,540 [nnabla][INFO]: iter=7529 {Training error}=0.0\n",
            "2024-12-29 02:30:02,588 [nnabla][INFO]: iter=7539 {Training loss}=3.7848872125323396e-07\n",
            "2024-12-29 02:30:02,588 [nnabla][INFO]: iter=7539 {Training error}=0.0\n",
            "2024-12-29 02:30:02,633 [nnabla][INFO]: iter=7549 {Training loss}=3.808169708463538e-07\n",
            "2024-12-29 02:30:02,633 [nnabla][INFO]: iter=7549 {Training error}=0.0\n",
            "2024-12-29 02:30:02,677 [nnabla][INFO]: iter=7559 {Training loss}=3.6125931046626647e-07\n",
            "2024-12-29 02:30:02,677 [nnabla][INFO]: iter=7559 {Training error}=0.0\n",
            "2024-12-29 02:30:02,721 [nnabla][INFO]: iter=7569 {Training loss}=3.7522914908549865e-07\n",
            "2024-12-29 02:30:02,721 [nnabla][INFO]: iter=7569 {Training error}=0.0\n",
            "2024-12-29 02:30:02,768 [nnabla][INFO]: iter=7579 {Training loss}=3.6498457234301895e-07\n",
            "2024-12-29 02:30:02,768 [nnabla][INFO]: iter=7579 {Training error}=0.0\n",
            "2024-12-29 02:30:02,821 [nnabla][INFO]: iter=7589 {Training loss}=3.808169708463538e-07\n",
            "2024-12-29 02:30:02,821 [nnabla][INFO]: iter=7589 {Training error}=0.0\n",
            "2024-12-29 02:30:02,864 [nnabla][INFO]: iter=7599 {Training loss}=3.6153869586996734e-07\n",
            "2024-12-29 02:30:02,864 [nnabla][INFO]: iter=7599 {Training error}=0.0\n",
            "2024-12-29 02:30:02,864 [nnabla][INFO]: iter=7599 {Training time}=0.507610559463501[sec/100iter] 36.36597180366516[sec]\n",
            "2024-12-29 02:30:02,896 [nnabla][INFO]: iter=7600 {Test error}=0.0140625\n",
            "2024-12-29 02:30:02,944 [nnabla][INFO]: iter=7609 {Training loss}=3.6619530874304473e-07\n",
            "2024-12-29 02:30:02,944 [nnabla][INFO]: iter=7609 {Training error}=0.0\n",
            "2024-12-29 02:30:02,996 [nnabla][INFO]: iter=7619 {Training loss}=3.565095880730951e-07\n",
            "2024-12-29 02:30:02,996 [nnabla][INFO]: iter=7619 {Training error}=0.0\n",
            "2024-12-29 02:30:03,045 [nnabla][INFO]: iter=7629 {Training loss}=3.5501949469107785e-07\n",
            "2024-12-29 02:30:03,047 [nnabla][INFO]: iter=7629 {Training error}=0.0\n",
            "2024-12-29 02:30:03,094 [nnabla][INFO]: iter=7639 {Training loss}=3.773711227950116e-07\n",
            "2024-12-29 02:30:03,094 [nnabla][INFO]: iter=7639 {Training error}=0.0\n",
            "2024-12-29 02:30:03,137 [nnabla][INFO]: iter=7649 {Training loss}=3.487796504941798e-07\n",
            "2024-12-29 02:30:03,137 [nnabla][INFO]: iter=7649 {Training error}=0.0\n",
            "2024-12-29 02:30:03,184 [nnabla][INFO]: iter=7659 {Training loss}=3.5362251082915463e-07\n",
            "2024-12-29 02:30:03,184 [nnabla][INFO]: iter=7659 {Training error}=0.0\n",
            "2024-12-29 02:30:03,233 [nnabla][INFO]: iter=7669 {Training loss}=3.509216526254022e-07\n",
            "2024-12-29 02:30:03,234 [nnabla][INFO]: iter=7669 {Training error}=0.0\n",
            "2024-12-29 02:30:03,281 [nnabla][INFO]: iter=7679 {Training loss}=3.4347112887189724e-07\n",
            "2024-12-29 02:30:03,281 [nnabla][INFO]: iter=7679 {Training error}=0.0\n",
            "2024-12-29 02:30:03,330 [nnabla][INFO]: iter=7689 {Training loss}=3.49338449723291e-07\n",
            "2024-12-29 02:30:03,330 [nnabla][INFO]: iter=7689 {Training error}=0.0\n",
            "2024-12-29 02:30:03,375 [nnabla][INFO]: iter=7699 {Training loss}=3.4188786912636715e-07\n",
            "2024-12-29 02:30:03,376 [nnabla][INFO]: iter=7699 {Training error}=0.0\n",
            "2024-12-29 02:30:03,376 [nnabla][INFO]: iter=7699 {Training time}=0.5116972923278809[sec/100iter] 36.87766909599304[sec]\n",
            "2024-12-29 02:30:03,415 [nnabla][INFO]: iter=7700 {Test error}=0.0140625\n",
            "2024-12-29 02:30:03,464 [nnabla][INFO]: iter=7709 {Training loss}=3.4831396078516264e-07\n",
            "2024-12-29 02:30:03,464 [nnabla][INFO]: iter=7709 {Training error}=0.0\n",
            "2024-12-29 02:30:03,520 [nnabla][INFO]: iter=7719 {Training loss}=3.403046378025465e-07\n",
            "2024-12-29 02:30:03,520 [nnabla][INFO]: iter=7719 {Training error}=0.0\n",
            "2024-12-29 02:30:03,575 [nnabla][INFO]: iter=7729 {Training loss}=3.4421617556290585e-07\n",
            "2024-12-29 02:30:03,575 [nnabla][INFO]: iter=7729 {Training error}=0.0\n",
            "2024-12-29 02:30:03,625 [nnabla][INFO]: iter=7739 {Training loss}=3.295944566161779e-07\n",
            "2024-12-29 02:30:03,625 [nnabla][INFO]: iter=7739 {Training error}=0.0\n",
            "2024-12-29 02:30:03,668 [nnabla][INFO]: iter=7749 {Training loss}=3.305257791907934e-07\n",
            "2024-12-29 02:30:03,669 [nnabla][INFO]: iter=7749 {Training error}=0.0\n",
            "2024-12-29 02:30:03,716 [nnabla][INFO]: iter=7759 {Training loss}=3.471963623269403e-07\n",
            "2024-12-29 02:30:03,716 [nnabla][INFO]: iter=7759 {Training error}=0.0\n",
            "2024-12-29 02:30:03,765 [nnabla][INFO]: iter=7769 {Training loss}=3.362068241585803e-07\n",
            "2024-12-29 02:30:03,765 [nnabla][INFO]: iter=7769 {Training error}=0.0\n",
            "2024-12-29 02:30:03,812 [nnabla][INFO]: iter=7779 {Training loss}=3.1739421046950156e-07\n",
            "2024-12-29 02:30:03,813 [nnabla][INFO]: iter=7779 {Training error}=0.0\n",
            "2024-12-29 02:30:03,868 [nnabla][INFO]: iter=7789 {Training loss}=3.338785177220416e-07\n",
            "2024-12-29 02:30:03,870 [nnabla][INFO]: iter=7789 {Training error}=0.0\n",
            "2024-12-29 02:30:03,914 [nnabla][INFO]: iter=7799 {Training loss}=3.2028125929173257e-07\n",
            "2024-12-29 02:30:03,914 [nnabla][INFO]: iter=7799 {Training error}=0.0\n",
            "2024-12-29 02:30:03,914 [nnabla][INFO]: iter=7799 {Training time}=0.5384376049041748[sec/100iter] 37.41610670089722[sec]\n",
            "2024-12-29 02:30:03,936 [nnabla][INFO]: iter=7800 {Test error}=0.0140625\n",
            "2024-12-29 02:30:03,976 [nnabla][INFO]: iter=7809 {Training loss}=3.3583427239136654e-07\n",
            "2024-12-29 02:30:03,976 [nnabla][INFO]: iter=7809 {Training error}=0.0\n",
            "2024-12-29 02:30:04,015 [nnabla][INFO]: iter=7819 {Training loss}=3.0239991133385047e-07\n",
            "2024-12-29 02:30:04,015 [nnabla][INFO]: iter=7819 {Training error}=0.0\n",
            "2024-12-29 02:30:04,056 [nnabla][INFO]: iter=7829 {Training loss}=3.132032304620225e-07\n",
            "2024-12-29 02:30:04,056 [nnabla][INFO]: iter=7829 {Training error}=0.0\n",
            "2024-12-29 02:30:04,098 [nnabla][INFO]: iter=7839 {Training loss}=3.270799027177418e-07\n",
            "2024-12-29 02:30:04,098 [nnabla][INFO]: iter=7839 {Training error}=0.0\n",
            "2024-12-29 02:30:04,136 [nnabla][INFO]: iter=7849 {Training loss}=3.0603206369050895e-07\n",
            "2024-12-29 02:30:04,137 [nnabla][INFO]: iter=7849 {Training error}=0.0\n",
            "2024-12-29 02:30:04,175 [nnabla][INFO]: iter=7859 {Training loss}=3.2512409120499797e-07\n",
            "2024-12-29 02:30:04,175 [nnabla][INFO]: iter=7859 {Training error}=0.0\n",
            "2024-12-29 02:30:04,216 [nnabla][INFO]: iter=7869 {Training loss}=3.109680619672872e-07\n",
            "2024-12-29 02:30:04,216 [nnabla][INFO]: iter=7869 {Training error}=0.0\n",
            "2024-12-29 02:30:04,254 [nnabla][INFO]: iter=7879 {Training loss}=3.0659089134132955e-07\n",
            "2024-12-29 02:30:04,255 [nnabla][INFO]: iter=7879 {Training error}=0.0\n",
            "2024-12-29 02:30:04,293 [nnabla][INFO]: iter=7889 {Training loss}=3.109680619672872e-07\n",
            "2024-12-29 02:30:04,293 [nnabla][INFO]: iter=7889 {Training error}=0.0\n",
            "2024-12-29 02:30:04,332 [nnabla][INFO]: iter=7899 {Training loss}=3.080809847233468e-07\n",
            "2024-12-29 02:30:04,332 [nnabla][INFO]: iter=7899 {Training error}=0.0\n",
            "2024-12-29 02:30:04,332 [nnabla][INFO]: iter=7899 {Training time}=0.41762590408325195[sec/100iter] 37.83373260498047[sec]\n",
            "2024-12-29 02:30:04,354 [nnabla][INFO]: iter=7900 {Test error}=0.01484375\n",
            "2024-12-29 02:30:04,394 [nnabla][INFO]: iter=7909 {Training loss}=2.9820898816979025e-07\n",
            "2024-12-29 02:30:04,395 [nnabla][INFO]: iter=7909 {Training error}=0.0\n",
            "2024-12-29 02:30:04,433 [nnabla][INFO]: iter=7919 {Training loss}=3.1236504582921043e-07\n",
            "2024-12-29 02:30:04,433 [nnabla][INFO]: iter=7919 {Training error}=0.0\n",
            "2024-12-29 02:30:04,470 [nnabla][INFO]: iter=7929 {Training loss}=2.9401806500573e-07\n",
            "2024-12-29 02:30:04,471 [nnabla][INFO]: iter=7929 {Training error}=0.0\n",
            "2024-12-29 02:30:04,509 [nnabla][INFO]: iter=7939 {Training loss}=3.0733593803233816e-07\n",
            "2024-12-29 02:30:04,509 [nnabla][INFO]: iter=7939 {Training error}=0.0\n",
            "2024-12-29 02:30:04,553 [nnabla][INFO]: iter=7949 {Training loss}=2.9522877298404637e-07\n",
            "2024-12-29 02:30:04,553 [nnabla][INFO]: iter=7949 {Training error}=0.0\n",
            "2024-12-29 02:30:04,596 [nnabla][INFO]: iter=7959 {Training loss}=2.9681203272957646e-07\n",
            "2024-12-29 02:30:04,596 [nnabla][INFO]: iter=7959 {Training error}=0.0\n",
            "2024-12-29 02:30:04,633 [nnabla][INFO]: iter=7969 {Training loss}=3.0426258490479086e-07\n",
            "2024-12-29 02:30:04,634 [nnabla][INFO]: iter=7969 {Training error}=0.0\n",
            "2024-12-29 02:30:04,672 [nnabla][INFO]: iter=7979 {Training loss}=2.878713587506354e-07\n",
            "2024-12-29 02:30:04,672 [nnabla][INFO]: iter=7979 {Training error}=0.0\n",
            "2024-12-29 02:30:04,713 [nnabla][INFO]: iter=7989 {Training loss}=2.807933299209253e-07\n",
            "2024-12-29 02:30:04,714 [nnabla][INFO]: iter=7989 {Training error}=0.0\n",
            "2024-12-29 02:30:04,752 [nnabla][INFO]: iter=7999 {Training loss}=2.991403107444057e-07\n",
            "2024-12-29 02:30:04,752 [nnabla][INFO]: iter=7999 {Training error}=0.0\n",
            "2024-12-29 02:30:04,752 [nnabla][INFO]: iter=7999 {Training time}=0.42009592056274414[sec/100iter] 38.25382852554321[sec]\n",
            "2024-12-29 02:30:04,775 [nnabla][INFO]: iter=8000 {Test error}=0.0140625\n",
            "2024-12-29 02:30:04,788 [nnabla][INFO]: Solver state save (.h5): output/states_8000.h5\n",
            "2024-12-29 02:30:04,795 [nnabla][INFO]: Parameter save (.h5): output/params_8000.h5\n",
            "2024-12-29 02:30:04,795 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_8000.json\n",
            "2024-12-29 02:30:04,833 [nnabla][INFO]: iter=8009 {Training loss}=3.017480025846453e-07\n",
            "2024-12-29 02:30:04,833 [nnabla][INFO]: iter=8009 {Training error}=0.0\n",
            "2024-12-29 02:30:04,871 [nnabla][INFO]: iter=8019 {Training loss}=2.676617043562146e-07\n",
            "2024-12-29 02:30:04,872 [nnabla][INFO]: iter=8019 {Training error}=0.0\n",
            "2024-12-29 02:30:04,914 [nnabla][INFO]: iter=8029 {Training loss}=2.984883735734911e-07\n",
            "2024-12-29 02:30:04,915 [nnabla][INFO]: iter=8029 {Training error}=0.0\n",
            "2024-12-29 02:30:04,953 [nnabla][INFO]: iter=8039 {Training loss}=2.8489114356489154e-07\n",
            "2024-12-29 02:30:04,953 [nnabla][INFO]: iter=8039 {Training error}=0.0\n",
            "2024-12-29 02:30:04,990 [nnabla][INFO]: iter=8049 {Training loss}=2.8302846999395115e-07\n",
            "2024-12-29 02:30:04,990 [nnabla][INFO]: iter=8049 {Training error}=0.0\n",
            "2024-12-29 02:30:05,029 [nnabla][INFO]: iter=8059 {Training loss}=2.7446034778222383e-07\n",
            "2024-12-29 02:30:05,029 [nnabla][INFO]: iter=8059 {Training error}=0.0\n",
            "2024-12-29 02:30:05,069 [nnabla][INFO]: iter=8069 {Training loss}=2.8219031378284853e-07\n",
            "2024-12-29 02:30:05,069 [nnabla][INFO]: iter=8069 {Training error}=0.0\n",
            "2024-12-29 02:30:05,108 [nnabla][INFO]: iter=8079 {Training loss}=2.7110760925097566e-07\n",
            "2024-12-29 02:30:05,108 [nnabla][INFO]: iter=8079 {Training error}=0.0\n",
            "2024-12-29 02:30:05,146 [nnabla][INFO]: iter=8089 {Training loss}=2.827490845902503e-07\n",
            "2024-12-29 02:30:05,146 [nnabla][INFO]: iter=8089 {Training error}=0.0\n",
            "2024-12-29 02:30:05,183 [nnabla][INFO]: iter=8099 {Training loss}=2.700831203128473e-07\n",
            "2024-12-29 02:30:05,183 [nnabla][INFO]: iter=8099 {Training error}=0.0\n",
            "2024-12-29 02:30:05,183 [nnabla][INFO]: iter=8099 {Training time}=0.4315347671508789[sec/100iter] 38.68536329269409[sec]\n",
            "2024-12-29 02:30:05,211 [nnabla][INFO]: iter=8100 {Test error}=0.0140625\n",
            "2024-12-29 02:30:05,254 [nnabla][INFO]: iter=8109 {Training loss}=2.7585733164414705e-07\n",
            "2024-12-29 02:30:05,254 [nnabla][INFO]: iter=8109 {Training error}=0.0\n",
            "2024-12-29 02:30:05,293 [nnabla][INFO]: iter=8119 {Training loss}=2.726908405747963e-07\n",
            "2024-12-29 02:30:05,293 [nnabla][INFO]: iter=8119 {Training error}=0.0\n",
            "2024-12-29 02:30:05,331 [nnabla][INFO]: iter=8129 {Training loss}=2.660785014541034e-07\n",
            "2024-12-29 02:30:05,331 [nnabla][INFO]: iter=8129 {Training error}=0.0\n",
            "2024-12-29 02:30:05,370 [nnabla][INFO]: iter=8139 {Training loss}=2.64308937403257e-07\n",
            "2024-12-29 02:30:05,370 [nnabla][INFO]: iter=8139 {Training error}=0.0\n",
            "2024-12-29 02:30:05,411 [nnabla][INFO]: iter=8149 {Training loss}=2.7846505190609605e-07\n",
            "2024-12-29 02:30:05,411 [nnabla][INFO]: iter=8149 {Training error}=0.0\n",
            "2024-12-29 02:30:05,450 [nnabla][INFO]: iter=8159 {Training loss}=2.5387817004229873e-07\n",
            "2024-12-29 02:30:05,450 [nnabla][INFO]: iter=8159 {Training error}=0.0\n",
            "2024-12-29 02:30:05,488 [nnabla][INFO]: iter=8169 {Training loss}=2.585347544936667e-07\n",
            "2024-12-29 02:30:05,488 [nnabla][INFO]: iter=8169 {Training error}=0.0\n",
            "2024-12-29 02:30:05,526 [nnabla][INFO]: iter=8179 {Training loss}=2.56206448057128e-07\n",
            "2024-12-29 02:30:05,526 [nnabla][INFO]: iter=8179 {Training error}=0.0\n",
            "2024-12-29 02:30:05,565 [nnabla][INFO]: iter=8189 {Training loss}=2.6402958042126556e-07\n",
            "2024-12-29 02:30:05,565 [nnabla][INFO]: iter=8189 {Training error}=0.0\n",
            "2024-12-29 02:30:05,608 [nnabla][INFO]: iter=8199 {Training loss}=2.544369692714099e-07\n",
            "2024-12-29 02:30:05,608 [nnabla][INFO]: iter=8199 {Training error}=0.0\n",
            "2024-12-29 02:30:05,608 [nnabla][INFO]: iter=8199 {Training time}=0.4246366024017334[sec/100iter] 39.109999895095825[sec]\n",
            "2024-12-29 02:30:05,630 [nnabla][INFO]: iter=8200 {Test error}=0.01484375\n",
            "2024-12-29 02:30:05,666 [nnabla][INFO]: iter=8209 {Training loss}=2.565789714026323e-07\n",
            "2024-12-29 02:30:05,666 [nnabla][INFO]: iter=8209 {Training error}=0.0\n",
            "2024-12-29 02:30:05,703 [nnabla][INFO]: iter=8219 {Training loss}=2.5322623287138413e-07\n",
            "2024-12-29 02:30:05,703 [nnabla][INFO]: iter=8219 {Training error}=0.0\n",
            "2024-12-29 02:30:05,743 [nnabla][INFO]: iter=8229 {Training loss}=2.486627863618196e-07\n",
            "2024-12-29 02:30:05,743 [nnabla][INFO]: iter=8229 {Training error}=0.0\n",
            "2024-12-29 02:30:05,780 [nnabla][INFO]: iter=8239 {Training loss}=2.6067681346830796e-07\n",
            "2024-12-29 02:30:05,780 [nnabla][INFO]: iter=8239 {Training error}=0.0\n",
            "2024-12-29 02:30:05,818 [nnabla][INFO]: iter=8249 {Training loss}=2.443786968342465e-07\n",
            "2024-12-29 02:30:05,819 [nnabla][INFO]: iter=8249 {Training error}=0.0\n",
            "2024-12-29 02:30:05,856 [nnabla][INFO]: iter=8259 {Training loss}=2.455894332342723e-07\n",
            "2024-12-29 02:30:05,856 [nnabla][INFO]: iter=8259 {Training error}=0.0\n",
            "2024-12-29 02:30:05,895 [nnabla][INFO]: iter=8269 {Training loss}=2.4838340095811873e-07\n",
            "2024-12-29 02:30:05,895 [nnabla][INFO]: iter=8269 {Training error}=0.0\n",
            "2024-12-29 02:30:05,936 [nnabla][INFO]: iter=8279 {Training loss}=2.4279546551042586e-07\n",
            "2024-12-29 02:30:05,936 [nnabla][INFO]: iter=8279 {Training error}=0.0\n",
            "2024-12-29 02:30:05,973 [nnabla][INFO]: iter=8289 {Training loss}=2.4950097099463164e-07\n",
            "2024-12-29 02:30:05,973 [nnabla][INFO]: iter=8289 {Training error}=0.0\n",
            "2024-12-29 02:30:06,010 [nnabla][INFO]: iter=8299 {Training loss}=2.3553113237539947e-07\n",
            "2024-12-29 02:30:06,011 [nnabla][INFO]: iter=8299 {Training error}=0.0\n",
            "2024-12-29 02:30:06,011 [nnabla][INFO]: iter=8299 {Training time}=0.4025704860687256[sec/100iter] 39.51257038116455[sec]\n",
            "2024-12-29 02:30:06,035 [nnabla][INFO]: iter=8300 {Test error}=0.0140625\n",
            "2024-12-29 02:30:06,073 [nnabla][INFO]: iter=8309 {Training loss}=2.378594672336476e-07\n",
            "2024-12-29 02:30:06,073 [nnabla][INFO]: iter=8309 {Training error}=0.0\n",
            "2024-12-29 02:30:06,109 [nnabla][INFO]: iter=8319 {Training loss}=2.436336501432379e-07\n",
            "2024-12-29 02:30:06,109 [nnabla][INFO]: iter=8319 {Training error}=0.0\n",
            "2024-12-29 02:30:06,146 [nnabla][INFO]: iter=8329 {Training loss}=2.4884906224542647e-07\n",
            "2024-12-29 02:30:06,146 [nnabla][INFO]: iter=8329 {Training error}=0.0\n",
            "2024-12-29 02:30:06,183 [nnabla][INFO]: iter=8339 {Training loss}=2.247278416689369e-07\n",
            "2024-12-29 02:30:06,183 [nnabla][INFO]: iter=8339 {Training error}=0.0\n",
            "2024-12-29 02:30:06,223 [nnabla][INFO]: iter=8349 {Training loss}=2.2919819286926213e-07\n",
            "2024-12-29 02:30:06,224 [nnabla][INFO]: iter=8349 {Training error}=0.0\n",
            "2024-12-29 02:30:06,263 [nnabla][INFO]: iter=8359 {Training loss}=2.475452163253067e-07\n",
            "2024-12-29 02:30:06,263 [nnabla][INFO]: iter=8359 {Training error}=0.0\n",
            "2024-12-29 02:30:06,300 [nnabla][INFO]: iter=8369 {Training loss}=2.2789433273828763e-07\n",
            "2024-12-29 02:30:06,300 [nnabla][INFO]: iter=8369 {Training error}=0.0\n",
            "2024-12-29 02:30:06,337 [nnabla][INFO]: iter=8379 {Training loss}=2.3273719307326246e-07\n",
            "2024-12-29 02:30:06,337 [nnabla][INFO]: iter=8379 {Training error}=0.0\n",
            "2024-12-29 02:30:06,374 [nnabla][INFO]: iter=8389 {Training loss}=2.2901193119650998e-07\n",
            "2024-12-29 02:30:06,374 [nnabla][INFO]: iter=8389 {Training error}=0.0\n",
            "2024-12-29 02:30:06,410 [nnabla][INFO]: iter=8399 {Training loss}=2.2361027163242397e-07\n",
            "2024-12-29 02:30:06,410 [nnabla][INFO]: iter=8399 {Training error}=0.0\n",
            "2024-12-29 02:30:06,410 [nnabla][INFO]: iter=8399 {Training time}=0.3996298313140869[sec/100iter] 39.91220021247864[sec]\n",
            "2024-12-29 02:30:06,437 [nnabla][INFO]: iter=8400 {Test error}=0.0140625\n",
            "2024-12-29 02:30:06,475 [nnabla][INFO]: iter=8409 {Training loss}=2.3366854406958737e-07\n",
            "2024-12-29 02:30:06,475 [nnabla][INFO]: iter=8409 {Training error}=0.0\n",
            "2024-12-29 02:30:06,511 [nnabla][INFO]: iter=8419 {Training loss}=2.23982809188783e-07\n",
            "2024-12-29 02:30:06,511 [nnabla][INFO]: iter=8419 {Training error}=0.0\n",
            "2024-12-29 02:30:06,549 [nnabla][INFO]: iter=8429 {Training loss}=2.2323774828691967e-07\n",
            "2024-12-29 02:30:06,549 [nnabla][INFO]: iter=8429 {Training error}=0.0\n",
            "2024-12-29 02:30:06,587 [nnabla][INFO]: iter=8439 {Training loss}=2.251003650144412e-07\n",
            "2024-12-29 02:30:06,587 [nnabla][INFO]: iter=8439 {Training error}=0.0\n",
            "2024-12-29 02:30:06,633 [nnabla][INFO]: iter=8449 {Training loss}=2.146695834426282e-07\n",
            "2024-12-29 02:30:06,633 [nnabla][INFO]: iter=8449 {Training error}=0.0\n",
            "2024-12-29 02:30:06,672 [nnabla][INFO]: iter=8459 {Training loss}=2.2603168758905667e-07\n",
            "2024-12-29 02:30:06,672 [nnabla][INFO]: iter=8459 {Training error}=0.0\n",
            "2024-12-29 02:30:06,708 [nnabla][INFO]: iter=8469 {Training loss}=2.1578719611170527e-07\n",
            "2024-12-29 02:30:06,709 [nnabla][INFO]: iter=8469 {Training error}=0.0\n",
            "2024-12-29 02:30:06,746 [nnabla][INFO]: iter=8479 {Training loss}=2.0926793808939692e-07\n",
            "2024-12-29 02:30:06,746 [nnabla][INFO]: iter=8479 {Training error}=0.0\n",
            "2024-12-29 02:30:06,782 [nnabla][INFO]: iter=8489 {Training loss}=2.16252857399013e-07\n",
            "2024-12-29 02:30:06,782 [nnabla][INFO]: iter=8489 {Training error}=0.0\n",
            "2024-12-29 02:30:06,821 [nnabla][INFO]: iter=8499 {Training loss}=2.126206766206451e-07\n",
            "2024-12-29 02:30:06,821 [nnabla][INFO]: iter=8499 {Training error}=0.0\n",
            "2024-12-29 02:30:06,821 [nnabla][INFO]: iter=8499 {Training time}=0.4107215404510498[sec/100iter] 40.32292175292969[sec]\n",
            "2024-12-29 02:30:06,844 [nnabla][INFO]: iter=8500 {Test error}=0.0140625\n",
            "2024-12-29 02:30:06,881 [nnabla][INFO]: iter=8509 {Training loss}=2.108511836240723e-07\n",
            "2024-12-29 02:30:06,881 [nnabla][INFO]: iter=8509 {Training error}=0.0\n",
            "2024-12-29 02:30:06,918 [nnabla][INFO]: iter=8519 {Training loss}=2.1271382877330325e-07\n",
            "2024-12-29 02:30:06,918 [nnabla][INFO]: iter=8519 {Training error}=0.0\n",
            "2024-12-29 02:30:06,960 [nnabla][INFO]: iter=8529 {Training loss}=2.0712589332561038e-07\n",
            "2024-12-29 02:30:06,960 [nnabla][INFO]: iter=8529 {Training error}=0.0\n",
            "2024-12-29 02:30:06,996 [nnabla][INFO]: iter=8539 {Training loss}=2.1746355116647464e-07\n",
            "2024-12-29 02:30:06,997 [nnabla][INFO]: iter=8539 {Training error}=0.0\n",
            "2024-12-29 02:30:07,036 [nnabla][INFO]: iter=8549 {Training loss}=2.0451821569622552e-07\n",
            "2024-12-29 02:30:07,036 [nnabla][INFO]: iter=8549 {Training error}=0.0\n",
            "2024-12-29 02:30:07,074 [nnabla][INFO]: iter=8559 {Training loss}=2.1345886125345714e-07\n",
            "2024-12-29 02:30:07,074 [nnabla][INFO]: iter=8559 {Training error}=0.0\n",
            "2024-12-29 02:30:07,111 [nnabla][INFO]: iter=8569 {Training loss}=2.0368000264170405e-07\n",
            "2024-12-29 02:30:07,111 [nnabla][INFO]: iter=8569 {Training error}=0.0\n",
            "2024-12-29 02:30:07,151 [nnabla][INFO]: iter=8579 {Training loss}=2.007929253977636e-07\n",
            "2024-12-29 02:30:07,151 [nnabla][INFO]: iter=8579 {Training error}=0.0\n",
            "2024-12-29 02:30:07,190 [nnabla][INFO]: iter=8589 {Training loss}=2.0647397036555049e-07\n",
            "2024-12-29 02:30:07,190 [nnabla][INFO]: iter=8589 {Training error}=0.0\n",
            "2024-12-29 02:30:07,228 [nnabla][INFO]: iter=8599 {Training loss}=1.9418052943365183e-07\n",
            "2024-12-29 02:30:07,229 [nnabla][INFO]: iter=8599 {Training error}=0.0\n",
            "2024-12-29 02:30:07,229 [nnabla][INFO]: iter=8599 {Training time}=0.407639741897583[sec/100iter] 40.73056149482727[sec]\n",
            "2024-12-29 02:30:07,254 [nnabla][INFO]: iter=8600 {Test error}=0.01484375\n",
            "2024-12-29 02:30:07,291 [nnabla][INFO]: iter=8609 {Training loss}=2.061014612309009e-07\n",
            "2024-12-29 02:30:07,291 [nnabla][INFO]: iter=8609 {Training error}=0.0\n",
            "2024-12-29 02:30:07,328 [nnabla][INFO]: iter=8619 {Training loss}=1.9296980724448076e-07\n",
            "2024-12-29 02:30:07,328 [nnabla][INFO]: iter=8619 {Training error}=0.0\n",
            "2024-12-29 02:30:07,366 [nnabla][INFO]: iter=8629 {Training loss}=2.0526324817637942e-07\n",
            "2024-12-29 02:30:07,366 [nnabla][INFO]: iter=8629 {Training error}=0.0\n",
            "2024-12-29 02:30:07,402 [nnabla][INFO]: iter=8639 {Training loss}=1.969745255792077e-07\n",
            "2024-12-29 02:30:07,402 [nnabla][INFO]: iter=8639 {Training error}=0.0\n",
            "2024-12-29 02:30:07,443 [nnabla][INFO]: iter=8649 {Training loss}=1.9296980724448076e-07\n",
            "2024-12-29 02:30:07,443 [nnabla][INFO]: iter=8649 {Training error}=0.0\n",
            "2024-12-29 02:30:07,480 [nnabla][INFO]: iter=8659 {Training loss}=1.9837148101942148e-07\n",
            "2024-12-29 02:30:07,480 [nnabla][INFO]: iter=8659 {Training error}=0.0\n",
            "2024-12-29 02:30:07,516 [nnabla][INFO]: iter=8669 {Training loss}=1.94646219142669e-07\n",
            "2024-12-29 02:30:07,517 [nnabla][INFO]: iter=8669 {Training error}=0.0\n",
            "2024-12-29 02:30:07,554 [nnabla][INFO]: iter=8679 {Training loss}=1.9734702050300257e-07\n",
            "2024-12-29 02:30:07,554 [nnabla][INFO]: iter=8679 {Training error}=0.0\n",
            "2024-12-29 02:30:07,591 [nnabla][INFO]: iter=8689 {Training loss}=1.912934521897114e-07\n",
            "2024-12-29 02:30:07,591 [nnabla][INFO]: iter=8689 {Training error}=0.0\n",
            "2024-12-29 02:30:07,628 [nnabla][INFO]: iter=8699 {Training loss}=1.943668195281134e-07\n",
            "2024-12-29 02:30:07,628 [nnabla][INFO]: iter=8699 {Training error}=0.0\n",
            "2024-12-29 02:30:07,628 [nnabla][INFO]: iter=8699 {Training time}=0.39927148818969727[sec/100iter] 41.12983298301697[sec]\n",
            "2024-12-29 02:30:07,659 [nnabla][INFO]: iter=8700 {Test error}=0.0140625\n",
            "2024-12-29 02:30:07,698 [nnabla][INFO]: iter=8709 {Training loss}=1.912934521897114e-07\n",
            "2024-12-29 02:30:07,698 [nnabla][INFO]: iter=8709 {Training error}=0.0\n",
            "2024-12-29 02:30:07,737 [nnabla][INFO]: iter=8719 {Training loss}=1.8980334459683945e-07\n",
            "2024-12-29 02:30:07,737 [nnabla][INFO]: iter=8719 {Training error}=0.0\n",
            "2024-12-29 02:30:07,778 [nnabla][INFO]: iter=8729 {Training loss}=1.8784757571665978e-07\n",
            "2024-12-29 02:30:07,778 [nnabla][INFO]: iter=8729 {Training error}=0.0\n",
            "2024-12-29 02:30:07,817 [nnabla][INFO]: iter=8739 {Training loss}=1.8784757571665978e-07\n",
            "2024-12-29 02:30:07,817 [nnabla][INFO]: iter=8739 {Training error}=0.0\n",
            "2024-12-29 02:30:07,857 [nnabla][INFO]: iter=8749 {Training loss}=1.9213163682252343e-07\n",
            "2024-12-29 02:30:07,857 [nnabla][INFO]: iter=8749 {Training error}=0.0\n",
            "2024-12-29 02:30:07,895 [nnabla][INFO]: iter=8759 {Training loss}=1.9138659013151482e-07\n",
            "2024-12-29 02:30:07,895 [nnabla][INFO]: iter=8759 {Training error}=0.0\n",
            "2024-12-29 02:30:07,933 [nnabla][INFO]: iter=8769 {Training loss}=1.8337723872718925e-07\n",
            "2024-12-29 02:30:07,933 [nnabla][INFO]: iter=8769 {Training error}=0.0\n",
            "2024-12-29 02:30:07,973 [nnabla][INFO]: iter=8779 {Training loss}=1.8840634652406152e-07\n",
            "2024-12-29 02:30:07,974 [nnabla][INFO]: iter=8779 {Training error}=0.0\n",
            "2024-12-29 02:30:08,011 [nnabla][INFO]: iter=8789 {Training loss}=1.7806870289405197e-07\n",
            "2024-12-29 02:30:08,011 [nnabla][INFO]: iter=8789 {Training error}=0.0\n",
            "2024-12-29 02:30:08,049 [nnabla][INFO]: iter=8799 {Training loss}=1.835635003999414e-07\n",
            "2024-12-29 02:30:08,049 [nnabla][INFO]: iter=8799 {Training error}=0.0\n",
            "2024-12-29 02:30:08,050 [nnabla][INFO]: iter=8799 {Training time}=0.4216117858886719[sec/100iter] 41.55144476890564[sec]\n",
            "2024-12-29 02:30:08,073 [nnabla][INFO]: iter=8800 {Test error}=0.0140625\n",
            "2024-12-29 02:30:08,110 [nnabla][INFO]: iter=8809 {Training loss}=1.7769617954854766e-07\n",
            "2024-12-29 02:30:08,110 [nnabla][INFO]: iter=8809 {Training error}=0.0\n",
            "2024-12-29 02:30:08,149 [nnabla][INFO]: iter=8819 {Training loss}=1.8328410078538582e-07\n",
            "2024-12-29 02:30:08,150 [nnabla][INFO]: iter=8819 {Training error}=0.0\n",
            "2024-12-29 02:30:08,188 [nnabla][INFO]: iter=8829 {Training loss}=1.8253902567266778e-07\n",
            "2024-12-29 02:30:08,188 [nnabla][INFO]: iter=8829 {Training error}=0.0\n",
            "2024-12-29 02:30:08,227 [nnabla][INFO]: iter=8839 {Training loss}=1.75833520188462e-07\n",
            "2024-12-29 02:30:08,227 [nnabla][INFO]: iter=8839 {Training error}=0.0\n",
            "2024-12-29 02:30:08,265 [nnabla][INFO]: iter=8849 {Training loss}=1.758335343993167e-07\n",
            "2024-12-29 02:30:08,265 [nnabla][INFO]: iter=8849 {Training error}=0.0\n",
            "2024-12-29 02:30:08,303 [nnabla][INFO]: iter=8859 {Training loss}=1.8179399319251388e-07\n",
            "2024-12-29 02:30:08,303 [nnabla][INFO]: iter=8859 {Training error}=0.0\n",
            "2024-12-29 02:30:08,340 [nnabla][INFO]: iter=8869 {Training loss}=1.7471593594109436e-07\n",
            "2024-12-29 02:30:08,341 [nnabla][INFO]: iter=8869 {Training error}=0.0\n",
            "2024-12-29 02:30:08,378 [nnabla][INFO]: iter=8879 {Training loss}=1.7285330500271812e-07\n",
            "2024-12-29 02:30:08,378 [nnabla][INFO]: iter=8879 {Training error}=0.0\n",
            "2024-12-29 02:30:08,416 [nnabla][INFO]: iter=8889 {Training loss}=1.7695111864668434e-07\n",
            "2024-12-29 02:30:08,416 [nnabla][INFO]: iter=8889 {Training error}=0.0\n",
            "2024-12-29 02:30:08,459 [nnabla][INFO]: iter=8899 {Training loss}=1.673585217076834e-07\n",
            "2024-12-29 02:30:08,459 [nnabla][INFO]: iter=8899 {Training error}=0.0\n",
            "2024-12-29 02:30:08,459 [nnabla][INFO]: iter=8899 {Training time}=0.4094722270965576[sec/100iter] 41.9609169960022[sec]\n",
            "2024-12-29 02:30:08,482 [nnabla][INFO]: iter=8900 {Test error}=0.01484375\n",
            "2024-12-29 02:30:08,521 [nnabla][INFO]: iter=8909 {Training loss}=1.6996621354792296e-07\n",
            "2024-12-29 02:30:08,521 [nnabla][INFO]: iter=8909 {Training error}=0.0\n",
            "2024-12-29 02:30:08,559 [nnabla][INFO]: iter=8919 {Training loss}=1.7527473517020553e-07\n",
            "2024-12-29 02:30:08,559 [nnabla][INFO]: iter=8919 {Training error}=0.0\n",
            "2024-12-29 02:30:08,598 [nnabla][INFO]: iter=8929 {Training loss}=1.6884862930055533e-07\n",
            "2024-12-29 02:30:08,599 [nnabla][INFO]: iter=8929 {Training error}=0.0\n",
            "2024-12-29 02:30:08,635 [nnabla][INFO]: iter=8939 {Training loss}=1.6381949308197363e-07\n",
            "2024-12-29 02:30:08,636 [nnabla][INFO]: iter=8939 {Training error}=0.0\n",
            "2024-12-29 02:30:08,676 [nnabla][INFO]: iter=8949 {Training loss}=1.724807674463591e-07\n",
            "2024-12-29 02:30:08,676 [nnabla][INFO]: iter=8949 {Training error}=0.0\n",
            "2024-12-29 02:30:08,717 [nnabla][INFO]: iter=8959 {Training loss}=1.6596152363490546e-07\n",
            "2024-12-29 02:30:08,717 [nnabla][INFO]: iter=8959 {Training error}=0.0\n",
            "2024-12-29 02:30:08,755 [nnabla][INFO]: iter=8969 {Training loss}=1.6381949308197363e-07\n",
            "2024-12-29 02:30:08,756 [nnabla][INFO]: iter=8969 {Training error}=0.0\n",
            "2024-12-29 02:30:08,793 [nnabla][INFO]: iter=8979 {Training loss}=1.6614778530765761e-07\n",
            "2024-12-29 02:30:08,793 [nnabla][INFO]: iter=8979 {Training error}=0.0\n",
            "2024-12-29 02:30:08,831 [nnabla][INFO]: iter=8989 {Training loss}=1.6381949308197363e-07\n",
            "2024-12-29 02:30:08,831 [nnabla][INFO]: iter=8989 {Training error}=0.0\n",
            "2024-12-29 02:30:08,869 [nnabla][INFO]: iter=8999 {Training loss}=1.5711397338691313e-07\n",
            "2024-12-29 02:30:08,869 [nnabla][INFO]: iter=8999 {Training error}=0.0\n",
            "2024-12-29 02:30:08,869 [nnabla][INFO]: iter=8999 {Training time}=0.4100341796875[sec/100iter] 42.3709511756897[sec]\n",
            "2024-12-29 02:30:08,893 [nnabla][INFO]: iter=9000 {Test error}=0.0140625\n",
            "2024-12-29 02:30:08,907 [nnabla][INFO]: Solver state save (.h5): output/states_9000.h5\n",
            "2024-12-29 02:30:08,913 [nnabla][INFO]: Parameter save (.h5): output/params_9000.h5\n",
            "2024-12-29 02:30:08,913 [nnabla][INFO]: Checkpoint save (.json): output/checkpoint_9000.json\n",
            "2024-12-29 02:30:08,952 [nnabla][INFO]: iter=9009 {Training loss}=1.6000106484170828e-07\n",
            "2024-12-29 02:30:08,952 [nnabla][INFO]: iter=9009 {Training error}=0.0\n",
            "2024-12-29 02:30:08,992 [nnabla][INFO]: iter=9019 {Training loss}=1.5655517415780196e-07\n",
            "2024-12-29 02:30:08,992 [nnabla][INFO]: iter=9019 {Training error}=0.0\n",
            "2024-12-29 02:30:09,030 [nnabla][INFO]: iter=9029 {Training loss}=1.5776591055782774e-07\n",
            "2024-12-29 02:30:09,030 [nnabla][INFO]: iter=9029 {Training error}=0.0\n",
            "2024-12-29 02:30:09,070 [nnabla][INFO]: iter=9039 {Training loss}=1.6093238741632376e-07\n",
            "2024-12-29 02:30:09,071 [nnabla][INFO]: iter=9039 {Training error}=0.0\n",
            "2024-12-29 02:30:09,108 [nnabla][INFO]: iter=9049 {Training loss}=1.5338869729930593e-07\n",
            "2024-12-29 02:30:09,108 [nnabla][INFO]: iter=9049 {Training error}=0.0\n",
            "2024-12-29 02:30:09,146 [nnabla][INFO]: iter=9059 {Training loss}=1.553444661794856e-07\n",
            "2024-12-29 02:30:09,147 [nnabla][INFO]: iter=9059 {Training error}=0.0\n",
            "2024-12-29 02:30:09,187 [nnabla][INFO]: iter=9069 {Training loss}=1.6186369578008453e-07\n",
            "2024-12-29 02:30:09,188 [nnabla][INFO]: iter=9069 {Training error}=0.0\n",
            "2024-12-29 02:30:09,227 [nnabla][INFO]: iter=9079 {Training loss}=1.5357495897205808e-07\n",
            "2024-12-29 02:30:09,227 [nnabla][INFO]: iter=9079 {Training error}=0.0\n",
            "2024-12-29 02:30:09,265 [nnabla][INFO]: iter=9089 {Training loss}=1.5078099124821165e-07\n",
            "2024-12-29 02:30:09,265 [nnabla][INFO]: iter=9089 {Training error}=0.0\n",
            "2024-12-29 02:30:09,302 [nnabla][INFO]: iter=9099 {Training loss}=1.5581014167764806e-07\n",
            "2024-12-29 02:30:09,302 [nnabla][INFO]: iter=9099 {Training error}=0.0\n",
            "2024-12-29 02:30:09,302 [nnabla][INFO]: iter=9099 {Training time}=0.4331498146057129[sec/100iter] 42.80410099029541[sec]\n",
            "2024-12-29 02:30:09,325 [nnabla][INFO]: iter=9100 {Test error}=0.0140625\n",
            "2024-12-29 02:30:09,363 [nnabla][INFO]: iter=9109 {Training loss}=1.5022219201910048e-07\n",
            "2024-12-29 02:30:09,363 [nnabla][INFO]: iter=9109 {Training error}=0.0\n",
            "2024-12-29 02:30:09,400 [nnabla][INFO]: iter=9119 {Training loss}=1.5012906828815176e-07\n",
            "2024-12-29 02:30:09,400 [nnabla][INFO]: iter=9119 {Training error}=0.0\n",
            "2024-12-29 02:30:09,437 [nnabla][INFO]: iter=9129 {Training loss}=1.492908836553397e-07\n",
            "2024-12-29 02:30:09,437 [nnabla][INFO]: iter=9129 {Training error}=0.0\n",
            "2024-12-29 02:30:09,477 [nnabla][INFO]: iter=9139 {Training loss}=1.4705570094974973e-07\n",
            "2024-12-29 02:30:09,477 [nnabla][INFO]: iter=9139 {Training error}=0.0\n",
            "2024-12-29 02:30:09,517 [nnabla][INFO]: iter=9149 {Training loss}=1.4808016146616865e-07\n",
            "2024-12-29 02:30:09,517 [nnabla][INFO]: iter=9149 {Training error}=0.0\n",
            "2024-12-29 02:30:09,555 [nnabla][INFO]: iter=9159 {Training loss}=1.5189857549557928e-07\n",
            "2024-12-29 02:30:09,555 [nnabla][INFO]: iter=9159 {Training error}=0.0\n",
            "2024-12-29 02:30:09,592 [nnabla][INFO]: iter=9169 {Training loss}=1.4230597855657834e-07\n",
            "2024-12-29 02:30:09,593 [nnabla][INFO]: iter=9169 {Training error}=0.0\n",
            "2024-12-29 02:30:09,629 [nnabla][INFO]: iter=9179 {Training loss}=1.4528620795317693e-07\n",
            "2024-12-29 02:30:09,629 [nnabla][INFO]: iter=9179 {Training error}=0.0\n",
            "2024-12-29 02:30:09,666 [nnabla][INFO]: iter=9189 {Training loss}=1.4854580854262167e-07\n",
            "2024-12-29 02:30:09,666 [nnabla][INFO]: iter=9189 {Training error}=0.0\n",
            "2024-12-29 02:30:09,702 [nnabla][INFO]: iter=9199 {Training loss}=1.476145001788609e-07\n",
            "2024-12-29 02:30:09,703 [nnabla][INFO]: iter=9199 {Training error}=0.0\n",
            "2024-12-29 02:30:09,703 [nnabla][INFO]: iter=9199 {Training time}=0.40056276321411133[sec/100iter] 43.20466375350952[sec]\n",
            "2024-12-29 02:30:09,731 [nnabla][INFO]: iter=9200 {Test error}=0.0140625\n",
            "2024-12-29 02:30:09,769 [nnabla][INFO]: iter=9209 {Training loss}=1.4407547155315115e-07\n",
            "2024-12-29 02:30:09,770 [nnabla][INFO]: iter=9209 {Training error}=0.0\n",
            "2024-12-29 02:30:09,807 [nnabla][INFO]: iter=9219 {Training loss}=1.435167007457494e-07\n",
            "2024-12-29 02:30:09,807 [nnabla][INFO]: iter=9219 {Training error}=0.0\n",
            "2024-12-29 02:30:09,845 [nnabla][INFO]: iter=9229 {Training loss}=1.4025707173459523e-07\n",
            "2024-12-29 02:30:09,846 [nnabla][INFO]: iter=9229 {Training error}=0.0\n",
            "2024-12-29 02:30:09,892 [nnabla][INFO]: iter=9239 {Training loss}=1.4090899469465512e-07\n",
            "2024-12-29 02:30:09,892 [nnabla][INFO]: iter=9239 {Training error}=0.0\n",
            "2024-12-29 02:30:09,929 [nnabla][INFO]: iter=9249 {Training loss}=1.344828604032955e-07\n",
            "2024-12-29 02:30:09,929 [nnabla][INFO]: iter=9249 {Training error}=0.0\n",
            "2024-12-29 02:30:09,969 [nnabla][INFO]: iter=9259 {Training loss}=1.4379608614945028e-07\n",
            "2024-12-29 02:30:09,969 [nnabla][INFO]: iter=9259 {Training error}=0.0\n",
            "2024-12-29 02:30:10,007 [nnabla][INFO]: iter=9269 {Training loss}=1.347622742287058e-07\n",
            "2024-12-29 02:30:10,007 [nnabla][INFO]: iter=9269 {Training error}=0.0\n",
            "2024-12-29 02:30:10,045 [nnabla][INFO]: iter=9279 {Training loss}=1.4230596434572362e-07\n",
            "2024-12-29 02:30:10,046 [nnabla][INFO]: iter=9279 {Training error}=0.0\n",
            "2024-12-29 02:30:10,084 [nnabla][INFO]: iter=9289 {Training loss}=1.4025707173459523e-07\n",
            "2024-12-29 02:30:10,084 [nnabla][INFO]: iter=9289 {Training error}=0.0\n",
            "2024-12-29 02:30:10,121 [nnabla][INFO]: iter=9299 {Training loss}=1.304781847011327e-07\n",
            "2024-12-29 02:30:10,121 [nnabla][INFO]: iter=9299 {Training error}=0.0\n",
            "2024-12-29 02:30:10,121 [nnabla][INFO]: iter=9299 {Training time}=0.4184257984161377[sec/100iter] 43.62308955192566[sec]\n",
            "2024-12-29 02:30:10,144 [nnabla][INFO]: iter=9300 {Test error}=0.01484375\n",
            "2024-12-29 02:30:10,183 [nnabla][INFO]: iter=9309 {Training loss}=1.3587985847607342e-07\n",
            "2024-12-29 02:30:10,183 [nnabla][INFO]: iter=9309 {Training error}=0.0\n",
            "2024-12-29 02:30:10,220 [nnabla][INFO]: iter=9319 {Training loss}=1.3671805731974018e-07\n",
            "2024-12-29 02:30:10,220 [nnabla][INFO]: iter=9319 {Training error}=0.0\n",
            "2024-12-29 02:30:10,257 [nnabla][INFO]: iter=9329 {Training loss}=1.3662490516708203e-07\n",
            "2024-12-29 02:30:10,258 [nnabla][INFO]: iter=9329 {Training error}=0.0\n",
            "2024-12-29 02:30:10,298 [nnabla][INFO]: iter=9339 {Training loss}=1.3355153782868e-07\n",
            "2024-12-29 02:30:10,298 [nnabla][INFO]: iter=9339 {Training error}=0.0\n",
            "2024-12-29 02:30:10,336 [nnabla][INFO]: iter=9349 {Training loss}=1.3252710573397053e-07\n",
            "2024-12-29 02:30:10,337 [nnabla][INFO]: iter=9349 {Training error}=0.0\n",
            "2024-12-29 02:30:10,375 [nnabla][INFO]: iter=9359 {Training loss}=1.3429659873054334e-07\n",
            "2024-12-29 02:30:10,375 [nnabla][INFO]: iter=9359 {Training error}=0.0\n",
            "2024-12-29 02:30:10,414 [nnabla][INFO]: iter=9369 {Training loss}=1.2628724732621777e-07\n",
            "2024-12-29 02:30:10,414 [nnabla][INFO]: iter=9369 {Training error}=0.0\n",
            "2024-12-29 02:30:10,454 [nnabla][INFO]: iter=9379 {Training loss}=1.3709056645438977e-07\n",
            "2024-12-29 02:30:10,454 [nnabla][INFO]: iter=9379 {Training error}=0.0\n",
            "2024-12-29 02:30:10,497 [nnabla][INFO]: iter=9389 {Training loss}=1.2619412359526905e-07\n",
            "2024-12-29 02:30:10,497 [nnabla][INFO]: iter=9389 {Training error}=0.0\n",
            "2024-12-29 02:30:10,537 [nnabla][INFO]: iter=9399 {Training loss}=1.2870867749370518e-07\n",
            "2024-12-29 02:30:10,537 [nnabla][INFO]: iter=9399 {Training error}=0.0\n",
            "2024-12-29 02:30:10,537 [nnabla][INFO]: iter=9399 {Training time}=0.41610026359558105[sec/100iter] 44.03918981552124[sec]\n",
            "2024-12-29 02:30:10,560 [nnabla][INFO]: iter=9400 {Test error}=0.0140625\n",
            "2024-12-29 02:30:10,598 [nnabla][INFO]: iter=9409 {Training loss}=1.3001253762467968e-07\n",
            "2024-12-29 02:30:10,599 [nnabla][INFO]: iter=9409 {Training error}=0.0\n",
            "2024-12-29 02:30:10,637 [nnabla][INFO]: iter=9419 {Training loss}=1.2218944789310626e-07\n",
            "2024-12-29 02:30:10,637 [nnabla][INFO]: iter=9419 {Training error}=0.0\n",
            "2024-12-29 02:30:10,674 [nnabla][INFO]: iter=9429 {Training loss}=1.240520788314825e-07\n",
            "2024-12-29 02:30:10,674 [nnabla][INFO]: iter=9429 {Training error}=0.0\n",
            "2024-12-29 02:30:10,713 [nnabla][INFO]: iter=9439 {Training loss}=1.2591473819156818e-07\n",
            "2024-12-29 02:30:10,713 [nnabla][INFO]: iter=9439 {Training error}=0.0\n",
            "2024-12-29 02:30:10,754 [nnabla][INFO]: iter=9449 {Training loss}=1.2693917028627766e-07\n",
            "2024-12-29 02:30:10,754 [nnabla][INFO]: iter=9449 {Training error}=0.0\n",
            "2024-12-29 02:30:10,794 [nnabla][INFO]: iter=9459 {Training loss}=1.2172378660579852e-07\n",
            "2024-12-29 02:30:10,794 [nnabla][INFO]: iter=9459 {Training error}=0.0\n",
            "2024-12-29 02:30:10,833 [nnabla][INFO]: iter=9469 {Training loss}=1.2591472398071346e-07\n",
            "2024-12-29 02:30:10,833 [nnabla][INFO]: iter=9469 {Training error}=0.0\n",
            "2024-12-29 02:30:10,871 [nnabla][INFO]: iter=9479 {Training loss}=1.209787257039352e-07\n",
            "2024-12-29 02:30:10,871 [nnabla][INFO]: iter=9479 {Training error}=0.0\n",
            "2024-12-29 02:30:10,909 [nnabla][INFO]: iter=9489 {Training loss}=1.2265509496955929e-07\n",
            "2024-12-29 02:30:10,909 [nnabla][INFO]: iter=9489 {Training error}=0.0\n",
            "2024-12-29 02:30:10,946 [nnabla][INFO]: iter=9499 {Training loss}=1.1734656624184936e-07\n",
            "2024-12-29 02:30:10,946 [nnabla][INFO]: iter=9499 {Training error}=0.0\n",
            "2024-12-29 02:30:10,946 [nnabla][INFO]: iter=9499 {Training time}=0.4085574150085449[sec/100iter] 44.447747230529785[sec]\n",
            "2024-12-29 02:30:10,968 [nnabla][INFO]: iter=9500 {Test error}=0.0140625\n",
            "2024-12-29 02:30:11,005 [nnabla][INFO]: iter=9509 {Training loss}=1.2274823291136272e-07\n",
            "2024-12-29 02:30:11,005 [nnabla][INFO]: iter=9509 {Training error}=0.0\n",
            "2024-12-29 02:30:11,044 [nnabla][INFO]: iter=9519 {Training loss}=1.1948858968935383e-07\n",
            "2024-12-29 02:30:11,044 [nnabla][INFO]: iter=9519 {Training error}=0.0\n",
            "2024-12-29 02:30:11,085 [nnabla][INFO]: iter=9529 {Training loss}=1.1706716662729377e-07\n",
            "2024-12-29 02:30:11,085 [nnabla][INFO]: iter=9529 {Training error}=0.0\n",
            "2024-12-29 02:30:11,122 [nnabla][INFO]: iter=9539 {Training loss}=1.2153751072219166e-07\n",
            "2024-12-29 02:30:11,122 [nnabla][INFO]: iter=9539 {Training error}=0.0\n",
            "2024-12-29 02:30:11,160 [nnabla][INFO]: iter=9549 {Training loss}=1.1734656624184936e-07\n",
            "2024-12-29 02:30:11,160 [nnabla][INFO]: iter=9549 {Training error}=0.0\n",
            "2024-12-29 02:30:11,197 [nnabla][INFO]: iter=9559 {Training loss}=1.1771909669278102e-07\n",
            "2024-12-29 02:30:11,197 [nnabla][INFO]: iter=9559 {Training error}=0.0\n",
            "2024-12-29 02:30:11,235 [nnabla][INFO]: iter=9569 {Training loss}=1.1371442099061824e-07\n",
            "2024-12-29 02:30:11,235 [nnabla][INFO]: iter=9569 {Training error}=0.0\n",
            "2024-12-29 02:30:11,272 [nnabla][INFO]: iter=9579 {Training loss}=1.1874353589291786e-07\n",
            "2024-12-29 02:30:11,272 [nnabla][INFO]: iter=9579 {Training error}=0.0\n",
            "2024-12-29 02:30:11,308 [nnabla][INFO]: iter=9589 {Training loss}=1.203267885330206e-07\n",
            "2024-12-29 02:30:11,308 [nnabla][INFO]: iter=9589 {Training error}=0.0\n",
            "2024-12-29 02:30:11,346 [nnabla][INFO]: iter=9599 {Training loss}=1.132487597033105e-07\n",
            "2024-12-29 02:30:11,346 [nnabla][INFO]: iter=9599 {Training error}=0.0\n",
            "2024-12-29 02:30:11,346 [nnabla][INFO]: iter=9599 {Training time}=0.4005584716796875[sec/100iter] 44.84830570220947[sec]\n",
            "2024-12-29 02:30:11,373 [nnabla][INFO]: iter=9600 {Test error}=0.01484375\n",
            "2024-12-29 02:30:11,410 [nnabla][INFO]: iter=9609 {Training loss}=1.1268995336877197e-07\n",
            "2024-12-29 02:30:11,410 [nnabla][INFO]: iter=9609 {Training error}=0.0\n",
            "2024-12-29 02:30:11,447 [nnabla][INFO]: iter=9619 {Training loss}=1.1334189053968657e-07\n",
            "2024-12-29 02:30:11,447 [nnabla][INFO]: iter=9619 {Training error}=0.0\n",
            "2024-12-29 02:30:11,484 [nnabla][INFO]: iter=9629 {Training loss}=1.1362127594338745e-07\n",
            "2024-12-29 02:30:11,484 [nnabla][INFO]: iter=9629 {Training error}=0.0\n",
            "2024-12-29 02:30:11,521 [nnabla][INFO]: iter=9639 {Training loss}=1.1455260562343028e-07\n",
            "2024-12-29 02:30:11,521 [nnabla][INFO]: iter=9639 {Training error}=0.0\n",
            "2024-12-29 02:30:11,558 [nnabla][INFO]: iter=9649 {Training loss}=1.0756768631381419e-07\n",
            "2024-12-29 02:30:11,558 [nnabla][INFO]: iter=9649 {Training error}=0.0\n",
            "2024-12-29 02:30:11,594 [nnabla][INFO]: iter=9659 {Training loss}=1.0691577756460902e-07\n",
            "2024-12-29 02:30:11,595 [nnabla][INFO]: iter=9659 {Training error}=0.0\n",
            "2024-12-29 02:30:11,631 [nnabla][INFO]: iter=9669 {Training loss}=1.0943033146304515e-07\n",
            "2024-12-29 02:30:11,631 [nnabla][INFO]: iter=9669 {Training error}=0.0\n",
            "2024-12-29 02:30:11,669 [nnabla][INFO]: iter=9679 {Training loss}=1.1119983867047267e-07\n",
            "2024-12-29 02:30:11,669 [nnabla][INFO]: iter=9679 {Training error}=0.0\n",
            "2024-12-29 02:30:11,708 [nnabla][INFO]: iter=9689 {Training loss}=1.0561191032820716e-07\n",
            "2024-12-29 02:30:11,708 [nnabla][INFO]: iter=9689 {Training error}=0.0\n",
            "2024-12-29 02:30:11,745 [nnabla][INFO]: iter=9699 {Training loss}=1.0645011627730128e-07\n",
            "2024-12-29 02:30:11,745 [nnabla][INFO]: iter=9699 {Training error}=0.0\n",
            "2024-12-29 02:30:11,745 [nnabla][INFO]: iter=9699 {Training time}=0.39880919456481934[sec/100iter] 45.24711489677429[sec]\n",
            "2024-12-29 02:30:11,772 [nnabla][INFO]: iter=9700 {Test error}=0.0140625\n",
            "2024-12-29 02:30:11,812 [nnabla][INFO]: iter=9709 {Training loss}=1.0346987977527533e-07\n",
            "2024-12-29 02:30:11,812 [nnabla][INFO]: iter=9709 {Training error}=0.0\n",
            "2024-12-29 02:30:11,849 [nnabla][INFO]: iter=9719 {Training loss}=1.0523939408813021e-07\n",
            "2024-12-29 02:30:11,850 [nnabla][INFO]: iter=9719 {Training error}=0.0\n",
            "2024-12-29 02:30:11,891 [nnabla][INFO]: iter=9729 {Training loss}=1.0291108765159152e-07\n",
            "2024-12-29 02:30:11,891 [nnabla][INFO]: iter=9729 {Training error}=0.0\n",
            "2024-12-29 02:30:11,929 [nnabla][INFO]: iter=9739 {Training loss}=1.0812648554292537e-07\n",
            "2024-12-29 02:30:11,929 [nnabla][INFO]: iter=9739 {Training error}=0.0\n",
            "2024-12-29 02:30:11,965 [nnabla][INFO]: iter=9749 {Training loss}=9.797506805853118e-08\n",
            "2024-12-29 02:30:11,966 [nnabla][INFO]: iter=9749 {Training error}=0.0\n",
            "2024-12-29 02:30:12,003 [nnabla][INFO]: iter=9759 {Training loss}=1.0849900888842967e-07\n",
            "2024-12-29 02:30:12,003 [nnabla][INFO]: iter=9759 {Training error}=0.0\n",
            "2024-12-29 02:30:12,045 [nnabla][INFO]: iter=9769 {Training loss}=9.91857973531296e-08\n",
            "2024-12-29 02:30:12,045 [nnabla][INFO]: iter=9769 {Training error}=0.0\n",
            "2024-12-29 02:30:12,084 [nnabla][INFO]: iter=9779 {Training loss}=1.0486685653177119e-07\n",
            "2024-12-29 02:30:12,084 [nnabla][INFO]: iter=9779 {Training error}=0.0\n",
            "2024-12-29 02:30:12,124 [nnabla][INFO]: iter=9789 {Training loss}=1.0123469706968535e-07\n",
            "2024-12-29 02:30:12,124 [nnabla][INFO]: iter=9789 {Training error}=0.0\n",
            "2024-12-29 02:30:12,162 [nnabla][INFO]: iter=9799 {Training loss}=9.965145864043734e-08\n",
            "2024-12-29 02:30:12,162 [nnabla][INFO]: iter=9799 {Training error}=0.0\n",
            "2024-12-29 02:30:12,162 [nnabla][INFO]: iter=9799 {Training time}=0.4171874523162842[sec/100iter] 45.664302349090576[sec]\n",
            "2024-12-29 02:30:12,185 [nnabla][INFO]: iter=9800 {Test error}=0.0140625\n",
            "2024-12-29 02:30:12,224 [nnabla][INFO]: iter=9809 {Training loss}=9.909265230589881e-08\n",
            "2024-12-29 02:30:12,224 [nnabla][INFO]: iter=9809 {Training error}=0.0\n",
            "2024-12-29 02:30:12,263 [nnabla][INFO]: iter=9819 {Training loss}=1.0253855720065985e-07\n",
            "2024-12-29 02:30:12,263 [nnabla][INFO]: iter=9819 {Training error}=0.0\n",
            "2024-12-29 02:30:12,301 [nnabla][INFO]: iter=9829 {Training loss}=9.844073645126628e-08\n",
            "2024-12-29 02:30:12,301 [nnabla][INFO]: iter=9829 {Training error}=0.0\n",
            "2024-12-29 02:30:12,339 [nnabla][INFO]: iter=9839 {Training loss}=9.741629725112944e-08\n",
            "2024-12-29 02:30:12,339 [nnabla][INFO]: iter=9839 {Training error}=0.0\n",
            "2024-12-29 02:30:12,378 [nnabla][INFO]: iter=9849 {Training loss}=9.872013606582186e-08\n",
            "2024-12-29 02:30:12,378 [nnabla][INFO]: iter=9849 {Training error}=0.0\n",
            "2024-12-29 02:30:12,420 [nnabla][INFO]: iter=9859 {Training loss}=9.750942808750551e-08\n",
            "2024-12-29 02:30:12,421 [nnabla][INFO]: iter=9859 {Training error}=0.0\n",
            "2024-12-29 02:30:12,459 [nnabla][INFO]: iter=9869 {Training loss}=9.713689053114649e-08\n",
            "2024-12-29 02:30:12,459 [nnabla][INFO]: iter=9869 {Training error}=0.0\n",
            "2024-12-29 02:30:12,496 [nnabla][INFO]: iter=9879 {Training loss}=9.769568265483031e-08\n",
            "2024-12-29 02:30:12,496 [nnabla][INFO]: iter=9879 {Training error}=0.0\n",
            "2024-12-29 02:30:12,534 [nnabla][INFO]: iter=9889 {Training loss}=9.564676872741984e-08\n",
            "2024-12-29 02:30:12,535 [nnabla][INFO]: iter=9889 {Training error}=0.0\n",
            "2024-12-29 02:30:12,573 [nnabla][INFO]: iter=9899 {Training loss}=9.862700522944579e-08\n",
            "2024-12-29 02:30:12,573 [nnabla][INFO]: iter=9899 {Training error}=0.0\n",
            "2024-12-29 02:30:12,573 [nnabla][INFO]: iter=9899 {Training time}=0.41074180603027344[sec/100iter] 46.07504415512085[sec]\n",
            "2024-12-29 02:30:12,598 [nnabla][INFO]: iter=9900 {Test error}=0.0140625\n",
            "2024-12-29 02:30:12,635 [nnabla][INFO]: iter=9909 {Training loss}=9.434292280730006e-08\n",
            "2024-12-29 02:30:12,635 [nnabla][INFO]: iter=9909 {Training error}=0.0\n",
            "2024-12-29 02:30:12,674 [nnabla][INFO]: iter=9919 {Training loss}=9.24802776580691e-08\n",
            "2024-12-29 02:30:12,674 [nnabla][INFO]: iter=9919 {Training error}=0.0\n",
            "2024-12-29 02:30:12,710 [nnabla][INFO]: iter=9929 {Training loss}=9.54605212655224e-08\n",
            "2024-12-29 02:30:12,710 [nnabla][INFO]: iter=9929 {Training error}=0.0\n",
            "2024-12-29 02:30:12,748 [nnabla][INFO]: iter=9939 {Training loss}=9.518112165096682e-08\n",
            "2024-12-29 02:30:12,748 [nnabla][INFO]: iter=9939 {Training error}=0.0\n",
            "2024-12-29 02:30:12,786 [nnabla][INFO]: iter=9949 {Training loss}=9.29459460508042e-08\n",
            "2024-12-29 02:30:12,786 [nnabla][INFO]: iter=9949 {Training error}=0.0\n",
            "2024-12-29 02:30:12,828 [nnabla][INFO]: iter=9959 {Training loss}=9.303907688718027e-08\n",
            "2024-12-29 02:30:12,828 [nnabla][INFO]: iter=9959 {Training error}=0.0\n",
            "2024-12-29 02:30:12,865 [nnabla][INFO]: iter=9969 {Training loss}=9.415665402912055e-08\n",
            "2024-12-29 02:30:12,865 [nnabla][INFO]: iter=9969 {Training error}=0.0\n",
            "2024-12-29 02:30:12,906 [nnabla][INFO]: iter=9979 {Training loss}=8.940692453052179e-08\n",
            "2024-12-29 02:30:12,907 [nnabla][INFO]: iter=9979 {Training error}=0.0\n",
            "2024-12-29 02:30:12,944 [nnabla][INFO]: iter=9989 {Training loss}=9.01519712215304e-08\n",
            "2024-12-29 02:30:12,944 [nnabla][INFO]: iter=9989 {Training error}=0.0\n",
            "2024-12-29 02:30:12,981 [nnabla][INFO]: iter=9999 {Training loss}=9.126955546889803e-08\n",
            "2024-12-29 02:30:12,981 [nnabla][INFO]: iter=9999 {Training error}=0.0\n",
            "2024-12-29 02:30:12,981 [nnabla][INFO]: iter=9999 {Training time}=0.4078824520111084[sec/100iter] 46.48292660713196[sec]\n",
            "2024-12-29 02:30:13,004 [nnabla][INFO]: iter=9999 {Test error}=0.01484375\n",
            "2024-12-29 02:30:13,013 [nnabla][INFO]: Parameter save (.h5): output/lenet_params_010000.h5\n",
            "2024-12-29 02:30:13,016 [nnabla][INFO]: Saving output/lenet_result.nnp as nnp\n",
            "2024-12-29 02:30:13,017 [nnabla][INFO]: Saving <_io.StringIO object at 0x79967ed66950> as prototxt\n",
            "2024-12-29 02:30:13,023 [nnabla][INFO]: Parameter save (.h5): <_io.BytesIO object at 0x79967ed8aed0>\n",
            "2024-12-29 02:30:13,024 [nnabla][INFO]: Model file is saved as (.nnp): output/lenet_result.nnp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "outputフォルダにモデルファイルnnpが作られていることを確認。"
      ],
      "metadata": {
        "id": "oaaEWUuI2mq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6yXUm1t2rVN",
        "outputId": "d2216e33-7e02-4662-ecb4-7444bed2a970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_0.json     checkpoint_7000.json     params_1000.h5  params_8000.h5  states_5000.h5\n",
            "checkpoint_1000.json  checkpoint_8000.json     params_2000.h5  params_9000.h5  states_6000.h5\n",
            "checkpoint_2000.json  checkpoint_9000.json     params_3000.h5  states_0.h5     states_7000.h5\n",
            "checkpoint_3000.json  lenet_params_010000.h5   params_4000.h5  states_1000.h5  states_8000.h5\n",
            "checkpoint_4000.json  lenet_result_epoch0.nnp  params_5000.h5  states_2000.h5  states_9000.h5\n",
            "checkpoint_5000.json  lenet_result.nnp\t       params_6000.h5  states_3000.h5\n",
            "checkpoint_6000.json  params_0.h5\t       params_7000.h5  states_4000.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nnpをonnxに変換するためのパッケージをインストール"
      ],
      "metadata": {
        "id": "_QNs8Uz9Q1f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnabla_converter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBRnx2GiRVt-",
        "outputId": "314284ae-8f4f-4a10-a916-f885e9363e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnabla_converter\n",
            "  Downloading nnabla_converter-1.39.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow<2.15.0,>=2.13.0 (from nnabla_converter)\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorflow-probability<0.23.0,>=0.21.0 (from nnabla_converter)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting onnx-tf (from nnabla_converter)\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl.metadata (510 bytes)\n",
            "Collecting tf2onnx~=1.15.1 (from nnabla_converter)\n",
            "  Downloading tf2onnx-1.15.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tensorflow-addons (from nnabla_converter)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting onnx~=1.13.0 (from nnabla_converter)\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tflite2onnx (from nnabla_converter)\n",
            "  Downloading tflite2onnx-0.4.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from nnabla_converter) (24.3.25)\n",
            "Requirement already satisfied: pyopenssl in /usr/local/lib/python3.10/dist-packages (from nnabla_converter) (24.2.1)\n",
            "Requirement already satisfied: nnabla==1.39.0 in /usr/local/lib/python3.10/dist-packages (from nnabla_converter) (1.39.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (75.1.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (3.0.11)\n",
            "Requirement already satisfied: numpy~=1.26.0 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (1.26.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (1.35.90)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (7.1.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (21.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (3.12.1)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (4.67.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (2.36.1)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (11.0.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from nnabla==1.39.0->nnabla_converter) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx~=1.13.0->nnabla_converter) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (18.1.1)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (24.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (2.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15.0,>=2.13.0->nnabla_converter) (1.68.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.23.0,>=0.21.0->nnabla_converter) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.23.0,>=0.21.0->nnabla_converter) (3.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability<0.23.0,>=0.21.0->nnabla_converter) (0.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx~=1.15.1->nnabla_converter) (2.32.3)\n",
            "Requirement already satisfied: cryptography<44,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyopenssl->nnabla_converter) (43.0.3)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->nnabla_converter)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "\u001b[33mWARNING: Package 'tflite2onnx' has an invalid Requires-Python: Invalid specifier: '>=3.5.*'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tflite>=2.4.0 (from tflite2onnx->nnabla_converter)\n",
            "  Downloading tflite-2.10.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.45.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44,>=41.0.5->pyopenssl->nnabla_converter) (1.17.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx~=1.15.1->nnabla_converter) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx~=1.15.1->nnabla_converter) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx~=1.15.1->nnabla_converter) (2.2.3)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.90 in /usr/local/lib/python3.10/dist-packages (from boto3->nnabla==1.39.0->nnabla_converter) (1.35.90)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->nnabla==1.39.0->nnabla_converter) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->nnabla==1.39.0->nnabla_converter) (0.10.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.90->boto3->nnabla==1.39.0->nnabla_converter) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44,>=41.0.5->pyopenssl->nnabla_converter) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15.0,>=2.13.0->nnabla_converter) (3.2.2)\n",
            "Downloading nnabla_converter-1.39.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2onnx-1.15.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.7/454.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite2onnx-0.4.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite-2.10.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: wrapt, typeguard, tflite, tensorflow-probability, tensorflow-estimator, onnx, ml-dtypes, keras, tflite2onnx, tf2onnx, tensorflow-addons, onnx-tf, google-auth-oauthlib, tensorboard, tensorflow, nnabla_converter\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 ml-dtypes-0.2.0 nnabla_converter-1.39.0 onnx-1.13.1 onnx-tf-1.10.0 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.14.0 tensorflow-probability-0.22.1 tf2onnx-1.15.1 tflite-2.10.0 tflite2onnx-0.4.1 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nnpをonnxに変換（何やらWarningが出てくるが、onnxが出力されていればOK）。"
      ],
      "metadata": {
        "id": "LKnOh1yJWnnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nnabla_cli convert ./output/lenet_result.nnp ./output/lenet_result.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn_kjJ6XQ9ZS",
        "outputId": "b7be3cbf-97b2-496e-88c4-d894aacc1e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-29 02:46:58,856 [nnabla][INFO]: Initializing CPU extension...\n",
            "NNabla command line interface (Version:1.39.0, Build:240523014612)\n",
            "2024-12-29 02:46:59.830236: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-29 02:46:59.830287: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-29 02:46:59.830328: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-29 02:47:00.963159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-12-29 02:47:02,145 [numexpr.utils][INFO]: NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "Importing ./output/lenet_result.nnp\n",
            " Expanding Validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d23benoyVii8",
        "outputId": "87e1f8ae-599d-476b-cb25-7b48ce7df07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint_0.json     checkpoint_7000.json     params_0.h5     params_7000.h5  states_4000.h5\n",
            "checkpoint_1000.json  checkpoint_8000.json     params_1000.h5  params_8000.h5  states_5000.h5\n",
            "checkpoint_2000.json  checkpoint_9000.json     params_2000.h5  params_9000.h5  states_6000.h5\n",
            "checkpoint_3000.json  lenet_params_010000.h5   params_3000.h5  states_0.h5     states_7000.h5\n",
            "checkpoint_4000.json  lenet_result_epoch0.nnp  params_4000.h5  states_1000.h5  states_8000.h5\n",
            "checkpoint_5000.json  lenet_result.nnp\t       params_5000.h5  states_2000.h5  states_9000.h5\n",
            "checkpoint_6000.json  lenet_result.onnx        params_6000.h5  states_3000.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "変換後のファイルをPCにダウンロードするために、Google Driveに一旦コピーする。"
      ],
      "metadata": {
        "id": "dFab70nk3Ovz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgY1Ml1SHEp8",
        "outputId": "cded184c-732f-4124-d11f-ffe08b09a39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./output/lenet_result.onnx /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "XDGf0RyDM-Fo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}